[
  {
    "objectID": "posts/Introduction_to_causal_inference_Graphical_Models/Graphical_Models.html",
    "href": "posts/Introduction_to_causal_inference_Graphical_Models/Graphical_Models.html",
    "title": "04. Graphical Models",
    "section": "",
    "text": "Contents\n\nGraphical models란 무엇인가요?\nBayesian Networks\nCausal Graphs\nBasic building blocks of graphs\nD-separation\n\n◦ 강의 영상 링크 : Chapter 3 - Graphical Models\n작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\n\n\n(1) Graphical models란 무엇인가요?\n\nProbabilistic graphical models, which provides a mechanism for exploiting structure in complex distributions to describe them compactly, and in a way that allows them to be constructed and utilized effectively.\n“Probabilistic Graphical Models : Principles and Techniques” (2009, Daphne Koller & Nir Friedman)\n\n\n정의 : 데이터(확률변수)간의 구조를 파악해서 복잡한 분포를 compact하게 표현할 수 있는 방법입니다.\n목표 : \n\n\n◦ 확률 변수간의 구조 표현 : 인과관계 (방향성) or 상관관계\n◦ 복잡한 분포를 표현 : 확률 변수들간의 결합확률분포 (Joint Distribution)\n◦ Compact하게 표현 : 분포를 구성하는 Parameter의 수를 줄이는 방식으로 표현 \n\n\nGraph 정의 : Graphical model을 통해 변수들간의 구조를 시각화한 방법이 Graph 입니다. (Chapter 3에서는요!)\n용어 정리 (Graph Terminology)\n\n\n◦ Graph : 수학적으로 Node와 Edge의 집합입니다. &lt; \\(G = (V, E)\\) &gt;\n◦ Node (Vertex) : Graph에서 주로 변수들을 나타냅니다. ◦ Edge (Link) : Graph에서 변수들간의 관계를 나타냅니다.\n◦ 그래프 방향성 여부에 따라 2가지 형태가 존재합니다.\n    1) Undirected Graph : 아래 Nodes와 Edges 그림 처럼 방향성이 없는 그래프\n         - 예시 : Markov Random Fields, Boltzmann Machine\n    2) Directed Graph : 아래 오른쪽 그림처럼, 화살표가 존재하는 그래프 \n         - 예시 : Bayesian Networks, HMM (Hidden Markov Models), Latent Variable Models\n◦영향을 주는 Node이면 Parent (Ancestor)이고, 받는 Node는 Child (Descendant)라고 정의합니다.\n\n◦ DAG (Directed Acyclic Graph) : Directed graph에서 cycle이 존재하는 경우가 있지만,\n    DAG는 cycle이 없는 방향성 그래프에 해당 합니다.\n     → Cycle이 있는 경우, Causal Inference에서 다루기 까다로워, 해당 강의에서는 DAG만 다룰 예정입니다.\n\n\n\n\n(2) Bayesian Networks\n\n위에서 설명드린 것 처럼, 방향성 그래프에 속하는 Bayesian Networks에 대해서 알아보도록 하겠습니다.\n정의 : 변수 집합의 Dependency 구조와 결합확률분포를 인수분해 방식 (Factorisation)을 통해, 효과적으로 나타내는 Probabilistic graphical models 입니다.\n활용 : DAG가 Bayesian Networks에 속하므로, Causal Model을 활용할 때 사용할 수 있습니다..!\nJoint Distribution 표현 방법 : \n\n\n◦ 변수간의 관계 (association)를 모른다면, 확률 연쇄법칙을 사용해서 다음과 같이 조건부 분포들의\n    (coditional distribution) 곱으로 결합분포를 표현할 수 있어요.\n   - \\(p(x_1, \\dots, x_n) = p(x_1)\\prod_{i=2}^n p(x_i | x_{i-1}, \\dots, x_1)\\)\n◦  만약 \\(x_i, i=1,\\dots, n\\) 가 이항(binary) 변수라면, \\(p(x_i | x_{i-1}, \\dots, x_1)\\)은 \\(2^{i-1}\\) 개의 모수가 필요해요.\n     → 결론적으로 조건부 확률에서 조건으로 주어지는 변수가 많아지면 모수가 지수적으로 증가하게 됩니다.\n \n◦  필요없는 변수는 고려하지 말고 영향을 주는 변수만을 골라서 조건으로 준다면, 고려해야하는 경우가 적어지므로\n     필요한 모수가 적어질 것입니다..! \n   - 아래 예시에서 \\((x_1, x_2, x_3)\\)가 주어지는 경우, \\(x_4\\) = 1(or \\(x_4=0\\))인 확률, 즉 \\(p(x_4|x_3, x_2, x_1)\\)만\n     정하면 나머지 확률은 \\(1-p(x_4|x_3, x_2, x_1)\\)로 자동으로 정해지게 됩니다.\n     → 따라서, 각 \\((x_1, x_2, x_3)\\) 경우에 1개의 모수만을 필요로 하게 됩니다.\n\n◦  다음 내용에서는 확률 분포의 조건부 독립에 대한 가정에 대해 알아보도록 하겠습니다~!\n\n\nLocal Markov Assumption\n\n\n◦ 정의 : DAG의 Parent가 주어지면, 노드 X는 나머지 descendants가 아닌 노드들과 독립  \n◦ 목적 : Conditional probability를 단순하게 만들기 위해서 입니다..!\n    (마치, Markov chain에서 현재 \\(t\\)시점의 확률분포가 이전 \\((t-1)\\) 시점에만 의존하는 것을 생각하면,\n    이해가 조금 쉬울 것 같습니다! - \\(P(X_t|X_{t-1}, \\dots, X_1) = P(X_t|X_{t-1})\\) )\n◦ 기대효과 : 결합분포에서, 조건으로 주어지는 변수가 줄어 고려해야하는 모수가 줄어들게 됩니다!\n    → \\(P(x_1, \\dots, x_4) = P(x_1) P(x_2|x_1) P(x_3 | x_2, x_1) P(x_4|x_3)\\)\n\n◦ 예시 : 아래 그림에서 \\(X_4\\)는 \\(X_3\\)가 조건으로 주어진다면 나머지 변수들과는 조건부 독립이에요.\n    → \\(P(X_4|X_3,X_2,X_1) = P(X_4|X_3)\\)\n◦ 직관 : “지능 → 성적 → 장학금 수여” 이라는 DAG를 생각해봅시다.\n    - 만약 어떤 학생의 성적을 안다면, 그 학생의 지능을 몰라도 장학금을 수여여부를 알 수 있게 됩니다..!\n      \\(P(장학금|지능,성적) = P(장학금|성적)\\)\n\n\nBayesian Network Factoriation (Chain rule for Bayesian networks)\n\n\n◦ 정의 : 확률분포 P와 DAG인 G가 주어졌을 때, G에 따른 P의 Factorisation은 아래와 같습니다.\n    \\(p(x_1, \\dots, x_n) =\\prod_{i=1}^n p(x_i | Pa_i)\\)\n◦ Local Markov assumption ⟺ Bayesian network factorization\n    → 위에서 배운 Local Markov assumption과 Bayesian network factorization은 같아요!\n       (해당 부분에 대한 증명은 Probabilistic Graphical Models 책의 Chapter 3 참고 부탁드립니다)\n◦ Local Markov assumption의 한계 : 독립성(독립, 조건부 독립,…)에 대해서만 정보를 제공합니다.\n    → 인접한 Node에 대해서, 종속성 (Dependence)에 대한 보장을 하기 위해서는 조금 더 강한 가정이 필요해요!\n    → 그러면 Minimality assumption에 대해 배워보겠습니다.\n\n\nMinimality assumption\n\n\n◦ 정의 : 해당 가정은 2가지 부분으로 구성되어 있습니다. \n    - Local Markov assumption \n    - Adjacent nodes in the DAG are dependent (DAG에서 인접한 노드들은 의존적이다)\n◦ 차이점 : Local Markov assumption과 비교 \n    - 연결된 노드 X와 Y가 있다고 가정해봅시다.     - Local Markov assumption만 있는 경우, 노드 \\(X\\)와 \\(Y\\)가 있는 경우 \\(P(x,y) = P(x)P(y|x)\\) 뿐만 아니라, \n      \\(P(x,y) = P(x)P(y)\\) 형태도로 인수분해가 가능합니다. (노드 \\(X\\)와 \\(Y\\)가 독립) \n    →  그러나, Minimality assumption에서는 추가적인 독립성 가정을 허용하지 않아요.  \n         (그래서 해당 가정에서는 \\(P(x,y) = P(x)P(y)\\)에 대해 이야기할 수 없어요)\n\n\n\n\n(3) Causal Graphs\n\n위에서 다룬 부분은 DAG의 연관성에 (Association) 대한 부분을 다루었습니다.\n그러나, 저희가 다뤄야할 인과성에 (Causation) 대해서는 추가적인 가정이 필요해요 (Causal assumption)\nCausal Graphs  : Bayesian Networks + 인과성 가정(Causal Edges Assumption) \n\n\n\nWhat is a cause? \n    ◦ 만약 변수 Y가 변수 X의 변화에 ​​따라 변할 수 있다면, X는 Y의 원인이라고 합니다. \n(Strict) Causal Edges Assumption\n    ◦ Directed graph에서, 모든 부모(parent) 노드는 모든 자식(children) 노드의 직접적인 원인입니다.\n    → Minimality assumption의 2번째 가정이(Adjacent nodes in the DAG are dependent)\n        자연스럽게 strict causal edges assumption으로 연결되며, 부모는 자식의 cause라고 특정하는 가정입니다.\n\n3)  Q : 그러면 Strict하지 않은 가정도 있는 건가요? (non-strict assumption)\n     A : 네! 그런데, 우리가 공부할 내용에 대해서는 strict 가정을 만족하는 DAG에 대해서만 다룰 예정이에요\n\n\nAssumptions Flowchart : DAG의 Causal dependencies를 파악하기 위해서 2가지 가정을 배웠습니다!\n\n\n1) Markov Assumption \n    : DAG의 부모 노드가 주어지면, 노드 X는 나머지 descendants가 아닌 노드들과 독립  \n2) Causal Edges Assumption \n    : Directed graph에서, 모든 부모 노드는 모든 자식 노드의 직접적인 원인\n     → 해당 가정은 Minimality Assumption을 내포하고 있어, 위에 Markov Assumption으로 나타냈습니다.\n\n\n\n\n\n(4) Graphical building blocks\n\nDAG에서 그래프를 이루는 구성요소와 흐름에 대해서 배워보려고 해요.\n그래프의 최소 구성 요소 (D-separation 요소)는 Chain, Fork, Immorality 이렇게 3가지로 이루어져 있습니다.\n\n\n\nChains & Forks : 3개의 노드로 구성된 DAG 중 Chain, Fork는 동일한 Dependency 성질을 보입니다.\n\n\n◦  설명 : \n    - \\(X_2\\)가 주어지지 않은 경우 :  \\(X_1, X_3\\)는 직접 연결되어있지는 않지만, 연관성은 존재합니다.\n       → \\(X_1\\)에서 \\(X_3\\)로 가는 통로가 차단되어 있지 않아, 그대로 정보가 \\(X_3\\)까지 흐르게 됩니다.\n            (Unblocked Path)\n    - \\(X_2\\)가 주어진 경우 :  \\(X_1, X_3\\)는 조건부 독립입니다. (연관성은 사라지게 됩니다)\n       → \\(X_1\\)에서 \\(X_3\\)로 가는 통로가 차단되어 있어,  \\(X_1\\)에 있는 정보가 더이상 흐르지 않게 됩니다.\n            (Blocked Path)\n◦  목표 : Causal association이외의 Non-causal association 영향을 제거 (Path 차단)\n    - Chains : Mediator (매개변수)를 통제 \n    - Forks : Confounder (교란변수)를 통제\n\n◦  사례 : \n    - Chains : 위에서 이야기한 사례인 “지능 → 성적 → 장학금 수여” 이라는 DAG를 생각해봅시다.\n       → 만약 성적을 알고 있다면, 지능과 장학금 수여에 대한 연관성은 더이상 존재하지 않게 됩니다!\n            &lt; 성적을 알고 있고, 그에 따라서 장학금을 수여 받게된 것이기 때문이죠 &gt; \n    - Forks : \\(X_1, X_2, X_3\\)가 연관되어 있는 Fork 형태를 선형 모형으로 이해 해봅시다!  \n       → \\(X_1 = X_2 + \\epsilon_1\\). \\(X_3 = X_2 + \\epsilon_2\\)  \n       → \\(X_2 \\perp \\epsilon_1, \\epsilon_2\\) / \\(\\epsilon_1 \\perp \\epsilon_2\\)\n       → \\(X_2 = x\\) 로 주어진다면, \\(x + \\epsilon_1 \\perp x + \\epsilon_2\\)\n            즉, \\(X_1\\)과 \\(X_3\\)는 조건부 독립입니다.!\n\n\nColiders(Immoralities) and their Descendants : \n\n\n◦  Immoralities vs Chains & Forks :  \n    - Immoralities는 앞에서 설명한 Chains과 Forks와 다른 구조를 가집니다.\n    - \\(X_1\\)과 \\(X_3\\)에 공통으로 영향받는 변수인 \\(X_2\\)가 주어진다면, \\(X_1\\)과 \\(X_3\\)에 연관성이 생기게 됩니다.\n◦  목표 : Causal association이외의 Non-causal association영향을 제거 (Path를 차단하지 않음)\n    - Immoralities : Collider를 통제하게 되면, Association이 형성되므로 통제하지 X \n\n◦  만약 Collider의 자손 (Descendents)이 주어졌다면, 어떻게 될까요?    \n\\(X_4\\)가 주어진 경우, \\(X_1\\)과 \\(X_3\\)는 더 이상 독립이 아니게 됩니다\n\n◦  사례 1 : 잘생긴 사람들은 무례한가요?   \n- \\(X_2\\) (연애여부)를 통제하지 않았을 때 : 외모 (\\(X_1\\))와 친절함 (\\(X_3\\))은 독립에 가깝습니다.   \n- \\(X_2\\) (연애여부)를 통제하지 했을 때 : 연애여부를 안다면 (\\(X_2\\)),  연애를 하지 않는 사람들은 외모와 친절함과 음의 상관관계를 가지는 것을 확인해볼 수 있습니다…!\n\n\n◦  사례 2 : 아래와 같은 Data Generating Process를 살펴봅시다.\n    - \\(X_1\\) ~ \\(N(0,1)\\), \\(X_2\\) ~ \\(N(0,1)\\), \\(X_2 = X_1 + X_3\\)\n    - \\(X_2\\)가 조건으로 주어지지 않은 경우, 공분산은 0 (독립)\n    - \\(X_2\\)가 조건으로 주어진 경우, 공분산은 -1 (음의 상관관계)\n\n\n\n\n\n(5) D-separation\n\n일반적인 인과 모형은 앞에서 배운 Building Blocks (Chains, Forks, Immoralities) 처럼 단순하게 구성되어 있지 않아요.\n따라서 복잡한 인과모형에 적용할 수 있는 규칙에 대해 확인해보도록 하겠습니다.\nD-separation : \n\n\n◦  정의 : 두 노드의 집합 \\(X\\), \\(Y\\) 사이의 모든 경로(Path)가 노드 집합 \\(Z\\)에 의해 차단되는 경우,\n     \\(X\\)와 \\(Y\\)는 \\(Z\\)에 의해 d-separation 된다고 말합니다.\n◦  의미 :    \n- 그래프 상에서 확인할 수 있는 d-separation은 확률분포 상 조건부 독립을 의미해요   \n- d-separation은 Local Markov assumption보다 더 광범위하므로 Global Markov assumption(dependencies) 라고도 해요. 이 경우에는 Local과 Global을 구분하지 않고 Markov assumption이라고 합니다…!\n     → 복잡한 그래프 구조에서 d-separated 되는 경우를 알아야하고 d-separated에서 나오는\n          blocked path를 통해 confounding association 효과를 제거해야 합니다!\n     → Graphical models에서 조건부 독립의 가정/성질(local Markov assumption, d-separated)은\n         확률분포의 분해와 연결됩니다.\n\n◦  예시 : \n    - \\(T\\)와 \\(Y\\)는 \\(\\{M_1, W_2, X_2\\}\\)가 주어진 경우, d-separated 될까요?    - \\(T\\)와 \\(Y\\)는 \\(\\{M_1, W_2, X_1, X_2\\}\\)가 주어진 경우, d-separated 될까요?\n       → 정답은 댓글로 달아주세요\n\n\nTo be continued) 배운 Causal Graphs를 활용해 일반화된 방법인 Strcutural Causal Models에 대해 배울 예정입니다.\n\n\nReference \n\n◦ Lecture Notes : Bayesian Networks 강의 자료 (카네기 멜론 Uni) [Link]\n◦ Books : Probabilistic graphical models principles and techniques [Link]\n◦ Blogs : Collider 관련 적용 NCSoft 적용 사례 [Link]"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Causal_Discovery/Causal_Discovery.html",
    "href": "posts/Introduction_to_causal_inference_Causal_Discovery/Causal_Discovery.html",
    "title": "12. Causal Discovery from Observational Data",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀의 김상돈, 김준영입니다. \nIntroduction to Causal Inference 강의의 11번째 챕터이며, 해당 챕터에서 다루는 내용은 아래와 같습니다.\n\nContents\n\nIndependence-Based Causal Discovery\nSemi-Parametric Causal Discovery\n\n◦ 강의 영상 링크 : Chapter 11. causal discovery from observational data\n    작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\nCausal Discovery 의미\n\nCausal Discovery : Data → Causal graph\n몇 가지 가정 하에서, causal discovery를 찾는 알고리즘을 적용하여 causal graph를 찾을 수 있음\n\n\n\n\n1. Independence-Based Causal Discovery\nAssumption\n\nMarkov assumption\nA node is dependent only on its descendants in the graph\n\n\n예시) 아래 그림에서 \\(X_4\\)는 \\(X_3\\)가 조건으로 주어진다면 나머지 변수들과는 독립(조건부 독립)\n\n→ \\(P(X_4|X_3,X_2,X_1) = P(X_4|X_3)\\)\n\n\n\n\nFaithfulness\nNode that are causally connected in a particular way in the graph are probabilistically dependent\n\nFaithfulness Conterexample\n\n\n\n\n\\[ \\begin{aligned} B &:= \\alpha A \\\\ C &:= \\gamma A \\\\ D &:= \\beta B + \\delta C \\\\ \\newline D &= (\\alpha \\beta + \\gamma \\delta) A \\end{aligned}  \n\\]\n\\(\\alpha \\beta = - \\gamma \\delta\\) 일 때, \\(D = 0\\)이 됨\n즉, A → B → D의 효과와 A → C → D의 효과가 서로 반대일 경우 효과가 상쇄됨\nA, D 간에 관계가 없다는 잘못된 결론을 도출할 수 있으므로, 이러한 경우는 없다고 가정함\n\n\nCausal sufficiency\nthere are no unobserved confounders of any of the variables in the graph\n\n\nAcyclicity\nstill assuming there are no cycles in the graph\n\n\n\n\nMarkov equivalent class\n\nconditional independence 구조가 같은 DAG의 집합을 의미함\nDAG에서 skeleton과 v-structure(immorality)가 같은 경우\n\nChain/Fork\n\n\nMarkov : \\(X_1 \\perp\\!\\!\\!\\perp X_3 | X_2\\)\nMinimality : \\(X_1 \\not\\!\\perp\\!\\!\\!\\perp X_2 \\text{ and }X_2 \\not\\!\\perp\\!\\!\\!\\perp X_3\\)\nFaithfulness : \\(X_1 \\not\\!\\perp\\!\\!\\!\\perp X_3\\)\nchain/fork에 해당하는 세 그래프 모두 그래프의 형태는 다르지만, 같은 conditional independence 구조를 갖음\n\nImmorality\n\n\n\n\nMarkov : \\(X_1 \\not\\!\\perp\\!\\!\\!\\perp X_3 | X_2\\)\nMinimality : \\(X_1 \\not\\!\\perp\\!\\!\\!\\perp X_2 \\text{ and }X_2 \\not\\!\\perp\\!\\!\\!\\perp X_3\\)\nFaithfulness : \\(X_1 \\perp\\!\\!\\!\\perp X_3\\)\nImmorality의 경우 같은 conditional independent 구조를 갖는 그래프는 한 개밖에 없음\n\nSkeletons\n\n\n\n\n\n\n\n\n\n\n\nchain/fork 구조의 경우 같은 conditional independence 구조를 갖고, 같은 skeleton을 갖음\ncomplete 그래프의 의 경우 chain 구조에서 \\(X_1 \\rightarrow X_3\\) edge를 추가할 때, 이전과 다른 conditional independence 구조를 갖고, 다른 skeleton을 갖음\n\n\nMarkov Equivalence via Immoral Skeletons\ntwo graphs are markov equivalent if and only if they have the same skeleton and same immoralities\n\n\nEssential graph(CPDAG): skeleton, immorality가 같은 그래프를 의미함\nMarkov equivalent class를 만족하는 DAG는 CPDAG로 표현할 수 있음\n\nExample\n\n\n\n\n\n\n\n\n\n\n\n\nPC algorithm\n\n데이터로부터 CPDAG를 찾는 알고리즘\n\n\n1. Identify the skeleton\n\n\n노드 간 완전연결된 complete graph 생성\ncomplete graph에서 두 노드 간 unconditionally independent인 경우 edge 제거\n\n\\(A,\\, B\\)는 immorality이므로 \\(A\\perp\\!\\!\\!\\perp B\\), edge 제거\n\n모든 쌍 \\((X, Y)\\)에 대해 \\(X\\perp\\!\\!\\!\\perp Y|{Z}\\)인 경우 edge 제거\n\n\\(C\\)에 대해 conditioning 했을 때, conditionally independent라는 의미는 두 노드 간 직접 연결된 edge가 없다는 의미로 볼 수 있음\n\\(A\\)와 \\(E\\)에 직접 연결된 edge가 사라짐\n나머지 노드도 동일한 접근 방식으로 생각해보면 (c)그래프처럼 true graph의 skeleton을 식별할 수 있음\n\n\n2. Identify immoralities and orient them \n\n\nImmorality의 경우 conditional independent 구조를 갖는 그래프는 한 개밖에 없으므로 방향을 식별할 수 있음\nImmorality의 경우 \\(X \\not\\!\\perp\\!\\!\\!\\perp Y | Z\\) 인 경우에 해당함\n\\(A\\perp\\!\\!\\!\\perp B|{C}\\), \\(A\\perp\\!\\!\\!\\perp D|{C}\\), \\(B\\perp\\!\\!\\!\\perp C|{E}\\), \\(A\\perp\\!\\!\\!\\perp B|{C}\\), \\(D\\perp\\!\\!\\!\\perp E|{C}\\) 에 대해서, 각각 다 test해보고conditionally dependent가 되는 쌍을 찾음\n\n3. Orient qualifying edges that are incident on colliders\n\n\n남은 edge 중에서 방향을 지정했을 때, immorality가 되지 않는 방향으로 지정\n\\(D \\rightarrow C\\)의 경우 \\(A \\rightarrow C \\leftarrow D\\)로 immorality에 해당하므로, \\(C \\rightarrow D\\) 로 방향을 지정해줘야 함\n\nCausal discovery에 관한 다른 방법\n\n\n\n인과추론의 데이터과학 [session 18-3] 강의자료\n\n\n\nFCI : without assuming causal sufficiency\nCCD : without assuming acylicity\n\n\n\nPC 알고리즘 한계점\n\n각 노드 쌍의 conditional independence test에 의존하므로 계산량이 많음\n정확한 test를 하기 위해서는 데이터가 많아야 함\n\n\n\n2. Semi-Parametric Causal Discovery\n\nIssues in independence based causal discovery\n\nFaithfulness assumption 필요\nLarge samples for conditional independence tests\nMarkov equivalence class만 identify\n\n\n\nNo identifiability without Parametric Assumptions\n1. Markov perspective\n\n\nMarkov equivalent인 경우, conditional independence가 \\(X→Y\\)와 \\(X←Y\\)구별에 도움 X\nBest는 essential graph X-Y identification\n\n2. SCM perspective\n\nNon-Identifiability of Two-Node Graphs(proposition): For every joint distribution P(x,y) on two real-valued random variables, there is an SCM in either direction that generates data consistent with P(x,y)\n\n\n\nParametric form SCM에 assumptions을 한다면, 구별 가능!\n즉, parametric form needs assumptions!\n\nLinear Non-Gaussian Assumption\n\nMarkov Completeness Theorem에 의해 linear with Gaussian noise형태는 그래프 구별이 불가능\n그렇지만 non-Gaussian인 경우 구별 가능!\n\n\\[Y : = f(x) + U\\]\n\\(X\\perp\\!\\!\\!\\perp U\\), and U is non-Gaussian random variable.\n\nIdentifiability in linear non-Gaussian setting theorem:\n\n\n\nGraphic intuition\n\n\n\n\nLiNGAM\n가정\n\nData generating process is linear\nNo unobserved confounders\n⇒ DAG 충족\nNoise follows independent non-Gaussian distribution.\n\ncomplete causal structure can be estimated without prior information\ndiscover direction of causality\n\n⇒ Linear, Non-Gaussian, Acyclic Model\n\n\nICA(Independent Component Analysis)\n\n: A statistical technique used for estimating mixing matrix A s.t x=Ae, x is observed and A and e are not.\n→ identify linear model\n\n독립 성분 분석\nDimension reduction\n데이터가 통계적으로 독립이고 정규분포를 따르지 않을 때, 독립성이 최대가 되는 방향으로 축을 삼음\n⇒ 가장 독립적인 축을 찾음\n\n만일 Gaussian이면 covariance matrix가 항상 같음\n\n\n\nhttps://www.jmlr.org/papers/volume7/shimizu06a/shimizu06a.pdf\n\n\n\n\nNonlinear Models\nNonlinear additive noise setting\n\n\n\nhttps://papers.nips.cc/paper/2008/file/f7664060cc52bc6f3d620bcedc94a4b6-Paper.pdf\n\n\n\nNonlinear의 역할은 non-Gaussianity와 유사causal direction identify 가능\n⇒ 관측변수들의 symmetry를 깸\nnonlinear+additive noise yields identifiable models\n\nPost-Nonlinear setting\n\n→ noise가 additive로 들어가지 않는다면?\n\ngeneralization of the nonlinear additive model (mild assumption)\n\n\n\n\n\nhttps://arxiv.org/ftp/arxiv/papers/1205/1205.2599.pdf\n\n\n\n참고 자료 \n인과추론의 데이터과학 강의 : https://youtu.be/h1eMKb4iCTk"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html",
    "title": "Randomised Controlled Trial",
    "section": "",
    "text": "👉 해당 포스트는 아래 인과추론 자료를 바탕으로 정리했습니다. - 고수들의 계량경제학 1장 무작위 시행 - Causal Inference for the brave and true Chapter 2. Randomised Experiments / 한국어 번역 자료 - 인과추론의 데이터 과학\n\n\n\n\n\n배운내용을 어떻게 현업에서 활용할지 & 사례를 바탕으로 느낀점에 중점\n단순 책 내용을 요약하는 건 앞으로 실제 업무 활용 시, 도움이 안될 수 있으므로 본인만의 방식으로 재구조화\n\n\n\n\n목적 : 해당 챕터를 배우는 이유는 무엇일까?\n\n실험 디자인 시, 이상적이지만, Treatment 인과효과 추정에 가장 효과적인 방법\n\n\n\n\n내용 : 이번 챕터에서 어떤 메세지를 전달하려고 하는가?\n\n모집단을 가지고 실험을 하는 것은 현실적으로 어려움. 따라서, 모집단과 유사한 그룹 샘플 데이터를 바탕으로 Random Assignment 하는 것이 핵심\nRandomised Experiments 상황에서, Association = Causation\n\n결국, 유저를 랜덤하게 나눌 수 있는 환경이면, 복잡한 실험디자인 or 통계 모형을 사용하지 않아도 Causal Effect 추정이 가능\n\nRCT 이후에 배울 내용 IV, DID, RDD, Matching, Synthetic Control이 왜 필요한지 내포하는 챕터\n\n참고로, 위의 방법론은 실험 디자인을 잘 활용해서, 두 그룹을 비교 가능하게 만들어주는 방법\n\n\n\n\n\n느낀점 : 배운 내용을 어떻게 현업에서 적용해볼 수 있는가? 왜 적용이 어려울까?\n\n직관과 실험 : 어떻게 보면 당연한, 검증 작업에 직관보다는 실험이 필요하지만, 아래 상황들로 인해 여의치 않음\n조직 문화 : OCE (Online Controlled Experiment) 플랫폼을 구축하는 것은 혼자 할 수 없으며, 조직 차원에서 실험의 중요성을 이해하고 있어야 함\n\nNAVER Search A/B Test 플랫폼 [Blog Link] / [Video]\n오늘의 집 A/B 실험 플랫폼 구축기 [Link]\n\n리소스 : 이해 부서와 실험 설계를 같이하고 분석을 진행하는 것은 시간과 비용 소모가 큰 작업. 따라서, 실험 설계단계에서 각 조직의 성과 지표 Align이 되었는지 확인 필요\n유저 경험 : 동일 빌드에서 어떤 유저에게만 프로모션을 하는 것은 라이브 서비스 측면에서 안좋을 수 있음\n분석가의 고충\n\n기획/개발 단계에서 검증해야할 지표가 제대로 협의/논의되지 않음\nData Generating Process : 로그는 잘 남고 있을까?\n실험을 진행할 유저군이 랜덤하게 나뉘어지지 않음 (Selection Bias)\nConfounding Factor 제대로 통제하지 못하는 케이스가 존재 (기간 / 그룹특성)\n\n\n\n\n\n어려운점 : 어떤 부분이 해당 챕터를 다룰 때 어렵고 생소했나?\n\n도메인 지식 : 미국의 의료보험 체계 및 사회적인 배경을 잘 몰라서, 내용을 이해하는데 까다로웠음\n가설검정과 인과추론 : 어떤 부분에서 관련이 있는지 생각하는데, 시간을 많이 쏟음\n\n\n\n\n\n\n\n\n\n💡Causal Inference is concerned with a very specific kind of prediction problem\n\nPredicting the results of an action, manipulation, or Intervention - “Making Things Happen” (2003, Woodward)\n\n\n\n\n\n인과추론 (Causal Inference)이란 무엇일까?\n\n문제에 대한 원인을 찾고 해당 원인에 대한 효과를 추론하는 것\n즉, Treatment를 주었을 때, 이에 따른 Outcome이 어떻게 바뀌는지를 추정\n\n이벤트(Treatment)를 진행하면, 유저의 잔존율(Outcome)이 높아질까?\n\n\n\n\n\n그러면 ML과 무엇이 다른가? &lt; Causal Inference vs Machine Learning &gt;\n\nCausal Inference : Potential outcomes까지 고려\nMachine Learning : Observed outcomes만을 고려\n\n\n\n\n상관관계는 인과관계를 의미하지 않음. Why? Confounding Factors\n\n\n\nimg\n\n\n\n✅ Standard Approach & Causal Approach\n\n기본 접근 : \\(X\\)의 변화가 \\(Y\\)의 변화와 어떻게 연관되어 있는지 정량화하는데 관심\n\n\\(Y = β_0 + β_1X+ ε\\) → \\(E(Y|X=x+1) - E(Y|X=x)\\)\nRegression (Chapter 2)에서 다룰 기본적인 접근\n\n인과추론 접근 : \\(X\\) (원인)의 변화가 \\(Y\\)의 변화를 유발하는지를 확인하는데 관심\n\n해당 접근은 Y가 변하는 이유(원인)에 대한 질문에 답을 할 수 있음\n만약 \\(X\\)와 \\(Y\\)가 인과적으로 관계가 있다면, \\(Y\\)의 변화는 \\(X\\)의 변화로 설명 가능\n\n\n\n\n\n\n\n\n\n▶️ 건강보험이 건강에 미치는 인과효과 추정 &lt;고수들의 계량경제학 Chapter 1. 무작위 시행&gt;\n\n\n\n\n\n목적 : 보험 가입이 실험 대상에 미치는 영향을 2가지 관점에서 파악 → 실험 규모와 비용을 고려 시, 여러 가지의 목표 지표 설정이 가능하도록 설계 할 수 있음\n\n가설 1 : 보험 의료 가격이 감소하면, 실제로 의료 서비스를 더 사용할 것이다. → Yes\n가설 2 : 보험 가입을 통해, 건강 증진의 인과적 효과가 있을 것이다. → No\n\n\n\n\n\n\n\n배경 : 국가 정책을 위해, 영향을 받는 모든 국민을 대상으로 테스트하면 아래와 같은 문제 발생 할 수 있음\n\n국가적으로 너무나 큰 리소스가 들어가며 통제 하기 쉽지 않음\n또한, Random Assignment 과정에서 윤리적인 부분이 이슈가 될 수 있음\n\n\n\n\n목적 : 모집단 (Population)을 잘 반영하는 실험 유저군 (Sampling Group)을 적절히 샘플링\n\nSampling Bias 최소화\nApple to Apple (Random Assignment)\n\n\n\n\n실험 그룹 설계 : 올바른 실험설계를 통해, 목적에 맞는 인과효과를 추정하기 위함\n\n테스트 가능한 가설 설계 및 목표 지표 설계\n\nPrimary Index &lt;궁극적인 목표가 되는 지표&gt; : 지출한 의료비 / 건강 지표\nSecondary Index &lt;실험과 직접적 연관이 되는 지표&gt; : 부담 보험료\nGuardrail Index &lt;실험 과정에 부정적 영향을 받을 수 있는 지표&gt; : 건강 지표 푸시를 했는데 이탈하는 유저가 발생한 Nexon 사례\n\n\n\n\n실험군/대조군 설정 : 보험의 보장 수준 (가입자 부담 보험료 수준)에 따라 5개 상품으로 구분\n\nControl Group : 무보험 상태에 가까운 보험 수준을 가진 상품 (재난적 플랜)\nTreatment Group : 그 외 보험 보장이 되는 상품군 (4가지)\n\n\n\n\n방법 : 보험 미가입자를 대상으로 5개의 보험 상품에 Random Assignment\n\n\n\n그룹 검증 : 과연 랜덤하게 나눈 실험군과 대조군이 서로 비교 가능한가 (Ceteris Paribus)\n\n실험 대상 (유저/국민)을 대표할 수 있는 비교 변수 설정 (Ex. 나이/연령/과금 수준 등)\n통계적으로 유의미한 차이가 발생했는지 확인 → 상황에 따라 A/A 테스트 진행을 하기도 함\n표본의 수가 충분한지 (Law of Large Numbers 나온 배경) & 동일한 수준으로 제대로 나뉘었는지 체크 필요\n\n→ 해당 실험에서 그룹간 차이는 무시해도 되는 것으로 보여짐\n\n\n\n\n\n\n실험 진행 시 체크 사항\n\n지표 모니터링 : 실험이 진행되는 동안, 실험 대상/유저가 받게될 경험에 부정적인 요소가 있는지 & 실험에 영향을 주는 외부 요인이 있는지 모니터링\n로그 확인 : 실험 분석에 진행될 로그가 잘 쌓이고 있는지 확인\n\n\n\n\n실험 분석 : 리포트 및 실험 Dashboard 제공\n\n해당 실험을 통해, 유저의 경험을 어떤 측면에서 개선했는지 사전 설계 지표 및 실험 그룹을 바탕으로 성과 분석\n\n\n\n\n\n\n\n목적 :\n\n실험을 바탕으로 조직 내 의사결정에 활용 → 보험 가입이 건강 증진에 도움이 될까? No\n이번 실험에서 얻은 Insight와 보완점을 통해, 이후 실험 과정 개선\n(반복 실험이 가능하다면) 이를 바탕으로, 실험을 개선 결과의 신뢰성을 높이기 위해 노력\n\n\n\n\n건강 보험 실험 Feedback\n\n실험 설계의 문제 : 건강보험이라는 국가적 실험에서 완벽한 Random Assignment가 된 것이 맞을까?\n\nSampling Bias : 모집단 (실제로 보험에 가입하지 않은 사람들)과 샘플 그룹 (재난적 플랜에 가입된 Control Group) 간의 차이가 존재\nUnobserved Confounders : 관측된 인구통계 정보를 바탕으로 설계를 했을 때, 약간의 Sampling Bias 존재. 그렇다면, 관측되지 않은 변수에서는 해당 부분이 더 크게 나타날 수 있지 않을까?\nCensoring Issue : 실험 중도 이탈자 / 실험군이지만, 영향을 받지 않은 유저는 어떻게 처리를 했는가? 제외했다면 Selection Bias가 아닌가?\n\n\n\n\n결과의 유효성 : 보험 증진으로 건강 개선을 할 수 없었던 것이 맞을까?\n\n목표 지표 : 건강 지표는 과연 객관적으로 정량화가 가능한 부분인가?\n실험 개선 : 보험 가입에 의한 효과가 없다면 이후의 실험 개선은? 오리건의 건강 보험 실험\n\n\n\n\n\n\n\n\n\n\n목적 : 결국, 인과추론의 근본적인 문제를 이해하고 효과적으로 해결해나가기 위함\n\nTreatment : 접속 이벤트 참여 여부\n\n실험군 (Treatment Group) : 이벤트 참여에 배정된 유저군\n대조군 (Control Group) : 이벤트 참여에 배정되지 않은 유저군\n\nOutcome : 유저 잔존율\n\n비교 그룹간 유의미한 차이 (ATE, Average Treatment Effect)가 있는지 확인하는 지표\n\n\n\n\n\n문제 : Counterfactuals (Counter to fact, 일어나지 않은 상황을 가정)\n\n실험 진행 시, 유저는 참여/미참여 중 한 개의 상태로만 존재할 수 있음\n따라서, 실험 당시 미참여 유저가 그렇지 참여한 상황(실제로 일어나지 않음)을 가정\n하지만, 우리는 타임머신이 없기 때문에 동일한 유저에 대해서 2가지 사항을 관측 불가\n→ 인과추론의 근본적인 문제 \n\n\n\nimg\n\n\n\n\n\n\n\n\n하나의 실험 대상에 대해 Treatment에 대한 Potential Outcomes 모두 관찰 불가\n\nSelection Bias 발생하는 이유?\n\n인과추론 근본적인 문제 : Control Group ≠ Counterfactuals\n특성이 다른 다른 대상과 비교 시 Selection Bias가 발생 : &lt;쿠즈다르와 마리아 사례&gt;\n\n결국, 이 문제가 해결이 되어야 Treatment에 따른 인과적인 효과 파악이 가능\n\n\n\n\nIndividual Treatment Effect (ITE) : 개별 유저 i 에 대해 Treatment 처지 효과\n\n유저 i 에게는 2가지 Potential Outcomes이 존재\n\n\\(T = 1\\) : 이벤트 참여 / \\(T = 0\\) : 이벤트 미참여\n2가지 Potential Outcomes 중에서 하나만 존재할 수 있음\n유저 i 에 대한 개별 인과효과 (ITE)\n$ ITE = Y_{0i} - Y_{1i} $\n\n\nAverage Treatment Effect (ATE) : 유저 그룹에 대한 Treatment 처지 효과\n\n유저 개인화 관점에서는 ITE가 이상적이고 중요하지만, 대부분은 유저 그룹단위의 실험이 일반적이며 개개인에 대해 ITE를 파악할 수 없는 경우가 존재\n따라서, 유저 개인의 인과효과를 평균을 내어 집단 레벨에서 설명\n만약, 제대로 된 실험 설계를 하지 않고 ATE를 계산한다면? 아래와 같은 Selection Bias가 생김 &lt;Causal Inference for the brave and true Chapter1. 수식 참조&gt;\n\n$ E[Y|T=1] - E[Y|T=0] = E[Y_1|T=1] - E[Y_0|T=0] + E[Y_0|T=1] - E[Y_0|T=1] $\n$ E[Y|T=1] - E[Y|T=0] = {ATT} + $\n\n\n\n\n\n인과추론의 근본적인 문제를 바라보는 3가지 관점\n\nPotential Outcomes : 물음표 채우기\nStructural Causal Models : DAG\nRegression → 다음 챕터가 Regression인 이유!\n\n오차항 가정(Gaussian Assumption)과 내생성 (Endogenity) → 도구변수 참조\n\n\n\n\n\nSelection Bias 해결하기 위해 이번 챕터에서는 Random Assignment 도입\n\n즉, 실험 대상를 동전던지기로 나눠서 Treatment 여부를 결정\n\n\n\n\nRandom Assignment이 가장 좋은 방법이지만, Research Design 필요성 존재\n\n목적 :\n\n하지만, 항상 주어진 상황에서 RCT를 활용할 수 없는 경우가 많음\n위와 같은 경우, Counterfactual과 최대한 비슷한 Control Group를 실험 디자인을 통해 찾아나가야 함 ↔︎ Selection Bias 줄이기\n\n\n\n\n실험 디자인 방법론 (To be continued)\n\nInstrumental Varibles (2SLS / Regression, Chapter 3)\nRDD (Regression Discontinuity Design, Chapter 4)\nDID (Difference In Difference, Chapter 5)\nSynthetic Control\n\n\n\n\n\n\n\nLLN (Law of Large Numbers) 나오게 된 배경\n\n결국 모집단을 잘 대표하는 표본(Sample)을 선정하기 위해, 충분한 수의 표본이 필요\n궁극적으로, 실험군과 대조군은 동일한 모집단에서 생성 → 그룹간에 비교 가능한 특성을 가져야함 → 해당 조건 달성을 위해서는 충분한 표본이 필요\n과연 Sample Size는 어떤 수준이 적절할까?\n\nStatistical Power(검정력)과 Sample Size\nProduct Active User 규모를 고려\n\n\n\n\n\nHypothesis Testing\n\n목적 : 모집단 (Population Data)의 특성에 대해 설계한 통계적 가설 (\\(H_0\\) / \\(H_1\\))을 모집단의 추출한 샘플 데이터 (Sample Data)를 이용해 검증하는 과정\n인과추론과 가설 검정 : 결국, 인과적인 효과를 추정하기 위해 모집단의 데이터를 활용하는 것보다는 샘플 데이터를 이용해, 개입 (Intervention)에 따른 효과가 있는지 검증\n\n그래서, 후반부에 가설 검정 T-test ↔︎ Two Sample T-test (↔︎ Hausman Test)이 나오게된 것 같음\n\n\n\n\n\n\n\n\nA/B 테스트를 할 수 있는 오픈 소스 및 자료\n\n자체 OCE (Online Controlled Experiment) 플랫폼이 있다면 최적의 환경\n실제로 3rd Party 툴 (Amplitude / Braze / Firebase 등)을 통해서 A/B Test를 해볼 수 있음\nGrowthBook과 같이 잘 알려진 오픈 소스를 통해, 현업에 적용이 가능\n오픈 소스 정리자료 링크 : https://posthog.com/blog/best-open-source-ab-testing-tools\n\n\n\n\n실험 플랫폼\n\n직관이 아닌 실험으로의 의사결정은 조직에서 매우 중요한 과제\n참고 도서 : 실리콘밸리의 실험\n\n\n\n\n\n\n(종언) 실험에 사용할 샘플 사이즈는 어떻게 가져가는게 좋을까요?\n\n(이삭) : 통계학적인 방법으로는 Statistical Power과 샘플 사이즈가 양의 상관관계가 있어, 검정력을 기준으로 샘플 사이즈가 적절한지 판단하는 것 같습니다,\n(소희) : 적정 샘플 사이즈를 계산해주는 사이트를 사용해봤어요.\n(진수) : 오히려 너무 적은 극단적인 케이스는 Bias가 많고 일반적으로 정상적인 범주에서 벗어났다고 생각해, 실험 대상으로는 제외했던 기억이 있습니다. 원론적인 답변이지만 항상 Product의 Active User 수를 고려해야 할 것 같습니다.\n\n\n\n\n(이삭) 의료 보험 가입으로 건강 증진의 효과를 얻지 못했는데, 미국의 사례여서 그런걸까요?\n\n(정현) : 의료 보험 체계가 다르지만 한국도 비슷하지 않을까 싶습니다. 그런데 실험을 해보지 않아서 직관적인 판단에 주의해야할 것 같아요.\n\n\n\n\n\n\n고수들의 계량경제학 Chapter 1. 무작위 시행 &lt;Joshua D. Angrist , Jorn-Steffen Pischke 저&gt;\nCausal Inference for the brave and true Chapter 1. Introduction to Causality \nKorea Summer Workshop on Causal Inference 2022\nIntroduction to Causal Inference\n유 퀴즈 온 더 블럭 - 구준엽편"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#chapter-summary",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#chapter-summary",
    "title": "Randomised Controlled Trial",
    "section": "",
    "text": "배운내용을 어떻게 현업에서 활용할지 & 사례를 바탕으로 느낀점에 중점\n단순 책 내용을 요약하는 건 앞으로 실제 업무 활용 시, 도움이 안될 수 있으므로 본인만의 방식으로 재구조화\n\n\n\n\n목적 : 해당 챕터를 배우는 이유는 무엇일까?\n\n실험 디자인 시, 이상적이지만, Treatment 인과효과 추정에 가장 효과적인 방법\n\n\n\n\n내용 : 이번 챕터에서 어떤 메세지를 전달하려고 하는가?\n\n모집단을 가지고 실험을 하는 것은 현실적으로 어려움. 따라서, 모집단과 유사한 그룹 샘플 데이터를 바탕으로 Random Assignment 하는 것이 핵심\nRandomised Experiments 상황에서, Association = Causation\n\n결국, 유저를 랜덤하게 나눌 수 있는 환경이면, 복잡한 실험디자인 or 통계 모형을 사용하지 않아도 Causal Effect 추정이 가능\n\nRCT 이후에 배울 내용 IV, DID, RDD, Matching, Synthetic Control이 왜 필요한지 내포하는 챕터\n\n참고로, 위의 방법론은 실험 디자인을 잘 활용해서, 두 그룹을 비교 가능하게 만들어주는 방법\n\n\n\n\n\n느낀점 : 배운 내용을 어떻게 현업에서 적용해볼 수 있는가? 왜 적용이 어려울까?\n\n직관과 실험 : 어떻게 보면 당연한, 검증 작업에 직관보다는 실험이 필요하지만, 아래 상황들로 인해 여의치 않음\n조직 문화 : OCE (Online Controlled Experiment) 플랫폼을 구축하는 것은 혼자 할 수 없으며, 조직 차원에서 실험의 중요성을 이해하고 있어야 함\n\nNAVER Search A/B Test 플랫폼 [Blog Link] / [Video]\n오늘의 집 A/B 실험 플랫폼 구축기 [Link]\n\n리소스 : 이해 부서와 실험 설계를 같이하고 분석을 진행하는 것은 시간과 비용 소모가 큰 작업. 따라서, 실험 설계단계에서 각 조직의 성과 지표 Align이 되었는지 확인 필요\n유저 경험 : 동일 빌드에서 어떤 유저에게만 프로모션을 하는 것은 라이브 서비스 측면에서 안좋을 수 있음\n분석가의 고충\n\n기획/개발 단계에서 검증해야할 지표가 제대로 협의/논의되지 않음\nData Generating Process : 로그는 잘 남고 있을까?\n실험을 진행할 유저군이 랜덤하게 나뉘어지지 않음 (Selection Bias)\nConfounding Factor 제대로 통제하지 못하는 케이스가 존재 (기간 / 그룹특성)\n\n\n\n\n\n어려운점 : 어떤 부분이 해당 챕터를 다룰 때 어렵고 생소했나?\n\n도메인 지식 : 미국의 의료보험 체계 및 사회적인 배경을 잘 몰라서, 내용을 이해하는데 까다로웠음\n가설검정과 인과추론 : 어떤 부분에서 관련이 있는지 생각하는데, 시간을 많이 쏟음"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#introduction-to-causal-inference",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#introduction-to-causal-inference",
    "title": "Randomised Controlled Trial",
    "section": "",
    "text": "💡Causal Inference is concerned with a very specific kind of prediction problem\n\nPredicting the results of an action, manipulation, or Intervention - “Making Things Happen” (2003, Woodward)\n\n\n\n\n\n인과추론 (Causal Inference)이란 무엇일까?\n\n문제에 대한 원인을 찾고 해당 원인에 대한 효과를 추론하는 것\n즉, Treatment를 주었을 때, 이에 따른 Outcome이 어떻게 바뀌는지를 추정\n\n이벤트(Treatment)를 진행하면, 유저의 잔존율(Outcome)이 높아질까?\n\n\n\n\n\n그러면 ML과 무엇이 다른가? &lt; Causal Inference vs Machine Learning &gt;\n\nCausal Inference : Potential outcomes까지 고려\nMachine Learning : Observed outcomes만을 고려\n\n\n\n\n상관관계는 인과관계를 의미하지 않음. Why? Confounding Factors\n\n\n\nimg\n\n\n\n✅ Standard Approach & Causal Approach\n\n기본 접근 : \\(X\\)의 변화가 \\(Y\\)의 변화와 어떻게 연관되어 있는지 정량화하는데 관심\n\n\\(Y = β_0 + β_1X+ ε\\) → \\(E(Y|X=x+1) - E(Y|X=x)\\)\nRegression (Chapter 2)에서 다룰 기본적인 접근\n\n인과추론 접근 : \\(X\\) (원인)의 변화가 \\(Y\\)의 변화를 유발하는지를 확인하는데 관심\n\n해당 접근은 Y가 변하는 이유(원인)에 대한 질문에 답을 할 수 있음\n만약 \\(X\\)와 \\(Y\\)가 인과적으로 관계가 있다면, \\(Y\\)의 변화는 \\(X\\)의 변화로 설명 가능"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#experiment-key-takeaway",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#experiment-key-takeaway",
    "title": "Randomised Controlled Trial",
    "section": "",
    "text": "▶️ 건강보험이 건강에 미치는 인과효과 추정 &lt;고수들의 계량경제학 Chapter 1. 무작위 시행&gt;\n\n\n\n\n\n목적 : 보험 가입이 실험 대상에 미치는 영향을 2가지 관점에서 파악 → 실험 규모와 비용을 고려 시, 여러 가지의 목표 지표 설정이 가능하도록 설계 할 수 있음\n\n가설 1 : 보험 의료 가격이 감소하면, 실제로 의료 서비스를 더 사용할 것이다. → Yes\n가설 2 : 보험 가입을 통해, 건강 증진의 인과적 효과가 있을 것이다. → No\n\n\n\n\n\n\n\n배경 : 국가 정책을 위해, 영향을 받는 모든 국민을 대상으로 테스트하면 아래와 같은 문제 발생 할 수 있음\n\n국가적으로 너무나 큰 리소스가 들어가며 통제 하기 쉽지 않음\n또한, Random Assignment 과정에서 윤리적인 부분이 이슈가 될 수 있음\n\n\n\n\n목적 : 모집단 (Population)을 잘 반영하는 실험 유저군 (Sampling Group)을 적절히 샘플링\n\nSampling Bias 최소화\nApple to Apple (Random Assignment)\n\n\n\n\n실험 그룹 설계 : 올바른 실험설계를 통해, 목적에 맞는 인과효과를 추정하기 위함\n\n테스트 가능한 가설 설계 및 목표 지표 설계\n\nPrimary Index &lt;궁극적인 목표가 되는 지표&gt; : 지출한 의료비 / 건강 지표\nSecondary Index &lt;실험과 직접적 연관이 되는 지표&gt; : 부담 보험료\nGuardrail Index &lt;실험 과정에 부정적 영향을 받을 수 있는 지표&gt; : 건강 지표 푸시를 했는데 이탈하는 유저가 발생한 Nexon 사례\n\n\n\n\n실험군/대조군 설정 : 보험의 보장 수준 (가입자 부담 보험료 수준)에 따라 5개 상품으로 구분\n\nControl Group : 무보험 상태에 가까운 보험 수준을 가진 상품 (재난적 플랜)\nTreatment Group : 그 외 보험 보장이 되는 상품군 (4가지)\n\n\n\n\n방법 : 보험 미가입자를 대상으로 5개의 보험 상품에 Random Assignment\n\n\n\n그룹 검증 : 과연 랜덤하게 나눈 실험군과 대조군이 서로 비교 가능한가 (Ceteris Paribus)\n\n실험 대상 (유저/국민)을 대표할 수 있는 비교 변수 설정 (Ex. 나이/연령/과금 수준 등)\n통계적으로 유의미한 차이가 발생했는지 확인 → 상황에 따라 A/A 테스트 진행을 하기도 함\n표본의 수가 충분한지 (Law of Large Numbers 나온 배경) & 동일한 수준으로 제대로 나뉘었는지 체크 필요\n\n→ 해당 실험에서 그룹간 차이는 무시해도 되는 것으로 보여짐\n\n\n\n\n\n\n실험 진행 시 체크 사항\n\n지표 모니터링 : 실험이 진행되는 동안, 실험 대상/유저가 받게될 경험에 부정적인 요소가 있는지 & 실험에 영향을 주는 외부 요인이 있는지 모니터링\n로그 확인 : 실험 분석에 진행될 로그가 잘 쌓이고 있는지 확인\n\n\n\n\n실험 분석 : 리포트 및 실험 Dashboard 제공\n\n해당 실험을 통해, 유저의 경험을 어떤 측면에서 개선했는지 사전 설계 지표 및 실험 그룹을 바탕으로 성과 분석\n\n\n\n\n\n\n\n목적 :\n\n실험을 바탕으로 조직 내 의사결정에 활용 → 보험 가입이 건강 증진에 도움이 될까? No\n이번 실험에서 얻은 Insight와 보완점을 통해, 이후 실험 과정 개선\n(반복 실험이 가능하다면) 이를 바탕으로, 실험을 개선 결과의 신뢰성을 높이기 위해 노력\n\n\n\n\n건강 보험 실험 Feedback\n\n실험 설계의 문제 : 건강보험이라는 국가적 실험에서 완벽한 Random Assignment가 된 것이 맞을까?\n\nSampling Bias : 모집단 (실제로 보험에 가입하지 않은 사람들)과 샘플 그룹 (재난적 플랜에 가입된 Control Group) 간의 차이가 존재\nUnobserved Confounders : 관측된 인구통계 정보를 바탕으로 설계를 했을 때, 약간의 Sampling Bias 존재. 그렇다면, 관측되지 않은 변수에서는 해당 부분이 더 크게 나타날 수 있지 않을까?\nCensoring Issue : 실험 중도 이탈자 / 실험군이지만, 영향을 받지 않은 유저는 어떻게 처리를 했는가? 제외했다면 Selection Bias가 아닌가?\n\n\n\n\n결과의 유효성 : 보험 증진으로 건강 개선을 할 수 없었던 것이 맞을까?\n\n목표 지표 : 건강 지표는 과연 객관적으로 정량화가 가능한 부분인가?\n실험 개선 : 보험 가입에 의한 효과가 없다면 이후의 실험 개선은? 오리건의 건강 보험 실험"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#theoretical-backgroud",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#theoretical-backgroud",
    "title": "Randomised Controlled Trial",
    "section": "",
    "text": "목적 : 결국, 인과추론의 근본적인 문제를 이해하고 효과적으로 해결해나가기 위함\n\nTreatment : 접속 이벤트 참여 여부\n\n실험군 (Treatment Group) : 이벤트 참여에 배정된 유저군\n대조군 (Control Group) : 이벤트 참여에 배정되지 않은 유저군\n\nOutcome : 유저 잔존율\n\n비교 그룹간 유의미한 차이 (ATE, Average Treatment Effect)가 있는지 확인하는 지표\n\n\n\n\n\n문제 : Counterfactuals (Counter to fact, 일어나지 않은 상황을 가정)\n\n실험 진행 시, 유저는 참여/미참여 중 한 개의 상태로만 존재할 수 있음\n따라서, 실험 당시 미참여 유저가 그렇지 참여한 상황(실제로 일어나지 않음)을 가정\n하지만, 우리는 타임머신이 없기 때문에 동일한 유저에 대해서 2가지 사항을 관측 불가\n→ 인과추론의 근본적인 문제 \n\n\n\nimg\n\n\n\n\n\n\n\n\n하나의 실험 대상에 대해 Treatment에 대한 Potential Outcomes 모두 관찰 불가\n\nSelection Bias 발생하는 이유?\n\n인과추론 근본적인 문제 : Control Group ≠ Counterfactuals\n특성이 다른 다른 대상과 비교 시 Selection Bias가 발생 : &lt;쿠즈다르와 마리아 사례&gt;\n\n결국, 이 문제가 해결이 되어야 Treatment에 따른 인과적인 효과 파악이 가능\n\n\n\n\nIndividual Treatment Effect (ITE) : 개별 유저 i 에 대해 Treatment 처지 효과\n\n유저 i 에게는 2가지 Potential Outcomes이 존재\n\n\\(T = 1\\) : 이벤트 참여 / \\(T = 0\\) : 이벤트 미참여\n2가지 Potential Outcomes 중에서 하나만 존재할 수 있음\n유저 i 에 대한 개별 인과효과 (ITE)\n$ ITE = Y_{0i} - Y_{1i} $\n\n\nAverage Treatment Effect (ATE) : 유저 그룹에 대한 Treatment 처지 효과\n\n유저 개인화 관점에서는 ITE가 이상적이고 중요하지만, 대부분은 유저 그룹단위의 실험이 일반적이며 개개인에 대해 ITE를 파악할 수 없는 경우가 존재\n따라서, 유저 개인의 인과효과를 평균을 내어 집단 레벨에서 설명\n만약, 제대로 된 실험 설계를 하지 않고 ATE를 계산한다면? 아래와 같은 Selection Bias가 생김 &lt;Causal Inference for the brave and true Chapter1. 수식 참조&gt;\n\n$ E[Y|T=1] - E[Y|T=0] = E[Y_1|T=1] - E[Y_0|T=0] + E[Y_0|T=1] - E[Y_0|T=1] $\n$ E[Y|T=1] - E[Y|T=0] = {ATT} + $\n\n\n\n\n\n인과추론의 근본적인 문제를 바라보는 3가지 관점\n\nPotential Outcomes : 물음표 채우기\nStructural Causal Models : DAG\nRegression → 다음 챕터가 Regression인 이유!\n\n오차항 가정(Gaussian Assumption)과 내생성 (Endogenity) → 도구변수 참조\n\n\n\n\n\nSelection Bias 해결하기 위해 이번 챕터에서는 Random Assignment 도입\n\n즉, 실험 대상를 동전던지기로 나눠서 Treatment 여부를 결정\n\n\n\n\nRandom Assignment이 가장 좋은 방법이지만, Research Design 필요성 존재\n\n목적 :\n\n하지만, 항상 주어진 상황에서 RCT를 활용할 수 없는 경우가 많음\n위와 같은 경우, Counterfactual과 최대한 비슷한 Control Group를 실험 디자인을 통해 찾아나가야 함 ↔︎ Selection Bias 줄이기\n\n\n\n\n실험 디자인 방법론 (To be continued)\n\nInstrumental Varibles (2SLS / Regression, Chapter 3)\nRDD (Regression Discontinuity Design, Chapter 4)\nDID (Difference In Difference, Chapter 5)\nSynthetic Control\n\n\n\n\n\n\n\nLLN (Law of Large Numbers) 나오게 된 배경\n\n결국 모집단을 잘 대표하는 표본(Sample)을 선정하기 위해, 충분한 수의 표본이 필요\n궁극적으로, 실험군과 대조군은 동일한 모집단에서 생성 → 그룹간에 비교 가능한 특성을 가져야함 → 해당 조건 달성을 위해서는 충분한 표본이 필요\n과연 Sample Size는 어떤 수준이 적절할까?\n\nStatistical Power(검정력)과 Sample Size\nProduct Active User 규모를 고려\n\n\n\n\n\nHypothesis Testing\n\n목적 : 모집단 (Population Data)의 특성에 대해 설계한 통계적 가설 (\\(H_0\\) / \\(H_1\\))을 모집단의 추출한 샘플 데이터 (Sample Data)를 이용해 검증하는 과정\n인과추론과 가설 검정 : 결국, 인과적인 효과를 추정하기 위해 모집단의 데이터를 활용하는 것보다는 샘플 데이터를 이용해, 개입 (Intervention)에 따른 효과가 있는지 검증\n\n그래서, 후반부에 가설 검정 T-test ↔︎ Two Sample T-test (↔︎ Hausman Test)이 나오게된 것 같음"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#ab-테스트-open-source",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#ab-테스트-open-source",
    "title": "Randomised Controlled Trial",
    "section": "",
    "text": "A/B 테스트를 할 수 있는 오픈 소스 및 자료\n\n자체 OCE (Online Controlled Experiment) 플랫폼이 있다면 최적의 환경\n실제로 3rd Party 툴 (Amplitude / Braze / Firebase 등)을 통해서 A/B Test를 해볼 수 있음\nGrowthBook과 같이 잘 알려진 오픈 소스를 통해, 현업에 적용이 가능\n오픈 소스 정리자료 링크 : https://posthog.com/blog/best-open-source-ab-testing-tools\n\n\n\n\n실험 플랫폼\n\n직관이 아닌 실험으로의 의사결정은 조직에서 매우 중요한 과제\n참고 도서 : 실리콘밸리의 실험"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#q-a",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#q-a",
    "title": "Randomised Controlled Trial",
    "section": "",
    "text": "(종언) 실험에 사용할 샘플 사이즈는 어떻게 가져가는게 좋을까요?\n\n(이삭) : 통계학적인 방법으로는 Statistical Power과 샘플 사이즈가 양의 상관관계가 있어, 검정력을 기준으로 샘플 사이즈가 적절한지 판단하는 것 같습니다,\n(소희) : 적정 샘플 사이즈를 계산해주는 사이트를 사용해봤어요.\n(진수) : 오히려 너무 적은 극단적인 케이스는 Bias가 많고 일반적으로 정상적인 범주에서 벗어났다고 생각해, 실험 대상으로는 제외했던 기억이 있습니다. 원론적인 답변이지만 항상 Product의 Active User 수를 고려해야 할 것 같습니다.\n\n\n\n\n(이삭) 의료 보험 가입으로 건강 증진의 효과를 얻지 못했는데, 미국의 사례여서 그런걸까요?\n\n(정현) : 의료 보험 체계가 다르지만 한국도 비슷하지 않을까 싶습니다. 그런데 실험을 해보지 않아서 직관적인 판단에 주의해야할 것 같아요."
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#reference",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#reference",
    "title": "Randomised Controlled Trial",
    "section": "",
    "text": "고수들의 계량경제학 Chapter 1. 무작위 시행 &lt;Joshua D. Angrist , Jorn-Steffen Pischke 저&gt;\nCausal Inference for the brave and true Chapter 1. Introduction to Causality \nKorea Summer Workshop on Causal Inference 2022\nIntroduction to Causal Inference\n유 퀴즈 온 더 블럭 - 구준엽편"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Estimation/Estimation.html",
    "href": "posts/Introduction_to_causal_inference_Estimation/Estimation.html",
    "title": "08. Estimation",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀의 남궁민상입니다.\nIntroduction to Causal Inference 강의의 일곱 번째 챕터이며, 해당 챕터에서 다루는 내용은 아래와 같습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#cate",
    "href": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#cate",
    "title": "08. Estimation",
    "section": "CATE",
    "text": "CATE\n\nATE\n\\[[\\tau(x) \\overset{\\Delta}{=}\\mathbb{E}[Y(1)-Y(0)\\,|\\,X=x]]\\]\nAssuming uncounfoundedness and positivity\n\\[[\\tau \\overset{\\Delta}{=} \\mathbb{E}[Y(1)-Y(0)]=\\mathbb{E}_W[\\mathbb{E}[Y\\,|\\, T=1,W]-\\mathbb{E}[Y\\,|\\, T=0,W]]]\\]\nGiven W is a sufficient adjustment set\n\n\nCATE\n\\[\n\\begin{aligned}\n\\tau(x) &\\overset{\\Delta}{=} \\mathbb{E}[Y(1)-Y(0)\\,\\|\\,X=x] \\\\\\\n&=\\mathbb{E}_W[\\mathbb{E}[Y\\,\\|\\, T=1,X=x,W]-\\mathbb{E}[Y\\,\\|\\, T=0,X=x,W]]\n\\end{aligned}\n\\]\ngiven \\(W \\cup X\\) is a sufficient adjustment set\n[개념정리]\n\nunconfoundedness = conditional exchangeability(ignorability)\n\n\\((Y(0),Y(1)) \\perp T\\,|\\,X\\)\n이 조건으로 인해 potential outcome을 treatment에 conditioning할 수 있음\\[ \\begin{aligned} \\mathbb{E}[Y(1)-Y(0)|X] &= \\mathbb{E}[Y(1)|X]- \\mathbb{E}[Y(0)|X] \\\\ &= \\mathbb{E}[Y(1)|T=1,X]- \\mathbb{E}[Y(0)|T=0,X] \\\\ &= \\mathbb{E}[Y|T=1,X]- \\mathbb{E}[Y|T=0,X] \\end{aligned} \\]\n\npositivity\n\n\\(0&lt;P(T=1\\,|\\,X=x)&lt;1\\), \\(P(X=x)&gt;0\\), x for all \\(x\\)"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#com",
    "href": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#com",
    "title": "08. Estimation",
    "section": "COM",
    "text": "COM\nTarget of modeling: the conditional expectations of CATE\n\n\\(\\mu(1,W) = \\mathbb{E}[Y\\,|\\, T=1,W]\\)\n\\(\\mu(0,W) = \\mathbb{E}[Y\\,|\\, T=0,W]\\)\n\n일반적으로 사용하는 대부분의 예측모델 사용 가능\n\nCOM estimation of ATE\n\n[ = _i[(1,w_i)-(0,w_i)] ]\n\nCOM estimation of CATE\n\n\\[ \\begin{aligned} \\tau(x) &\\overset{\\Delta}{=} \\mathbb{E}[Y(1)-Y(0)\\,|\\,X=x] \\\\ &=\\mathbb{E}_W[\\mathbb{E}[Y\\,|\\, T=1,X=x,W]-\\mathbb{E}[Y\\,|\\, T=0,X=x,W]] \\end{aligned}\\]\ntarget of modeling:\n\\[ \\mu(t,x,w) \\overset{\\Delta}{=}\\mathbb{E}[Y\\,|\\, T=t,X=x,W=w] \\]\nCOM estimator of CATE:\n\\[ \\hat\\tau(x) = \\frac{1}{n_x}\\sum_{i:x_i=x}[\\hat\\mu(1,x,w_i)-\\hat\\mu(0,x,w_i)] \\]\nProblem with COM estimation in high dimensions\n\n매우 차원이 높은 (input 변수가 많은) 경우, T의 영향력이 다른 변수 W들에 비해 크지 않으면 T에 대한 weight 역시 매우 작은 값으로 추정된다.\n\\(\\hat\\mu(1,w_i)-\\hat\\mu(0,w_i)\\) 가 0에 매우 가까워짐\n결론: 실제 treatment effect가 존재하더라도, scale의 차이 때문에 treatment 추정치는 0에 편향될 수 있음\n\nSolution: Grouped COM (GCOM) estimation\n\nCOM: \\(\\hat\\tau = \\frac{1}{n}\\sum_i[\\hat\\mu(1,w_i)-\\hat\\mu(0,w_i)]\\)\nGCOM: \\(\\hat\\tau = \\frac{1}{n}\\sum_i[\\hat\\mu_1(w_i)-\\hat\\mu_0(w_i)]\\)\n\nGCOM의 경우, T는 모델의 input으로 들어가지 않음\nProblem: models have higher variance than they would if they were trained with all the data (since the splitted data might not efficient)"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#increasing-data-efficiency-tarnet-x-learner",
    "href": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#increasing-data-efficiency-tarnet-x-learner",
    "title": "08. Estimation",
    "section": "Increasing Data Efficiency: TARNet & X-Learner",
    "text": "Increasing Data Efficiency: TARNet & X-Learner\nTARNet\n\n\nNN 기반인거 같은데,\n\n중간 모델: treatment-agnostic model; \\(\\hat \\mu\\)\nbranch model: treatment-specific model; T=1 데이터, T=0인 데이터만으로 학습됨\n\n전체 모델이 모든 데이터를 활용해 학습되는 것이 아니므로 여전히 data inefficiency 존재\n\nX-Learner\n\nEstimate \\(\\hat \\mu_1(x)\\) and \\(\\hat \\mu_0(x)\\) (assume \\(X\\) is a sufficient adjustment set and is all observed covariates)\nImpute ITEs\n\nTreatment group: \\(\\hat \\tau_{1,i}= Y_i(1)-\\hat \\mu_0(x_i)\\)\nControl group: \\(\\hat \\tau_{0,i}= \\hat \\mu_1(x_i) - Y_0(1)\\)\n\nFit a model \\(\\hat \\tau_1(x)\\) to predict \\(\\hat \\tau_{1,i}\\) from \\(x_i\\) in treatment group Fit a model \\(\\hat \\tau_0(x)\\) to predict \\(\\hat \\tau_{0,i}\\) from \\(x_i\\) in control group → \\(\\hat \\tau_1(x)\\), \\(\\hat \\tau_0(x)\\)는 treatment/control group의 모든 데이터를 사용한 모델 (GCOM의 문제 해결)\n\\(\\hat \\tau(x)=g(x)\\hat \\tau_0(x) + (1-g(x))\\hat \\tau_1(x)\\) where \\(g(x)\\) is a weight function btw 0 and 1 (e.g., propensity score)"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#propensity-score-ipw",
    "href": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#propensity-score-ipw",
    "title": "08. Estimation",
    "section": "Propensity Score & IPW",
    "text": "Propensity Score & IPW\n지금까지는 \\(\\mu(t,w)\\)를 모델링하여 estimation을 했습니다. 그 다음으로는 경향 점수(propensity score)라는 것을 이용한 estimation을 알아봅시다.\n\n경향 점수(Propensity score)란?\n수학적으로 말하자면 경향 점수 \\(e(w)\\)는 다음과 같은 스칼라 값입니다.\n\\[ e(w) \\triangleq P(T=1\\:|\\:W=w) \\]\n우리가 \\(W=w\\)인 임의의 사례를 골랐을 때, 해당 케이스가 처치 집단\\((T=1)\\)일 조건부 확률이죠.\n그리고 propensity score theorem에 따르면 다음과 같은 식이 성립합니다.\n\\[ (Y(1), Y(0))\\:{\\perp \\!\\!\\! \\perp}\\:T\\:|\\:W \\Rightarrow (Y(1), Y(0))\\:{\\perp \\!\\!\\! \\perp}\\:T\\:|\\:e(W) \\]\n문자 그대로 풀어 쓰자면, \\(W\\)를 conditioning 했을 때 positivity, unconfoundedness가 성립한다면, \\(e(W)\\)를 conditioning 했을 때도 positivity, unconfoundedness가 성립한다는 정리입니다.\n이게 왜 중요할까요? Chapter 2에서, ATE가 association difference와 같아지려면 positivity, unconfoundedness가 성립해야 했습니다. Propensity score Theorem에 따르면 \\(W\\)를 conditioning 해서 ATE를 구할 수 있다면, \\(e(W)\\)를 conditioning 했을 때도 ATE를 구할 수 있게 된 거죠!\n아래 그래프를 보면 이해가 쉽습니다.\n\n왼쪽 그림에서 \\(W\\)는 \\(T\\)에 causal effect를 가집니다. 그 effect는 \\(e(W)\\)와 같으므로 오른쪽과 같이 그릴 수도 있겠죠? (\\(e(W)\\)가 \\(W \\rightarrow T\\)의 full mediator)\n따라서 \\(W\\)를 conditioning해서 backdoor를 막을 수 있다면, \\(e(W)\\)를 conditioining해서도 같은 효과를 가지게 됩니다.\n물론 수식을 길게 늘어놓아 증명할 수도 있습니다!\n\\[ \\begin{aligned}P(T=1\\:|\\:Y(t),\\:e(W))\\:&=\\:E[T \\:|\\:Y(t),\\:e(W)] \\\\ &=E[E[T \\:|\\:Y(t),\\:e(W),W]\\:|\\:Y(t),e(W)] \\\\ &= E[E[T \\:|\\:Y(t),W]\\:|\\:Y(t),e(W)] \\\\ &= E[E[T \\:|\\:W]\\:|\\:Y(t),e(W)] \\\\ &= E[P(T=1\\:|\\:W)\\:|\\:Y(t),e(W)] \\\\ &= E[e(W)\\:|\\:Y(t),e(W)] \\\\ &= e(W)\\end{aligned} \\]\n이 값이 \\(Y(t)\\)와 독립이므로\\((Y(1), Y(0)){\\perp \\!\\!\\! \\perp}T\\|e(W)\\)입니다.\n\n앞선 챕터에서 positivity-unconfoundedness tradeoff를 이야기했는데, 기억 나시나요?.\n비교집단과 처치집단을 제대로 비교하려면 같은 \\(W\\)를 가진 집단을 비교해야 합니다. 그런데 \\(W\\)의 차원이 높아지면 positivity가 심각하게 줄어들죠.\n그런데 \\(W\\)의 차원이 아무리 높아져도 \\(e(W)\\)는 1차원의 스칼라입니다. 따라서 \\(e(W)\\)를 conditioning하면 이 문제를 마법처럼 해결할 수 있는 거죠! 와!\n물론 세상은 그렇게 아름답지 않습니다. 대부분의 경우에 우리는 \\(e(W)\\) 함수를 알 수 없거든요. 보통은 모델을 학습시켜 \\(e(W=w)\\)를 구합니다.\n\n기억합시다!\n경향 점수는 covariate로부터 계산하는 스칼라값입니다. unbiased estimate of ATE를 구하고 싶을 때, 고차원의 \\(W\\)를 conditioning하는 대신 1차원의 \\(e(W)\\)를 conditioning하여 같은 효과를 얻을 수 있습니다.\n\n\n\nInverse Probability Weighting\n다음으로 IPW에 대해 알아봅시다. 관측을 통해 association은 쉽게 계산할 수 있습니다. 하지만 우리가 원하는 것은 이로부터 causation을 뽑아내는 것이죠. 그런데 association == causation이도록 데이터를 resampling하는 방법이 있습니다. \n\n\\(W\\rightarrow T\\)의 인과가 존재한다는 것은 \\(T\\)의 분포가 \\(W\\)에 의해 영향을 받는다는 뜻이죠. 수학적으로 나타내자면 \\(P(T\\:|\\:W) \\neq P(T)\\). 그렇다면 이를 뒤집으면 어떨까요?\n\n\\(P(T\\:|\\:W) = P(T)\\)인 경우\n\\(P(T\\:|\\:W)\\)가 상수인 경우\n\n위와 같은 경우에는 \\(W\\)가 \\(T\\)의 분포에 영향을 주지 않습니다. 따라서 \\(T\\)와 \\(Y\\) 사이의 association은 곧 causation이겠죠.\n\n정리!\n\\(P(T|W)\\)가 상수라면 \\(W=w\\) 값이 바뀌어도 \\(T=t\\)의 분포에 영향을 주지 않습니다. 따라서, 데이터에 \\(\\frac{1}{P(t|W)}\\)를 곱해 만든 pseudo-population에서는 \\(W\\rightarrow (T=t)\\)의 인과가 끊어집니다. (이 pseudo-population에서의\n\\(P(T=t|W)=1\\)이니까요)\n그래서 \\((T=t) \\rightarrow Y\\)의 인과를 계산할 수 있습니다.\n\n이를 수학적으로 나타내면\n\\[ E[Y(t)]=E[\\frac{\\mathbb{1}(T=t)\\:Y}{P(t|W)}] \\]\n마찬가지로 수식으로 증명할 수도 있습니다!\n\\[ \\begin{aligned} E[Y(t)] &= E[E[Y\\:|\\:t,W]] \\\\ &= \\sum_{w}{(\\sum_{y}{yP(y\\:|\\:t,w)})P(w)} \\\\ &= \\sum_{w}{\\sum_{y}{yP(y\\:|\\:t,w)}P(w)\\frac{P(t\\:|\\:w)}{P(t\\:|\\:w)}} \\\\ &= \\sum_{w}{\\sum_{y}{yP(y,t,w)}\\frac{1}{P(t\\:|\\:w)}} \\\\ &= \\sum_{w}{E[1(T=t,W=w)Y]\\frac{1}{P(t|w)}} \\\\ &= E[\\frac{1(T=t)\\:Y}{P(t|W)}]\\end{aligned} \\]\n그런데 잠깐, re-weighting할 때 쓰는 \\(P(T=t\\:|\\:W)\\)를 봅시다. 어딘가 익숙한데요?\nTreatment가 binary하다면\n\\[ P(T=1\\:|\\:W)=e(W) \\\\ P(T=0\\:|\\:W)=1-e(W) \\]\n즉, 경향점수를 이용해 IPW를 할 수 있습니다!\n\n\nIPW 적용하기\nbinary treatment를 가정했을 때, ATE의 identification equation은 경향점수를 이용해 아래와 같이 다시 쓸 수 있습니다.\n\\[ \\tau \\triangleq E[Y(1)-Y(0)]=E[\\frac{1(T=1)Y}{e(W)}]-E[\\frac{1(T=0)Y}{1-e(W)}] \\]\n이 때, 경향점수가 0이나 1에 아주 가까우면 estimate이 무한대로 발산하게 되죠. 따라서, 적당한 값으로 trim을 하기도 합니다. 물론 이 경우 bias와 같은 문제는 각오해야 합니다.\n위의 식을 확장해 CATE에 대한 IPW estimator를 만들 수도 있습니다.\n\\[ \\hat{\\tau}(x)=\\frac{1}{n_x}\\sum_{i:x_i = x}{(\\frac{1(t_i=1)y_i}{\\hat{e}(w_i)}-\\frac{1(t_i=0)y_i}{1-\\hat{e}(w_i)})} \\]\n다만 이 식을 그대로 사용하면 데이터가 많지 않아 variance가 커진다는 문제가 생깁니다. 더 general한 CATE IPW estimator도 있지만 본 강의에서는 다루지 않겠다네요."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#또-다른-방법들",
    "href": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#또-다른-방법들",
    "title": "08. Estimation",
    "section": "또 다른 방법들…",
    "text": "또 다른 방법들…\n이번 장에서는 causal effect estimation을 위해 사용할 수 있는 방법을 두 가지 소개했습니다.\n\n\\(\\mu(t,w) \\triangleq E[Y|t,w]\\)를 모델링하는 방법\n\\(e(w) \\triangleq P(T=1|w)\\)을 모델링하는 방법\n\n마지막으로 여기서 더 나아간 estimation 방법들을 소개합니다.\n\nDoubly Robust Methods\n\\(\\mu(t,w)\\)와 \\(e(w)\\)를 둘 다 모델링하는 방법. 이 방법은 다음과 같은 장점이 있습니다.\n\n\\(\\hat{\\mu}(t,w)\\) 또는 \\(\\hat{e}(w)\\) 중 하나만 consistent해도 전체 estimator가 consistent합니다 (doubly robust)\n이론상으로는 \\(\\tau\\)에 수렴하는 속도가 COM이나 IPW보다 빠릅니다 (\\(\\hat{\\mu} \\rightarrow \\mu\\)의 수렴 속도 \\(\\times \\: \\hat{e} \\rightarrow e\\)의 수렴 속도이기 때문)\n\n다만 \\(\\hat{\\mu}\\)나 \\(\\hat{e}\\)가 well-specified 되지 않았을 때 얼마나 잘 작동하는지 논란이 있습니다.\n\n\nMatching\n\nTreatment group과 control group에서 비슷한 사례들만 비교하는 방법입니다. ’비슷함’이 무엇을 의미하냐는 실험 설계에 따라 여러 방법으로 결정하시면 됩니다.\n\n\nDouble Machine Learning\n\nDouble machine learning 기법에서는 3가지의 모델을 학습시킵니다.\nStage 1:\n\n\\(W\\)로부터 \\(T\\)에 대한 예측값 \\(\\hat{T}\\)을 생성하는 모델\n\\(W\\)로부터 \\(Y\\)에 대한 예측값 \\(\\hat{Y}\\)을 생성하는 모델\n\nStage 2:\n\n\\((T-\\hat{T})\\)로부터 \\((Y-\\hat{Y})\\)에 대한 예측값을 생성하는 모델\n\n이 방법에서는 \\((T-\\hat{T})\\)과 \\((Y-\\hat{Y})\\)를 보아 \\(W\\)를 partial out합니다.\n\n\nCausal Trees and Forests\n\ndecision tree와 비슷하게 데이터를 재귀적으로 나눔으로써 같은 treatment effect를 가진 subset들을 만드는 기법입니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#참고자료",
    "href": "posts/Introduction_to_causal_inference_Estimation/Estimation.html#참고자료",
    "title": "08. Estimation",
    "section": "참고자료",
    "text": "참고자료\n\nThe Central Role of the Propensity Score in Observational Studies for Causal Effects"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Library/causal_inference_library.html",
    "href": "posts/Introduction_to_causal_inference_Library/causal_inference_library.html",
    "title": "01. Causal Inference 라이브러리 정리",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀입니다.\n본격적으로 Causal Inference 챕터 공부에 앞서, 학습에 필요한 Library와 튜토리얼을 정리해보았습니다.\n앞으로 Causal Inference 관련된 패키지를 꾸준히 추가할 예정이니, 혹시나 해당 페이지에\n정리되지 않은 라이브러리는 댓글로 달아주시면 감사하겠습니다~!  (Update 22.06.18)\n\n\n\n\n순서\n언어\n라이브러리 명\n설명 & 링크\n\n\n\n\n1\nPython\ncausality\nPython Causality 라이브러리 (Observational Datasets 기반) Github 링크\n\n\n2\nPython\nMicrosoft - DoWhy\nCausal Inference End-to-End 라이브러리 (4단계로 구성) Github 링크/Dowhy 설명자료\n\n\n3\nPython\nMicrosoft - EconML\nHeterogeneous treatment effects 추정 라이브러리 Github 링크\n\n\n4\nPython\nUber - CausalML\nUplift Modeling & ML과 함께 사용할 수 있는 라이브러리 Github 링크\n\n\n5\nPython\nsensemakr\nPython Sensitivity Analysis 라이브러리 설명 링크\n\n\n6\nPython\ncdt\nCausal Discovery 라이브러리 (PC, Skeleton) Github 링크\n\n\n7\nR\nGoogle - CausalImpact\nGoogle에서 베이지안 Time Series 모델을 사용한 R 기반 라이브러리 Github 링크\n\n\n8\nR\nDagitty\nDAG 시각화 및 모델링 라이브러리 Github 링크 / 시각화 연습\n\n\n9\nR\nbnlearn\nDAG 베이지안 네트워크 모델링 라이브러리 Github 링크 /관련 논문 및 코드 소개\n\n\n10\nR\nsensemakr / tipr\nR Sensitivity Analysis 라이브러리 sensemakr 설명 링크 / tipr Github 링크\n\n\n11\nR\nMatchlt\nMatching (PSM)라이브러리 Github 링크\n\n\n12\n공통\ncausaldata\nCausal inference 책에 있는 데이터를 불러오는 라이브러리 Github 링크\n\n\n13\nR\ntlverse\ncausal data science with the tlverse software ecosystem https://tlverse.org/tlverse-handbook/\n\n\n\n\nCausal Inference 라이브러리와 튜토리얼에 대한 정리는\n가짜연구소 Causal Inference 노션 페이지에서도 확인하실 수 있습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Causal_Models/Causal_Models.html",
    "href": "posts/Introduction_to_causal_inference_Causal_Models/Causal_Models.html",
    "title": "05. Causal Models",
    "section": "",
    "text": "Contents\n\nDo-operator and Interventional Distributions\nModularity Assumption\nBackdoor adjustment\nStructural causal models\n\n◦ 강의 영상 링크 : Chapter 4 - Causal Models\n    작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n◦ 이번 강의는 아래의 내용을 다룰 예정입니다.\n     Casual Inference를 할 때, 이론적으로 대답할 수 없는 Causal Estimand를 여러가지 가정을 통해 계산할 수 있는\n     Statistical Estimand로 추정하게 됩니다. 이때 필요한 개념인 Causal Model에 대해서 학습합니다.\n\n\n\n\n(1) Do-operator란 무엇인가요?\n\n정의 : 주어진 현상을 그대로 관찰하는게 아닌, 더 나아가 “개입한다”라는 것을 표현하는 수학 연산자입니다.\n                                                                                   (Intervention)\n역할 : Do-operator를 통해, Treament에 영향을 줄 수 있는 모든 요인의 효과를 무시할 수 있게 됩니다. \n                                                       (Treatment의 부모 노드)\nConditioning (조건) vs Intervention (개입) \n\n\n◦ Conditioning on \\(T=t\\) : 전체 모집단 or 관측한 데이터에서 Treatment \\(t\\)를 받은 모집단의 부분 집합에 해당합니다.\n◦ Intervention on \\(T=t\\) : 처치한 부분 집합이 아닌, 전체 모집단에 대해서 \\(T=t\\) 로 설정한 것을 말합니다.\n     - 통상적으로 Intervention은 \\(do(T=t), do(t)\\)로 표현합니다.\n     - 이는 주어진 현상을 그대로 관찰하는 것이 아닌, Doing(개입)한다라는 의미로 이해할 수 있습니다.\n◦ 아래와 같이 Conditioning과 Intervention은 서로 다른 표현방식이므로, 다른 데이터 분포를 형성합니다.\n\n\n\n\nObservational Distribution vs Interventional Distribution\n\n\n◦ Observational distribution \n     - 표현 : \\(P(Y),P(Y,T,X)\\)     - 특징 : 개입(doing)이 없이, 생성된 분포를 Observational distribution이라 합니다.\n◦ Interventional distribution \n     - 표현 : \\(P(Y|do(T=t)),P(Y|do(T=t),X=x))\\)\n     - 특징 : Treatment에 대한 개입 (do-operator)이 존재합니다. \n        →  처치(\\(T\\))를 통해 Randomized trial실험과 같은 효과를 낼 수 있으며, 이러한 데이터를 통해 추정된 인과 효과를\n              Causal Estimand라고 합니다.\n        → 반면, do-operator를 포함하지 않은 추정치 (Estimand)는 Statistical Estimand라고 합니다.     \n     - 예시 : \\(P(Y|do(T=t),Z = z)\\)가 의미하는 것은 무엇일까요?\n        → 모집단에 대해서 \\(T=t\\)에 대한 개입을 받은 Z=z인 부분집합에 해당하는 데이터라고 할 수 있습니다.\n\n\nIdentifiability :\n\n◦ 정의 : 개입을 통해 얻은 Causal Estimand를 Identification 가정을 통해 Statistical Estimand로 바꾸는 과정\n                           (직접 계산할 수 없음, Counterfactuals)                               (직접 계산가능)           \n    → 이 때, Confounders \\(X\\)를 제어하는데 필요한 Causal Models의 요소를 이번 Chapter에서 배울 예정입니다!\n\n\n(참고) Do-operator\n여기서 Do-operator는 쉽게 말해서 “개입한다”라는 의미입니다. 다시말해서 Do-operator의 역할은, Treament에 영향을 줄 수 있는 모든 변수의 효과를 무시하게 만들어줍니다.\n\n여기서 \\(P(Y|X)\\)는 인과효과가 아니에요. 왜냐하면 Confounder로 인한, Backdoor path가 열려 있기 때문이죠.\nDo-operator를 적용하면, X에 영향을 주는 C→ X 사이의 연결고리를 그래프 상에서 이론적으로 없애는 것이며,이 상태에서 계산한 \\(P(Y|do(X))\\) 값이 바로 인과 효과라는 것입니다.\n\n이러한 Do-operator는 실제 계산할 수 있는 값이라기 보다는 이론적인 개념이며, 그래서 결국 Do-operator를 수학적으로 계산할 수 있는 조건부 확률로 만들어줘야 하는데, 이때 필요한 가정을 앞에서 배운 Identification 입니다.\n“정리하자면, Interventional probability를 통해 Casual effect를 정의하고, Identifiable인지를 통해서 실제로 추정 가능한지에 대해 판단하며, 이를 통해 인과 관계를 구해보자는 것이죠”\n\n\n(2) Modularity Assumption\n\n앞으로 Identification을 하기 위해서 가정이 필요한데요, 해당 가정에 대해 배워보도록 할게요!\nCausal Indentification를 하기 위한 중요한 가정 : Interventions are local\n그러면, Interventions are local이 무엇일까요?\n\n\n◦  의미 : 어떤 노드에 개입(Intervention)하게 되면, 개입으로 인한 변화가 local하다는 것입니다.\n◦  효과 : 즉, 개입한 노드 \\(X_i\\)에 대해서 부모 노드 \\(pa_i\\)가 미치는 영향만 변하고, 나머지 노드에서 주는 영향은 유지가 된다라는 것입니다.\n◦  예시 : 아래 그림에서, 해당 가정에 따르면 원 안에 있는 \\(X_i\\)의 부모 노드(\\(pa_i\\))가 미치는 영향만 변화하고,\n     나머지는 영향은 유지 됩니다.\n\n\n\nModularity assumption : Interventions are local을 일반화한 가정\n\n\n◦ 정의 : \n\n   어떤 Graph 상 n개의 노드가 존재하고, 그 중 개입(intervention)을 한 노드의 인덱스 집합을 S라고 한다면,\n    1. 노드 i가 개입되지 않은 경우 (\\(i∉S\\)) 노드 i (\\(X_i\\))의 부모 노드(\\(pa_i\\))가 노드 \\(i\\)에 미치는 영향은 그대로 유지\n    2. 노드 i가 개입되었다면 (\\(i∈S\\)), \\(x_i\\)값으로 개입한 경우 \\(P(x_i|pa_i)\\) = 1,\n                                                          \\(x_i\\)값으로 개입하지 않은 경우 \\(P(x_i|pa_i)\\) = 0\n     * [n] = 1,2,3,4…,n 이며 각 숫자는 노드의 index를 의미\n        \\(X_i\\): Index가 i인 노드를 의미, \\(x_i\\) : 값(scalar)을 의미\n\n◦ Assumption violation : 그러면, Modularity 가정이 위배된다는 것은 어떤 의미일까요?\n     - 노드 \\(T\\) 에 대한 개입(intervention)이 \\(T\\)의 부모 노드에 대한 영향력에 변화를 줄 뿐만 아니라,  \n       \\(T_2\\)의 부모 노드에 대해 변화를 주었을 때, “Intervention이 local이 아니다”라고 합니다.\n\n◦ 예시 : \n    (a) 개입이 없는 Observational distribution\n    (b) \\(T\\)에 개입 : \\(T\\)의 부모 노드에서 오는 영향만 사라지고, 나머지는 유지됩니다.\n    (c) \\(T_2\\)에 개입 : \\(T_2\\)의 부모 노드에서 오는 영향이 사라지고, 나머지는 유지됩니다.\n     → \\(P(Y)\\), \\(P(Y|do(T=t))\\), \\(P(Y|do(T_2=t_2))\\)는 서로 연관되지 않은 완전히 다른 분포가 됩니다.\n     → (b), (c) 처럼 edge가 제거된 그래프를 Manipulated graph라고 해요!\n\n\n\n\nTruncated factorization\n\n\n◦ 우리는 방금 배운 Modularity assumption을 통해 새로운 식을 추론해낼 수 있어요. \n◦ 정의 : Bayesian network factorization에서 modularity assumption이 적용된 식입니다. \n◦ 과정 : 그럼 지난 시간에 배운 내용을 Remind 해볼까요?\n    1. Bayesian network factoriazation\n         = Chain rule of probability + Markov assumption\n\n        - Chain rule of probability : \\(P(x,y) = P(x)⋅P(y|x)\\)\n        - Markov assumption : 모든 노드는 오직 부모 노드로부터 영향을 받습니다.\n    2. Modularity assumption 적용\n       여기서 개입(intervention)을 한 노드의 인덱스 집합을 S라고 한다면, \\(i∈S\\) 인 노드들에 대해서는,\n       \\(P(x_i|pa_i)\\) = 1이기 때문에, bayesian network factorization 계산 과정에서 생략이 가능합니다.\n      →  따라서 \\(i∉S\\)인 노드들에 대해서만 \\(P(x_i|pa_i)\\)를 계산하면 되며, bayesian network factorization\n           식에서 아래와 같은 식을 도출할 수 있습니다.\n \n\n◦ 예시 : \\(P(y|do(t))\\)를 Identify 해봅시다.\n→ Treatment \\(T\\)에 영향을 미치는 부분이, 제거 (Trucated) 됩니다.\n\n\n\n\n(3) Backdoor adjustment\n\n이전 내용에서 개입(Doing)을 통해서 Treatment에 영향을 주는 외부 변수(Backdoor)를 차단하면서\nCasual effect를 구할 수 있다고 했습니다.\n\n\n\nQ : 그러면, Observational data에서 어떻게 Causal effect를 구할 수 있을까요?\n     A : 관측 데이터인 observational data에서는 개입(intervention)을 통해 그래프를 마음대로 변경하기는 어려워요.\n             하지만 아래 그림과 같이 Observational data의 Graph에 조건을 추가한다면, \\(P(Y|do(X))\\)와 동일한 효과를\n             줄 수 있지 않을까요?\n\n    * 아래 그래프에서의 Backdoor Paths (Non-causal association)\n       ◦ \\(T - W - Y\\)\n       ◦ \\(T - C - Y\\)\n\n\nQ : 그렇다면 어떠한 조건을 통해, Observation data에서 Doing(개입)한 것과 동일한 효과를 낼 수 있을까요?\n     A : Observation data Graph에 추가할 조건에 대한 기준이 필요합니다. 해당 조건을 정리한 것이 바로,\n           Backdoor criterion입니다.\n\n\n\nBackdoor Criterion :\n\n\n◦ 정의 : \\(T → Y\\)간의 Causal association을 제외한 모든 Backdoor paths를 막을 수 있는 변수들의 집합 \\(W\\)\n◦ 조건 :\n   1. 집합 W는 T에서 Y로 가는 모든 Backdoor paths를 block\n   2. 집합 W는 T의 어느 자손도 포함하지 말아야 함\n◦ Sufficient adjustment set : Modularity 가정이 주어졌을 때, 변수들의 집합 \\(W\\)가 Backddor Criterion을\n    만족한다면, \\(W\\)를 Sufficient adjustment set이라고 합니다.\n◦ 의미 : \\(W\\)가 Backdoor Criterion을 만족하게 되면, \\(T\\)에 대한 \\(Y\\)의 Causal Effect를 Identify 할 수 있어요!\n◦ 예시 :    \n1.  만약 confounder가 있다면, confounder를 통제를 해야 backdoor path를 막을 수 있습니다. 이러한 confounder의 집합이 backdoor criterion을 만족하는 집합이라고 볼 수 있겠죠. \n2. 반면에 collider는 통제하면 안됩니다. 따라서 이러한 collider는 backdoor criterion을 만족하는 집합이라고 볼 수 없습니다.\n     → 즉, 우리가 해야하는 것은 backdoor criterion을 만족하는 모든 집합을 통제해야해요!\n◦ 증명 : 그렇다면 정말 Backdoor adjustment를 통해 Doing(개입)의 효과를 얻을 수 있을까요?\n    1.  \\(P(Y|do(t),W)=P(Y|T,W)\\)  &lt; line 1 to line 2 &gt;\n          - Backdoor criterion 1번 조건에 의해 \\(W\\)는 모든 backdoor paths를 차단합니다.\n          → 따라서, \\(T\\)로 들어오는 edge의 영향이 제거 됩니다!\n          - 좌변 : \\(do(t)\\)의 modularity assumption에 의해 \\(T\\)에 들어오는 edge의 영향이 제거\n          - 우변 : \\(W\\)를 condition함으로써, \\(T\\)로 들어오는 edge의 영향을 제거\n    2.  \\(P(W|do(t)) = P(W)\\) &lt; line 2 to line 3 &gt;\n          - \\(T=t\\) 라고 통제를 했으므로, \\(W\\)→\\(T\\) 관계가 사라집니다. (독립)\n          →  따라서, Backdoor adjustment를 통해 observational data를 가지고 앞에서 Casual로 정의한         \n               \\(P(Y|do(t))\\)를 규명할 수 있습니다.\n\n\n\nBackdoor Criterion과 D-separation : D-separation을 backdoor criterion 가지고 정의해봅시다.\n\n\n1. Backdoor criterion &lt; 왼쪽 그림 &gt;\n     - 조건 1. 집합 \\(W\\)는 \\(T\\)에서 \\(Y\\)로 가는 모든 backdoor paths를 막아야합니다.\n                   열려 있는 Backdoor path는 \\(W_2\\) or \\(W_1\\)→ Blocked\n     - 조건 2. 집합 \\(W\\)는 \\(T\\)의 어느 자손도 포함하지 말아야 합니다.\n                   \\(T\\)의 자손인 \\(X_2\\)가 막혀 있습니다. → Unblocked\n2.  Backdoor adjustment 처리 된 그래프 \\(G\\) &lt; 가운데 그림 &gt;\n     - 그리고 단 하나의 Association도 존재하지 않는 조건부 독립을 의미하는 D-separated는 \\(T\\)→\\(M_1\\)으로 가는\n       edge를 제거하게 됩니다.\n3. D-separation &lt; 오른쪽 그림 &gt;\n     - 이렇게 하여 생성된 그래프를 아래 그림과 같이 \\(G_{\\bar{T}}\\)로 표현하고, \\(W\\) 컨디션 아래에서 \\(Y\\)와 \\(T\\)는\n       d-separated 되었다고 표현합니다.\n\n\n\n\n(4)Structural causal models (구조적 인과 모델)\n\n구조적 인과모델 (Structural Casual Model)은 변수들 사이의 인과 관계를 구조화 된 함수로 나타내는 것입니다.\n표현 : 수학에서 쓰는 ‘=’ 과는 달리, causation 상에서는 역이 성립하지 않으며, 아래와 같이 표기합니다.\n◦  Structural equation B := f(A)\n◦ 여기서 A와 B 의 mapping이 deterministic 합니다. 명확한 관계가 이외의 확률적인 부분 (Stochastic)을\n    고려하기 위해선 B의 unknown causes도 인지해야 해요. 그래서 해당 변수를 고려하면 아래와 같습니다.\n    →  B := f(A,U)\n\n\n\nStructural Casual Models\n\n\n◦ 정의 : Structural causal models은 다음 3개의 집합에 대한 튜플(Tuple)입니다.\n    1.  U : 외생(exogenous) 변수, 모델 밖에서 그 값이 결정되는 변수들의 집합\n         - 부모 노드가 없는 변수로 이 노드의 causes를 모델링 할 필요가 없습니다.\n         - 아래 그림에서는 변수 \\(U_B, U_C, U_D\\)에 해당합니다.\n    2.  V : 내생(endogenous) 변수, 모델 내에서 다른 변수들에 의해 설명되는 집합\n         - 부모노드가 존재하는 변수로 모델링 하고자하는 structural equation의 변수\n         - 아래 그림에서는 변수  \\(B, C, D\\)에 해당합니다.\n    3.  f : 모델 내 다른 변수들에 따라 V에 속한 변수들의 값을 결정하는 함수 집합\n\n◦ Structural Causal Model (SCM)를 쓰는 이유가 무엇일까요?\n    1. Potential Outcomes 표현\n         - SCM에서 \\(T=t\\)로 고정했을때 나오는 결과 값은 potential outcome 입니다.\n    2. 일반화된 분포 고려 가능\n         - DAG로 표현 시, Causal direction이 다를 수 있어 인과관계를 확인하기에 적합하지 않아요.\n           하지만 SCM은 DAG의 구조적 할당을 따르며 SEM (Strctural Equation Models)의 functional form을\n           통해, intervention set을 지정할 수 있습니다. 따라서, 더 많은 상황에서의 분포를 고려할 수 있어요.\n    3. Causal Models 체계화 \n         - 그래프 기반으로 인과관계를 분석하는 건 간단하지만 이런 그래프가 복잡해지면 직관적인 이해만으론 한계가\n           존재합니다. 그렇기 때문에, 그래프 기반의 인과관계 분석을 수학적인 언어를 통해 보다 체계화 할 수 있어요.\n◦ 예시 : 아래 그래프를 SCM 구조로 표현해봅시다.\n\n\\(U=\\) {\\(X\\)}, \\(V=\\) {\\(T,Y\\)}, \\(F=\\) {\\(f_T,f_Y\\)}\n\\(f_T:=\\alpha_1X\\)\n\\(f_Y:=\\beta T+\\alpha_2X\\)\n\n\n\n\n\n SCMs에서의 Intervention : Modularity assumption에 의해 SCM(M)과 Interventional SCM(\\(M_t\\))에는 \\(M_t\\)에서 개입이 일어나는 변수 \\(T\\)에 대한 구조방정식이 T:=t로 대체되는 것 외, 개입이 일어나지 않는 다른 변수에 대한 구조 방정식은 동일합니다.\n\n\n\nThe Law of Counterfactuals (and Interventions)\n\n\n◦ 정의 :  \\(Y_t(u) = Y_{M_t}(u)\\)\n◦ 의미 : SCM에 대한 충분한 정보가 있는 경우, 실질적으로 Counterfactuals을 계산 할 수 있다는 Principle입니다.\n◦ 의의 : Chapter 2에서 이야기한 인과추론의 근본적인 문제이기 때문입니다. \n    해당 내용은 Chapter 14에서 더 세부적으로 다룰 예정이에요.\n\n\nCollider과 Treatment의 자식노드는 왜 Condition을 하지 않을까요?\n\n\n\nCausation을 막기 때문입니다.\n    ◦ 왼쪽 그림 : 아래 그림은 \\(T\\)와 \\(Y\\)가 d-seperarted되어, 모든 causation이 막힌 상황입니다.\n    ◦ 오른쪽 그림 : Causation이 있기 위해서는 \\(T\\)와 \\(Y\\) 사이에 direct path가 있으면 됩니다.\n        → 이러한 blocking causal association 이유로 descendants of treatment를 condition 하지 않습니다.\n\n\n\n새로운 형태의 Association이 생기기 때문입니다 : new post-treatment association\n    ◦오른쪽 그림 : \\(M\\)에서 관측되지 않은 외생변수 \\(U_M\\)과 \\(T\\), \\(M\\)사이엔 collider가 있다고 볼 수 있어요.\n       → collider의 자식 노드인 \\(Z\\)를 condition하면, 새로운 post-treatment association이 발생할 수 있습니다!\n \n\n새로운 형태의 Association이 생기기 때문입니다 : new pre-treatment association &lt; M-bias &gt;\n    ◦ 아래 그림에서도 \\(Z2\\) 가 collider이므로, M-bias 형태에서 conditioning 시킬 수 없습니다.\n\n\n\n\n\n\nBackdoor Adjustment 예제\n\n◦ 데이터 설명\n   - 상황 : 미국인의 46%가 고혈압이 있고 고혈압은 사망률 증가와 연관되어 있습니다.\n   - 가설 : 이때 나트륨 섭취가 고혈압에 영향을 줄까요?\n   - Outcome : 혈압\n   - Treatment : 나트륨 섭취\n   - Covariates \\(W\\) : 나이,  Covariates \\(Z\\) : 소변에 배출되는 단백질 양\n     → 나이는 혈압과 신체의 나트륨 수치를 조절하는 Confounder이며, 소변에 배출되는 단백질 양이 많은 것은\n          고혈압과 나트륨 섭취량이 많기 때문입니다. 즉, \\(Z\\)는 Colider이며 \\(W\\)는 Cofounder 입니다.\n\n◦ Causal Graph\n   - 위에서 배운 Backdoor criterion에 의하면, Confounder인 \\(W\\)에 대한 Backdoor path만 막으면 됩니다. \n     Identification을 통해, 계산할 수 있는 Statistical estimand를 그래프 이용해 도출해 봅시다.\n   - Chapter 3에서 배운 방식으로 Statistical estimand를 작성해보면, \\(E_w,zE[Y|t,W]\\) 이지만,colider인 \\(z\\)는\n     막을 필요가 없어요. 그래서 Causal graph를 통해 도출된 Statistical estimand는 \\(E_wE[Y|t,W]\\)입니다.\n\n\n◦ Identification \n   - 위와 같은 방식을 통해, Backdoor path를 어떤 변수를 가지고 조절해야 하는지 쉽게 알 수 있습니다.\n   - 우리가 구해야하는 값(Causal estimand) : \\(E[Y|do(t)]\\)\n   - 우리가 구할 수 있는 값(Statistical estimand from causal graph) : \\(E_wE[Y|t,W]\\)\n   - 우리가 배운 과정을 적용해보면 최초의 종속변수는 ‘sodium’, ‘age’, ’proteinuria’과 같았겠죠?\n      이 때, Collider인 proteinuria (단백뇨)를 제거해서 ’sodium’과 ’age’를 종속변수로 활용해봅시다.\n\n◦ Estimation   - 데이터를 통해 ATE estimation을 확인하면, 각 Condition 마다 차이는 아래와 같습니다.\n   - 1) 변수 통제 하지 않았을 때 오류 : 407%\n     2) \\(T\\),\\(Y\\) 변수와 관계된 모든 영향을 통제했을 때 오류 : 19%\n     3) Backdoor path를 차단했을 때 오류 : 0.02%\n\n\n\n위 과정을 Python code를 활용해, 간단한 실험을 진행해볼게요.\n\n\n이전 예제에서의 변수간 영향력을 알 수 없으므로 위 그림과 같이 변수간의 관계를 숫자로 표현하였습니다.\nimport numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as sm\n\nnp.random.seed(12345)\nnum = 10000\n\nW = np.random.normal(size = num)\n\nT = 6 * W + np.random.normal(size = num)\nY = 5 * T +  3 * W + np.random.normal(size = num)\nZ = 2 * T + 7 * Y + np.random.normal(size = num)\n\ndata = pd.DataFrame({'T':T,'Y':Y,'Z':Z,'W':W})\n우리가 구하고자 하는 관계는 T가 Y에 미치는 인과관계를 구하고 이때 그림과 같이 5로 설정했습니다.\n먼저 어떠한 종속변수를 통제하지 않고 선형회귀모델을 사용하여 관계를 구해볼게요.\nmodel1 = sm.ols('Y ~ T', data).fit()\nmodel1.summary().tables[1]\n\nY에 대한 T의 영향이 5.4866으로 0.4866이라는 잡음이 생겼네요. 교란변수를 통제하지 않아서 오차가 생겼습니다.\n그러면 Y와 T사이 영향을 주는 모든 변수를 통제해볼까요?\nmodel2 = sm.ols('Y ~ T + W +Z', data).fit()\nmodel2.summary().tables[1]\n\nY에 대한 T의 영향이 -0.1770으로 우리가 구하고자 하는 5란 값과 매우 멀어졌습니다.\ncollider를 통제하면서 Y와 T간의 새로운 종속 관계를 만들어 내어 collider bias를 만들었군요.\n이처럼 모든 변수를 통제하여 collider 또한 통제하게 되면 편향이 발생할 위험이 있습니다.\n마지막으로 Y와 T사이 collider인 Z는 제거하지 말고 교란변수인 W만 통제해보겠습니다.\nmodel3 = sm.ols('Y ~ T + W', data).fit()\nmodel3.summary().tables[1]\n\nY에 대한 T의 영향이 4.9967으로 가장 5에 가까운 결과를 도출해냈습니다.\n변수간의 관계를 파악하여 non-causal association은 통제하고 정확한 causal association을 찾아내는 과정은 중요합니다.  \nTo be continued) 다음은 인과관계를 학습하는데 있어, Gold standard라고 불리는 Randomized Experiment에 대해 배울 예정입니다.\n\n\n\nReference \n\n◦ Lecture Notes : 2021 Summer Session on Causal Inference (박지용 교수님) [Link]\n◦ Blog\n   - Backdoor Adjustment [Link]\n   - 인과추론. 그래프와 확률 [Link]"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html",
    "href": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html",
    "title": "09. Unobserved Confounding Analysis",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀의 최은희, 김상돈입니다.\nIntroduction to Causal Inference 강의의 여덟번째 챕터이며, 해당 챕터에서 다루는 내용은 아래와 같습니다.\n강의 영상 링크 : https://youtu.be/IXNMYqUsBBQ\n작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#contents",
    "href": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#contents",
    "title": "09. Unobserved Confounding Analysis",
    "section": "Contents",
    "text": "Contents\n\n Overview\n\nPotential Outcomes, ATE 리마인드\n\nBounds\n\nObservational-Counterfactual Decomposition\nNo-Assumptions Bound\nMonotone Treatment Response (MTR)\nMonotone Treatment Selection (MTS)\nOptimal Treatment Selection (OTS)\n\nSensitivity Analysis\n\nLinear Single Confounder\nTowards More General Settings"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#overview",
    "href": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#overview",
    "title": "09. Unobserved Confounding Analysis",
    "section": "Overview",
    "text": "Overview\n\nPotential outcomes\n\n\n실제 비즈니스 문제를 해결할 때 우리가 가진 Control group을 활용하여 관측되지 않은 Counterfactual(Unobserved confounders)과 최대한 같아지게 해야함\n인과추론의 Consistency 원칙 (동일 T의 경우 그에 대한 결과도 동일해야함)Potential Outcomes\n\n하얀 생쥐의 경우 Consist하지 않고 Counterfactual함 (이런 경우가 바로 unobserved confounding factors)\n\n\n\n2. ATE에 대해 다시 한번 짚어보자.\n\\(\\mathbb{E}[Y(1)-Y(0)]=\\mathbb{E}_W[\\mathbb{E}[Y\\,|\\, T=1,W]-\\mathbb{E}[Y\\,|\\, T=0,W]]\\)\n\nWhat is ATE(Average Treatment Effect)?\n\n일반적으로 A/B testing에서 사용되는 분석 방법. 개인의 인과효과를 평균을 내어 집단 레벨에서 설명. 보통의 경우 교란변수(Confounders) \\(W\\)가 관측될 경우 처치 \\(T\\)(treatment)와 결과 \\(Y\\)에 대한 인과를 아래와 같은 ATE 식을 기반으로 설명할 수 있음\n위 ATE식이 성립 가능한 경우: Confounder가 모든 그룹에 동일하게 작용할때 두 그룹에 Confounding factors가 동질하게 작용하기 위해선? RCT를 통해 가능!\n\n\n\n\n\n\n하지만 ATE의 경우 Outlier에 취약한 단점 또한 있음\n\ne.g. 타겟군과 대조군의 매출 비교 진행 시, 만약 대조군에 타겟군의 구매액을 합친 수준의 핵과금러가 한 명이라도 존재한다면?\n\n\n\n\n\n\nIdentify a point [Identification]\n\n모든 변수가 관측가능하다고 강한 가정을 한다면, 우리는 포인트가 되는 지점을 명확히 알 수 있을 것이다.\n\n\n3. 만약 관측 불가(Unobserved Confounders)한 \\(U\\)를 발견하였을땐 어떡해야 할까?\n\n사실 관측 불가한 \\(U\\)는 거의 모든 연구에서 고려해야할 사항\n\n\\(\\begin{aligned}\\mathbb{E}[Y(1)-Y(0)] &=\\mathbb{E}_W,_U[\\mathbb{E}[Y\\,|\\, T=1,W,U]-\\mathbb{E}[Y\\,|\\, T=0,W,U]] \\\\ &\\approx \\mathbb{E}_W[\\mathbb{E}[Y\\,|\\, T=1,W]-\\mathbb{E}[Y\\,|\\, T=0,W]]\\end{aligned}\\)\n\nIdentify an interval (Partial identification)\n\nATE를 활용하여 최대한 근사치를 찾아보자\n한가지 가정을 내리는 것이 아닌 가정의 범위를 넓혀 [근사치], 즉 그 간격(Interval)을 추정해보자\n\n\n\n\n\n\n💡 ‘No Unobserved Confounding’ is Unrealistic.\n   현실 세계에서 모든 변수를 관측한다는 것은 불가능하다.\n\n\n\n\n\n\n\n\n\n\n1\nNo-Assumptions Bound\n가정이 없다.\nInterval 매우 김\n\n\n\n\n2\nMonotone Treatment Response\n처치(\\(T\\))는 언제나 결과(\\(Y\\))에 영향을 준다.\n \n\n\n3\nMonotone Treatment Selection\n처치(\\(T\\))를 받은 군이 언제나 좋은 Potential Outcomes을 도출한다.\n \n\n\n4\nOptimal Treatment Selection\n개개인은 언제나 최적의 처치(\\(T\\))를 받는다.\n- Interval 짧아짐\n\n\n\n👉 가정의 정도가 올라갈수록 현실 세계에서 발생되는 현상에 대한 설명력이 떨어진다는 한계점이 존재한다. 강한 가정 아래에서 나온 결론일수록 그 결과의 신뢰성을 떨어진다는 뜻. (“The credibility of inference decreases with the strength the assumptions maintained.” Manski)\n👉 Interval이 짧아질수록 결과에 대한 신뢰도도 떨어질 수 있음 (개개인이 언제나 최적의 처치를 받을 확률은?)"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#bounds",
    "href": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#bounds",
    "title": "09. Unobserved Confounding Analysis",
    "section": "Bounds",
    "text": "Bounds\n\n 💡 지금부터 관측이 어려운 변수들의 범위를 좁히는 방법론들에 대해 알아봐보자.\n\n\nObservational-Counterfactual Decomposition\n이쯤에서 다시보는 ATE. \\(\\mathbb{E}[Y(1)-Y(0)]=\\mathbb{E}_W[\\mathbb{E}[Y\\,|\\, T=1,W]-\\mathbb{E}[Y\\,|\\, T=0,W]]\\)\n\nObservational : 관측되는 부분\nCounterfactual : 가정을 통해 범위를 좁히는 부분\n\n\n\n💡Observational-Counterfactual Decomposition\n\\(\\begin{aligned}\\mathbb{E}[Y(1)-Y(0)] = \\pi\\mathbb{E}[Y|T=1] + (1-\\pi)\\mathbb{E}[Y(1)|T=0] \\\\ -\\,\\pi\\mathbb{E}[Y(0)|T=1] - (1-\\pi)\\mathbb{E}[Y|T=0] \\\\ where \\;\\; \\pi \\triangleq P(T=1)\\end{aligned}\\)\n\n\n\n[1] No-Assumptions Bound\n\n가정: 범위(Bound)에 대한 가정이 없을 때 Interval Length 구해보기\n\nBounded Potential Outcomes\n\\(Y(0)\\)과 \\(Y(1)\\)이 \\(0\\)과 \\(1\\) 사이에 있다고 가정했을 때 \\(\\mathbb{E}Y(1)-Y(0)\\)의 경우 음의 0과 1, 양의 0과 1 사이에 있다.\n\\(-1 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 1\\)\n이를 일반화한다면, \\(\\forall t, a \\le Y(t) \\le b\\)\n\\[ a-b \\le \\mathbb{E}[Y(1)-Y(0)] \\le b-a \\]\n\nTrival length limit : \\(2(b-a)\\)\n\nNo-Assumptions Bound\n\nobservational-counterfactual decomposition 와 각 방법론의 가정을 활용하여 lower bound와 upper bound를 추정하는 과정\n\nupper bound\n\n\\(\\mathbb{E}[Y(1)-Y(0)] \\le \\pi\\mathbb{E}[Y|T=1]+(1-\\pi)b -\\pi a-(1-\\pi)\\mathbb{E}[Y|T=0]\\)\n\nlower bound\n\n\\(\\mathbb{E}[Y(1)-Y(0)] \\ge \\pi\\mathbb{E}[Y|T=1]+(1-\\pi)a -\\pi b-(1-\\pi)\\mathbb{E}[Y|T=0]\\)\\[ Interval\\; Length = b-a \\]\n\n\n최초의 시작에서 범위를 반으로 줄이게 되는 것. \\(2(b-a) \\longrightarrow b-a\\)\n언제나 0을 포함한다.\n\n\n💡 (앞으로 계속 나올) 예시\n(1) Potential outcomes 가 \\(0(a)\\) 와 \\(1(b)\\) 사이에 있음\n(2) \\(\\pi = 0.3\\) \\(\\mathbb{E}[Y|T=1]=0.9\\) \\(\\mathbb{E}[Y|T=0]=0.2\\)\n\\[ -0.17 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.83 \\]\n\n\n\n[2] Monotone Treatment Response (MTR)\n\n가정: 처치(T)는 언제나 결과(Y)에 영향을 준다는 가정 (Nonnegative, Nonpositive)\n\n\n\n\n\n\n\n\nNonnegative MTR\nNonpositive MTR\n\n\n\n\n\\(\\forall i\\; Y_i(1) \\ge Y_i(0)\\)\n\\(\\forall i\\; Y_i(1) \\le Y_i(0)\\)\n\n\n\\(0 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.83\\)\n\\(-0.17 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0\\)\n\n\n\n\nNonnegative MTR (lower bound 무시)\n\n처치는 언제나 결과에 긍정적인 영향을 준다.\n\n\n\\(\\forall i\\; Y_i(1) \\ge Y_i(0)\\)\n\nITE (Individual Treatment Effect) \\(a - b \\ge 0\\)\nATE (Average Treatment Effect) \\(\\mathbb{E}[Y(1)-Y(0)] \\ge 0\\)\n\n\nNonpositive MTR (upper bound 무시)\n\n처치는 언제나 결과에 부정적인 영향을 준다. \n\n\n\\(\\forall i\\; Y_i(1) \\le Y_i(0)\\)\n\nITE (Individual Treatment Effect) \\(a - b \\le 0\\)\nATE (Average Treatment Effect) \\(\\mathbb{E}[Y(1)-Y(0)] \\le 0\\)\n\n\n\n[3]Monotone Treatment Selection (MTS)\n\n가정: 처치(\\(T\\))를 받은 타겟군(Target)이 대조군(Control)보다 언제나 좋은 Potential Outcomes 도출한다. (MTS Upper Bound)\n\n\n\\(\\mathbb{E}[Y(1)|T=1] \\ge \\mathbb{E}[Y(1)|T=0]\\)\n\\(\\mathbb{E}[Y(0)|T=1] \\ge \\mathbb{E}[Y(0)|T=0]\\)\n\n\\[ \\mathbb{E}[Y(1)-Y(0)] \\le \\mathbb{E}[Y|T=1] - \\mathbb{E}[Y|T=0] \\]\n\n💡 그러면 이제 MTS Upper Bound에 nonnegative MTR을 합쳐보자.\n이를 통해 우리는 더 좁은 Interval length를 겟할 수 있다!\n\n\n\n\nNo Assumptions\n\\(-0.17 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.83\\)\n\n\n\n\nMTS Upper Bound\n\\(-0.17 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.7\\)\n\n\nnonnegative MTR\n\\(0 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.83\\)\n\n\ndo combine. (MTS + MTR)\n\\(0 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.7\\)\n\n\n\n\n\n[4]Optimal Treatment Selection (OTS)\n\n가정: 개개인은 언제나 그들에게 최적의 처치(Optimal Treatment)를 받는다.\n\n\n💡 OTS Assumption\n(1) Treatment Group (타겟군) \\(T_i = 1 \\Longrightarrow Y_i(1) \\ge Y_i(0)\\)\n(2) Nontreatment Group (대조군) \\(T_i = 0 \\Longrightarrow Y_i(0) &gt; Y_i(1)\\) \n\n[4-1] 방법론1\nobservational-counterfactual decomposition\n\nOTS Upper Bound 1 : \\(\\mathbb{E}[Y(1)|T=0] \\le \\mathbb{E}[Y|T=0]\\)\nOTS Lower Bound 2 : \\(-\\mathbb{E}[Y(0)|T=1] \\ge -\\mathbb{E}[Y|T=1]\\)\n\n\\[ Interval\\; Length = \\pi\\mathbb{E}[Y|T=1]+(1-\\pi)\\mathbb{E}[Y|T=0]-a \\]\n\n\n\nNo Assumptions\n\\(-0.17 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.83\\)\n\n\n\n\nOTS Bound 1\n\\(-0.14 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.27\\)\n\n\n\n여전히 0을 포함하고 있는데…..\n[4-2] 방법론2 : Bound the identifies the sign!\nobservational-counterfactual decomposition\n\nOTS Upper Bound 2 : \\(\\mathbb{E}[Y(1)|T=0] \\le \\mathbb{E}[Y|T=1]\\)\nOTS Lower Bound 2 : 알아서 해보래요…\n\n\n\n\nNo Assumptions\n\\(-0.17 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.83\\)\n\n\n\n\nOTS Bound 1\n\\(-0.14 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.27\\)\n\n\nOTS Bound 2\n\\(0.07 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.76\\)\n\n\ndo combine\n\\(0.07 \\le \\mathbb{E}[Y(1)-Y(0)] \\le 0.27\\)"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#unobserved-confounding이-과연-관측-연구에만-적용되는-이슈일까",
    "href": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#unobserved-confounding이-과연-관측-연구에만-적용되는-이슈일까",
    "title": "09. Unobserved Confounding Analysis",
    "section": "Unobserved Confounding이 과연 관측 연구에만 적용되는 이슈일까?",
    "text": "Unobserved Confounding이 과연 관측 연구에만 적용되는 이슈일까?\n\n💡 실험 연구(Experimental Study)에서 발생하는 Unobserved Confounding factors\n\n\n관측되지 않는 교란 변수가 RCT 기반의 실험에서는 전혀 이슈가 되지 않을까?\n\nRCT (Randomised Controlled Trial) 랜덤화 실험 (RCT 수행 목적: 그룹의 동질성)\n우리가 원하는 이상적인 RCT 기반 A/B test는…\n타겟군과 대조군을 랜덤하게 나누어 동질 그룹(homogeneous group)으로 분할하고, 타겟군에만 처치(Treatment)를 진행하여 나온 값에서 대조군의 값을 차감해준 결과는 처치로 인한 결과다! \\(T \\longrightarrow Y\\) (처치와 결과 사이에는 인과관계가 존재한다.)\n\n\n\n\n\n\n(특히 마케팅에서)인과추론을 잘 모르는 의사결정자의 흔한 반론. 원래 [상품/이벤트/기능개선/업데이트]가 이전보다 고객에게 매력적이어서 그런거 아냐?\n흔한 분석가의 설명: 타겟군과 대조군 모두에게 동질하게 적용되는 외부변수임.\n\n🤔 과연 진짜 그럴까? 의외로 날카로운 지적이었을 수도\n\n\n\n\n\n\n논문소개. (Microsoft) Common Metric Interpretation Pitfall in A/B test 원문은 여기\n\n\n💡 A/B test를 진행할 때 반드시 아래 4가지를 확인해야 함\n(1) Data Quality : 활용된 데이터가 신뢰할만한가? e.g. 타겟군과 대조군의 동일한 모집단에서 랜덤 샘플링되었는지.\n(2) OverallEvaluation Criteria : 처치가 성공적이었는지, 성공했다면 어느 정도의 효과였는지, 그 효과가 통계적으로 유의한지\n(3) Guardrail : 실험에 영향을 주는 교란은 어느 정도였는가 (전사적으로 영향을 받으면 안되는 지표)\n(4) Local Feature and Diagnostic : 유저의 액션을 세밀한 수준에서 분석하여 처치의 성공 여부와 교란 변수의 영향 정도를 파악 \n\n\n\n사례1. Counfounding factor - Metric Sample Ratio Mismatch(e.g.)\n\n링크 이동 방법에 따른 유저 경험 최적화\n링크를 새로운 탭에서 띄우는 것이 홈페이지 로드 타임을 증가시켰다 (?)\n\n\n\n\n\n\n\n\n\n\n\n \n가설\n결과 (페이지 로드 수)\n\n\n\n\n타겟군\nMSN 홈페이지에서 클릭된 어느 링크든, 새로운 탭으로 페이지가 뜬다.\n~8.4M\n\n\n대조군\nMSN 홈페이지에서 클릭된 어느 링크든, 오픈되어 있는 탭에서 링크로 이동된다.\n~9.2M\n\n\n\n결론: 실험군(타겟군)에서 페이지 로드 타임이 약 8.32% 증가했다. -&gt; 기대 이상의 큰 증가\n🌟 Confounding factor\n\n홈페이지 탭이 미리 켜져 있어 reload하지 않아도 되는 상황\n대조군의 경우 브라우저에 남은 홈페이지 캐시\n\n💡 이런 요인들을 어떻게 발견 해야할까?\n\n비율 지표를 분해하여 어느 부분에서 차이가 발생하는지 파악\n비율 mismatch에 영향을 받지 않는 실험군, 대조군 간의 동등하게 비교할 수 있는 subset을 찾아서 신뢰 가능한 결과를 분석\n\n\n사례2. Counfounding factor - Novelty and Primacy Effects\n\n(e.g.) CRM측면에서의 각 세그먼트 별 처치에 따른 효과 측정\n그룹 A의 처치 효과가 그룹 B의 처치 효과보다 좋았다(?)\n\n\n\n\n\n\n\n\n\n\n \n그룹 A\n그룹 B\n\n\n\n\n처치 효과\n(처치군이 대조군에 비해) + 126% 상승\n(처치군이 대조군에 비해) + 108% 상승\n\n\n\n여기서 낼 수 있는 결론: 그룹 A가 CRM 측면에서 그룹 B보다 더 좋은 세그먼트다. 그룹 A를 중심으로 한 전략을 수립해보자(?)\n\n\n🌟 Confounding factor - 그룹 A에서의 Novelty effect\n\nNovelty effect : 긍정적인 효과가 단기간 혹은 초반에만 발생하고, 기간이 길어질수록 그 효과가 나타나지 않을 때 (초두효과)\nPrimacy effect : 초반에는 유저의 반응이 극적이지 않지만, 시간이 지날수록 user learning이 발생하여 처치 최적화가 잘 이루어질때\n\n\n💡 이런 요인들을 어떻게 발견 해야할까?\n(1) 처치 효과를 다양한 세그먼트로 쪼개어 결과를 확인해본다.\n(2) 처치의 효과를 일별로 쪼개어 확인해본다.\n(3) 실험의 기간을 늘려 장기적으로 확인해본다.\n\n\n결론\n\n우리가 진행한 테스트 설계가 잘되어있다는 굳은 믿음에서 벗어나 결과를 주어진 리소스 안에서 최대한 비판적으로 해석해야한다.\nA/B test를 진행할 때 발생할 수 있는 교란 변수의 범위를 정한다 하더라도 세부적인 변수들을 모두 파악하기란 힘들다. 하지만 위 논문에서 소개한대로 여러 Metric에 대해 정의를 진행하고 경험적으로 쌓인 발생 가능한 변수들에 대한 관리 시스템을 잘 구축한다면 더 발전된 추론을 할 수 있을 것이다.\nA/B test 분석을 진행하는 분석가의 도메인에 대한 이해도, 사전 지식이 중요할 수 있다. 도메인 지식 정도에 따라 추측할 수 있는 교란 변수의 범위도 넓어질 수 있을 것이다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#sensitivity-analysis",
    "href": "posts/Introduction_to_causal_inference_Unobserved_confounding_Analysis/Unobserved_Confounding_Analysis.html#sensitivity-analysis",
    "title": "09. Unobserved Confounding Analysis",
    "section": "Sensitivity analysis",
    "text": "Sensitivity analysis\n일반적으로 관찰 데이터로 인과추론 분석을 할 때에는 관측되지 않은 교란 요인이 없다는 가정 하에서 분석을 진행합니다. 일반적으로 이러한 가정은 만족될 수 없습니다. 따라서 가정이 위반되었을 때, 인과 관계에 미치는 영향을 정량적으로 확인하는 절차, 즉 강건성을 확인하는 절차가 필요합니다. 이것을 측정하기 위해 다음과 같은 질문을 해볼 수 있습니다.\n관찰 데이터로 추정한 인과효과를 \\(0\\)으로 만들기 위해서 관찰되지 않은 교란요인이 \\(T\\)와 \\(Y\\)에 얼마나 많은 영향을 끼쳐야 하는가? 민감도분석은 이러한 질문에 답을 하기 위한 정량적인 분석을 수행하는 것입니다. \n\nSensitivity Basiscs in Linear Setting\n먼저 가장 간단한 세팅으로 linear setting을 고려해보겠습니다. 오른쪽 그림을 보면 \\(W\\)는 관찰된 교란요인이고, \\(U\\)는 관찰되지 않은 교란요인을 나타냅니다. \\(U\\)의 효과를 무시했을 때, 나타나는 편향은 어느 정도일까요?\n\n\n\nlinear setting에서 \\(T\\)와 \\(Y\\)는 다음과 같이 표현할 수 있습니다.\n\\[\\begin{aligned} &T := \\alpha_w W + \\alpha_u U \\\\ &Y := \\beta_w W + \\beta_u U + \\delta T \\\\ \\end{aligned}\\]\n먼저 \\(T, \\, U\\)가 주어졌을 때를 가정하면, ATE는 \\(\\delta\\)로 계산됩니다.\n\\[E[Y(1) - Y(0)] = E_{W, U}[E[Y|T=1,W,U] - E[Y|T=0, W, U]] = \\delta\\]\n하지만 \\(U\\)는 관찰할 수 없는 교란요인이므로, 실제로는 \\(W\\)만 조정할 수 있습니다. 따라서 \\(U\\)의 영향으로 confounding bias가 \\(\\frac{\\beta_u}{\\alpha_u}\\) 만큼 발생합니다.\n\n\\[ E_W[E[Y|T=1, W]-E[Y|T=0, W]] - E_{W,U}[E[Y|T=1, W, U] - E[Y|T=0, W, U]] = \\frac{\\beta_u}{\\alpha_u} \\]\n\n\\(proof\\)\n\\[ \\begin{aligned} E_W[E[Y|T=t, W]] &= E_W[E[\\beta_w W + \\beta_u U + \\delta T|T=t, W]] \\\\ &= E_W[\\beta_w W + \\beta_u E[U|T=t, W] + \\delta t] \\\\ \\newline &=E_w \\left[\\beta_w W + \\beta_u \\frac{t-\\alpha_w W}{\\alpha_u} + \\delta t\\right] \\\\ &=E_w \\left[\\beta_w W + \\frac{\\beta_u}{\\alpha_u}t - \\frac{\\beta_u \\alpha_w}{\\alpha_u}W + \\delta t\\right] \\\\ &=\\beta_w E[W] + \\frac{\\beta_u}{\\alpha_u}t - \\frac{\\beta_u \\alpha_w}{\\alpha_u}E[W] + \\delta t \\\\ &=\\left(\\delta + \\frac{\\beta_u}{\\alpha_u}\\right)t + \\left(\\beta_w - \\frac{\\beta_u \\alpha_w}{\\alpha_u}\\right)E[W] \\end{aligned} \\]\n\\[ \\begin{aligned} &E_W[E[Y|T=1, W]-E[Y|T=0, W]] \\\\ &= \\left(\\delta + \\frac{\\beta_u}{\\alpha_u}\\right)(1) + \\left(\\beta_w - \\frac{\\beta_u \\alpha_w}{\\alpha_u}\\right)E[W] - \\left[\\left(\\delta + \\frac{\\beta_u}{\\alpha_u}\\right)(0) + \\left(\\beta_w - \\frac{\\beta_u \\alpha_w}{\\alpha_u}\\right)E[W]\\right] \\\\ &= \\delta + \\frac{\\beta_u}{\\alpha_u} \\end{aligned}\\]\n\\[ \\begin{aligned} Bias &= E_W[E[Y|T=1, W]-E[Y|T=0, W]] \\\\ &- E_{W,U}[E[Y|T=1, W, U] - E[Y|T=0, W, U]] \\\\ &= \\delta + \\frac{\\beta_u}{\\alpha_u} - \\delta \\\\ &= \\frac{\\beta_u}{\\alpha_u} \\end{aligned} \\]\n\n\nSensitivity Contour Plots\ntrue ATE인 \\(\\delta\\)는 아래와 같이 다시 정리할 수 있습니다.\n\\[ E_W[E[Y|T=1, W]-E[Y|T=0, W]] = \\delta + \\frac{\\beta_u}{\\alpha_u} \\]\n\\[\\begin{aligned} \\delta = E_W[E[Y|T=1, W]-E[Y|T=0, W]] - \\frac{\\beta_u}{\\alpha_u} \\end{aligned}\\]\n식을 한번 더 해석해보면 다음과 같습니다.\n\n\\(U\\)에 의해 생기는 bias인 \\(\\frac{\\beta_u}{\\alpha_u}\\)이 크다면 \\(E_W[E[Y|T=1, W]-E[Y|T=0, W]]\\)는 상쇄되고, \\(\\delta\\)는 \\(0\\)에 가까워짐\n\\(U\\)에 의해 생기는 bias인 \\(\\frac{\\beta_u}{\\alpha_u}\\)이 작다면 \\(E_W[E[Y|T=1, W]-E[Y|T=0, W]]\\)는 크게 변화하지 않고, \\(\\delta\\)는 \\(E_W[E[Y|T=1, W]-E[Y|T=0, W]]\\)과 큰 차이가 없음\n\n이에 대해서 그래프로 나타내보면 다음과 같습니다.\n\n그림은 (\\(\\frac{1}{\\alpha_u}\\), \\(\\beta_u\\))에 따른 \\(\\delta\\)의 변화 그래프입니다. 먼저 green curve 값을 해석해보겠습니다. \\(E_W[E[Y|T=1, W]-E[Y|T=0, W]]=25\\)로 고정했을 때, \\(\\frac{1}{\\alpha_u} = 1\\)이고, \\(\\beta_u = 25\\)라면 \\(\\delta = 0\\)이 됩니다. 따라서 green curve일 경우 (\\(\\frac{1}{\\alpha_u}\\), \\(\\beta_u\\))의 변화에 따른 \\(\\delta = 0\\) 일 때에 해당하는 곡선입니다. \\(\\delta = 0\\)이라는 의미는 관찰되지 않은 교란 요인 \\(U\\)에 의해 \\(E_W[E[Y|T=1, W]-E[Y|T=0, W]]\\)을 전부 설명한다는 의미와 같으며, \\(U\\)는 강력한 교란요인이라고 볼 수 있습니다. 결론적으로 green curve에 가까워지거나 혹은 green curve를 넘어설 경우 교란요인에 의해 영향을 많이 받으므로, 강건성이 떨어진다고 볼 수 있습니다. 정리하면, 관찰되지 않은 교란요인이 treatment와 outcome에 대해 미치는 영향의 방향은 알 수 없습니다. 이에 따라 민감도 분석에서는 관찰되지 않은 교란요인의 **크기**를 고려합니다. 위의 그림 예시처럼 민감도 분석을 통해 추정된 효과를 없앨 정도로 추정량을 변경하려면 관찰되지 않은 교란요인의 크기가 어느 정도여야 하는지를 확인할 수 있고, 도메인 지식을 활용하여 추정된 효과의 강건성을 주관적으로 결정할 수 있습니다.\n\n\nMore General Settings\n강의에서는 더 일반적인 민감도 분석 방법에 대해 소개합니다. \n\nAssess-ing Sensitivity to an Unobserved Binary Covariate in an Observational Study with Binary Outcome(1983)\nMaking sense of sensitivity: extending omitted variable bias(2020)\n\n이 중 두 번째 논문에 대해서 짧게 정리했습니다. \n이 논문에서는 partial \\(R^2\\)를 활용해서 linear regression에서 민감도분석을 수행하고 리포팅하기 위한 새로운 방식을 제안합니다. \n**주요 기여사항**\n1.  Robustness value 개발\n2.  partial \\(R^2\\)를 활용한 민감도분석 툴 개발\n3.  extreme scenario에 대한 분석 그래프 개발\n해당 논문 저자가 개발한 툴은 R, Python, Stata 등에서 이용할 수 있습니다.\n\n\n\npython : \n\nPySensemakr\npywhy\n\nR : sensemakr \n\n논문에서 나오는 example이 직관적이지 않아서 다른 블로그 예시를 참고했습니다. \n\n참고 : https://matteocourthoud.github.io/post/ovb/\n교육기간과 임금 사이의 관계에 관심이 있음\n교육기간과 임금 사이에는 많은 unobserved confounder가 존재함\n예시를 위해 unobserved confounder로 ability가 있다고 가정\nability는 omitted variable이지만 education과 wage에 영향을 미친다는 것을 알고 있다고 가정함\n\n\n\n\nlibrary(sensemakr)\nlibrary(tidyverse)\n#setwd(\"./posts/2023-02-07-sensitivity-analysis\")\ndf &lt;- read.csv(\"ex_data.csv\")[, -1] %&gt;% \n    mutate(gender = as.factor(gender))\ndf %&gt;% head(2)\n\n  age gender education wage\n1  62   male         6 3800\n2  44   male         8 4500\nfit &lt;- lm(wage ~ ., df)\nsummary(fit)\n\nCall:\nlm(formula = sleep_total ~ ., data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.7435 -2.6495  0.0466  1.3376  7.0845 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.618464   0.862433  14.631 4.59e-11 ***\nbrainwt     -9.246523  14.305157  -0.646    0.527    \nbodywt      -0.009216   0.013960  -0.660    0.518    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.476 on 17 degrees of freedom\nMultiple R-squared:  0.4766,    Adjusted R-squared:  0.4151 \nF-statistic: 7.741 on 2 and 17 DF,  p-value: 0.004072\n회귀분석 결과, 추정된 ATE는 약 96으로, 교육 기간이 한 단위 증가할 때, 임금은 약 96 증가합니다(education = 95.94). 하지만 실제로는 관찰되지 않은 교란요인(ability)이 존재하므로, 해당 추정량은 편향 추정량입니다(해당 데이터는 가상의 데이터이므로, 실제로는 수 많은 교란요인이 존재합니다).\n관찰되지 않은 교란요인의 크기에 따라 추정된 ATE의 강건성을 분석하기 위해 민감도 분석을 수행해보겠습니다. sensemakr 패키지의 sensemakr() 함수를 이용해서 간단히 할 수 있습니다.\nsens &lt;- sensemakr(model = fit, treatment = \"education\")\nsummary(sens)\n\nSensitivity Analysis to Unobserved Confounding\n\nModel Formula: wage ~ age + gender + education\n\nNull hypothesis: q = 1 and reduce = TRUE \n-- This means we are considering biases that reduce the absolute value of the current estimate.\n-- The null hypothesis deemed problematic is H0:tau = 0 \n\nUnadjusted Estimates of 'education': \n  Coef. estimate: 95.9437 \n  Standard Error: 38.7521 \n  t-value (H0:tau = 0): 2.4758 \n\nSensitivity Statistics:\n  Partial R2 of treatment with outcome: 0.1176 \n  Robustness Value, q = 1: 0.3044 \n  Robustness Value, q = 1, alpha = 0.05: 0.0627 \n\nVerbal interpretation of sensitivity statistics:\n\n-- Partial R2 of the treatment with the outcome: an extreme confounder (orthogonal to the covariates) that explains 100% of the residual variance of the outcome, would need to explain at least 11.76% of the residual variance of the treatment to fully account for the observed estimated effect.\n\n-- Robustness Value, q = 1: unobserved confounders (orthogonal to the covariates) that explain more than 30.44% of the residual variance of both the treatment and the outcome are strong enough to bring the point estimate to 0 (a bias of 100% of the original estimate). Conversely, unobserved confounders that do not explain more than 30.44% of the residual variance of both the treatment and the outcome are not strong enough to bring the point estimate to 0.\n\n-- Robustness Value, q = 1, alpha = 0.05: unobserved confounders (orthogonal to the covariates) that explain more than 6.27% of the residual variance of both the treatment and the outcome are strong enough to bring the estimate to a range where it is no longer 'statistically different' from 0 (a bias of 100% of the original estimate), at the significance level of alpha = 0.05. Conversely, unobserved confounders that do not explain more than 6.27% of the residual variance of both the treatment and the outcome are not strong enough to bring the estimate to a range where it is no longer 'statistically different' from 0, at the significance level of alpha = 0.05.\nUnadjusted Estimates of ’ education ’:는 기존 회귀분석 결과와 같습니다. Sensitivity Statistics:을 보면 partial \\(R^2\\)와 Robustness Value(RV) 등이 표기됩니다. 또한 해당 지표에 대한 해석도 함께 제시됩니다.\n\n\\(RV_1\\) : 측정되지 않은 교랸요인이 교육과 임금의 잔차 변동의 30.44%를 설명한다면 추정량을 0으로 만들기 충분함 or 충분하지 않음\n\n30.44%가 충분한지 or 충분하지 않은지는 분석가의 판단에 의존합니다. 또는 benchmark_covariates 옵션을 통해 관찰된 \\(X\\) 변수와 비교함으로써 추가적인 해석을 해볼 수 있습니다.\n\n Robustness value \n\\(RV_q\\)는 추정된 treatment effect의 약 \\((100 \\times q)\\)%를 설명하기 위해서 unobserved confounder의 효과가 얼마나 강력해야 하는지를 설명하는 지표입니다.\n\n\n\n\\(Z \\sim Y\\)의 영향과 \\(Z \\sim D\\)의 영향이 동일하다고 가정할 경우 \\(RV_q\\)를 유도할 수 있습니다.\n\\(R^2_{Y\\sim Z|X, D} = R^2_{D\\sim Z|X}=RV_q\\)일 때,\n\\[ \\begin{aligned} RV_q = \\frac{1}{2}(\\sqrt{f^4_q + 4f^2_q - f^2_q}), \\quad f = q\\cdot|\\frac{t}{df}|\\,\\, (cohen's\\,f) \\end{aligned} \\]\n\n\\(RV_q \\approx 1\\)일 경우 \\(Z\\)가 \\(Y\\)와 \\(D\\)의 모든 잔차 변동을 설명한다는 것을 의미함   \n\nstrong confounder\n\n\\(RV_q \\approx 0\\)일 경우 \\(Z\\)가 \\(Y\\)와 \\(D\\)의 모든 잔차 변동을 설명하지 못한다는 것을 의미함     \n\nweak confonder\n\n\n\n\nSensitivity Contour plot \nRobustness Value는 \\(R^2_{Y\\sim Z|X, D} = R^2_{D\\sim Z|X}\\)일 때를 가정하므로, \\(R^2_{Y\\sim Z|X, D} \\neq R^2_{D\\sim Z|X}\\)일 경우 그래프를 통해 대략적인 추이를 파악해볼 수 있습니다. \nplot(sens, xlab = \"Partial R^2 of ability with education\", \n     ylab = \"Partial $R^2$ of ability with wage\")\n\n그래프를 보면 Unadjusted는 관찰되지 않은 교란요인(ability)가 영향을 주지 않을 때를 의미합니다. 즉, 회귀분석 결과와 동일합니다. 우측 상단으로 갈수록 관찰되지 않은 교란요인의 효과가 증가하고, 빨간색 dot line에 도달했을 때, \\(\\hat{\\beta}_{education} = 0\\)이 됩니다. \n그래프를 보면 빨간색 dot line 위에 있는 값으로 \\(R^2_{Y \\sim Z|D,X} = 0.3\\), $ R^2_{D \\sim Z|X} = 0.3$ 정도로 생각해볼 수 있습니다. 논문에서 유도한 공식을 이용해서 bias 추정치를 구해보고 확인해보겠습니다. \n논문에서 partial \\(R^2\\)를 이용해서 유도한 bias 추정치는 다음과 같습니다. \n\\[ |\\hat{bias}| = \\sqrt{\\frac{R^2_{Y \\sim Z|D,X} \\cdot R^2_{D \\sim Z|X}}{1 - R^2_{D \\sim Z|X}}} \\cdot \\frac{sd(Y^{\\perp X, D})}{sd(D^{\\perp X})} \\]\nR_YZ = 0.3\nR_DZ = 0.3 \n\nDperpX &lt;- lm(education ~ age + gender, df)$residuals\nYperpXD &lt;- lm(wage ~ ., df)$residuals\n\nbias &lt;- sqrt((R_YZ*R_DZ/(1 - R_DZ)))*(sd(YperpXD)/sd(DperpX))\n\n95.94 - bias\n\n[1] 1.697537\n\\(\\hat{\\beta}_{education} = 95.94\\)이고, \\(|\\hat{bias}| = 94.24\\)이므로, 대략 \\(0\\)에 가까운 것을 확인할 수 있습니다. \n\n\nSensitivity contour plot using benchmark covariates \nsensitivity contour plot을 봤을 때, 관찰되지 않은 교란요인의 treatment와 outcome에 미치는 영향에 따른 bias 효과를 확인해볼 수 있지만, 실제로 이 bias가 큰지 혹은 작은지는 주관적인 판단에 의존합니다. 즉, 이전 예시에서 \\(R^2_{Y \\sim Z|D,X} = 0.3\\), \\(R^2_{D \\sim Z|X} = 0.3\\) 일 때, 추정된 회귀계수는 \\(0\\)이 되만, \\(R^2_{Y \\sim Z|D,X} = 0.3\\), \\(R^2_{D \\sim Z|X} = 0.3\\) 값이 큰지 혹은 작은지의 기준은 알 수 없습니다. \n이러한 기준 설정의 어려움을 극복하기 위해서 관찰된 설명변수를 벤치마크하여 관찰되지 않은 교란요인이 미치는 영향의 크기를 대략적으로 추측합니다. \n\\[ \\begin{aligned} k_D := \\frac{R^2_{D \\sim Z|X_{-j}}}{R^2_{D \\sim X_j|X_{-j}}}, \\quad k_Y := \\frac{R^2_{Y \\sim Z|X_{-j}, D}}{R^2_{Y \\sim X_j|X_{-j}, D}} \\end{aligned} \\]\n\\(k_D \\ge 1\\)일 때, \\(R^2_{D \\sim Z|X_{-j}} \\ge R^2_{D \\sim X_j|X_{-j}}\\)이므로 관찰되지 않은 교란요인이 사전에 지정한 설명변수 대비 Treatment에 미치는 영향이 크다는 의미로 볼 수 있습니다. \\(k_Y \\ge 1\\)일 때도 마찬가지로 관찰되지 않은 교란요인이 사전에 지정한 설명변수 대비 반응변수에 미치는 영향이 크다는 의미로 볼 수 있습니다.\nsens2 &lt;- sensemakr(model = fit, treatment = \"education\", \n                  benchmark_covariates = \"age\", \n                  kd = c(0.5, 1, 2), \n                  ky = c(0.5, 1, 2))\n\nplot(sens2)\n\nsensemakr() 함수에는 `benchmark_covariates` 옵션이 존재하며, \\(k_D\\), \\(k_Y\\)의 크기를 사전에 지정할 수 있습니다. 그래프를 해석해보면 관찰되지 않은 교란요인(ability)가 age의 두 배 정도의 설명력을 갖더라도, \\(\\hat{\\beta}_{education} = 67.61\\)로 값의 변화는 있지만 부호는 여전히 positive인 것을 볼 수 있습니다. \n옵션을 추가할 경우 해당 plot에서 통계적 유의성 또한 체크해볼 수 있습니다. \nplot(sens2, sensitivity.of = \"t-value\")\n\n통계적 유의성을 보면 관찰되지 않은 교란요인(ability)가 \\(1 \\times age\\)보다 약간 큰 정도의 설명력을 갖는다면, \\(\\hat{\\beta}_{education}\\)이 통계적으로 유의하지 않게 바뀔 수 있다는 것을 의미합니다. \nplot(sens2)\nadd_bound_to_contour(r2dz.x = 0.3, \n                     r2yz.dx = 0.3, \n                     bound_label = \"Something related to\\nboth outcome and treatment\")\n\n추가적으로 임의로 partial \\(R^2\\)를 설정해서 점을 찍어볼 수도 있습니다. \n\n\nSensitivity plots of extreme scenarios\nextreme scenario는 outcome의 거의 모든 잔차 변동을 관찰되지 않은 교란요인이 설명한다는 의미로, \\(R_{Y \\sim Z|D,X} = 1\\)을 의미합니다(옵션으로 \\(0.75, 0.5\\)일 때도 함께 제시됨). 그래프를 활용하여 extreme scenario일 때, \\(R^2_{D \\sim Z|X}\\)의 변화에 따라 추정된 회귀계수가 어떻게 바뀌는지를 시각화해볼 수 있습니다. \nsens3 &lt;- sensemakr(model = fit, treatment = \"education\", \n                  benchmark_covariates = \"age\", \n                  kd = c(1, 2, 3, 4), \n                  ky = c(1, 2, 3, 4))\nplot(sens3, type = \"extreme\", lim = 0.5)\nresult &lt;- plot(sens3, type = \"extreme\", lim = 0.5)\n\nresult$scenario_r2yz.dx_1[117:119,]\n\n    r2dz.x r2yz.dx adjusted_estimate\n117  0.116       1         0.7348541\n118  0.117       1         0.2712232\n119  0.118       1        -0.1912156\n\n x axis : \\(R^2_{D \\sim Z|X}\\) \ny axis : \\(\\hat{\\tau} = \\hat{\\tau}_{res} - \\hat{bias}\\) \nline : \\(R^2_{Y \\sim Z|D,X}\\)\n\n그래프를 보면 빨간색 dot line은 추정된 회귀계수가 0이 되는 경우에 해당합니다. solid line은 \\(R^2_{Y \\sim Z|D,X} = 1\\)일 때에 해당합니다. \\(R^2_{Y \\sim Z|D,X} = 1\\)일 때, 추정된 회귀계수가 0이 되기 위해서는 \\(R^2_{D \\sim Z|X} \\approx 0.117\\) 정도 되어야 하는 것을 확인할 수 있습니다.  \n또한, 왼쪽 하단에 빨간색 vertical line은 benchmark로 설정한 변수에 비해 confounder가 몇 배 더 강력한지를 나타내는 것으로 `kd = c(0.5, 1, 2)` 옵션에서 설정한 것과 같습니다. \n관찰된 설명변수 age가 education에 미치는 효과에 비해서 관찰되지 않은 교란요인이 education에 미치는 효과가 네 배 정도 클 때, \\(\\hat{\\beta}_{education} \\approx 0\\)이 되는 것을 확인할 수 있습니다. \n상식적으로 교육기간과 나이는 충분한 양의 상관관계가 존재한다고 생각할 수 있습니다. 따라서 관찰된 설명변수 age가 education에 미치는 효과에 비해서 관찰되지 않은 교란요인이 education에 미치는 효과가 네 배정도 클 때, \\(\\hat{\\beta}_{education} \\approx 0\\)이 된다는 의미는 ATE 추정량이 충분히 신뢰할 수 있고, 관찰되지 않은 교란요인에 강건하다는 것을 의미한다고 볼 수 있습니다(주관적인 해석).  \n\n\npywhy tutorial \nimport dowhy\nfrom dowhy import CausalModel\nimport pandas as pd\nimport numpy as np\nimport dowhy.datasets\nimport os\nfrom dowhy import CausalModel\ndat = pd.read_csv(\"posts/2023-02-07-sensitivity-analysis/ex_data.csv\", index_col = 0)\ndat.head()\ngdot = \"\"\"graph[directed 1 node[id \"age\" label \"age\"]\n                    node[id \"gender\" label \"gender\"]\n                    node[id \"education\" label \"education\"]\n                    node[id \"wage\" label \"wage\"]\n                    \n                    edge[source \"education\" target \"wage\"]\n                    edge[source \"gender\" target \"wage\"]\n                    edge[source \"age\" target \"wage\"]]\"\"\"\nmodel = CausalModel(\n            data = dat,\n            treatment=\"education\",\n            outcome=\"wage\", \n            graph = gdot\n        )\nidentified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\nprint(identified_estimand)\nestimate = model.estimate_effect(identified_estimand,\n                                 method_name=\"backdoor.linear_regression\")\nrefute = model.refute_estimate(identified_estimand, \n                               estimate,\n                               method_name = \"add_unobserved_common_cause\",\n                               simulated_method_name = \"linear-partial-R2\",\n                               benchmark_common_causes = \"age\",\n                               effect_fraction_on_treatment = [ 1,2,3]\n                              )"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PseudoLab Causal Inference Team",
    "section": "",
    "text": "Randomised Controlled Trial\n\n\n\n\n\n\n\nA/B Test\n\n\nRCT\n\n\n\n\n스터디 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\njinsoo shin\n\n\n\n\n\n\n  \n\n\n\n\n12. Causal Discovery from Observational Data\n\n\n\n\n\n\n\nCausal Discovery\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 11 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nSangdon & Junyoung\n\n\n\n\n\n\n  \n\n\n\n\n11. Difference-in-Difference(DID)\n\n\n\n\n\n\n\nDifference-in-Difference\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 10 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nBrady Kim & Minsang Namgoong\n\n\n\n\n\n\n  \n\n\n\n\n10. Instrumental Variables\n\n\n\n\n\n\n\nInstrumental Variables\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 9 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nMinsang Namgoon & Hojae\n\n\n\n\n\n\n  \n\n\n\n\n09. Unobserved Confounding Analysis\n\n\n\n\n\n\n\nUnobserved Confounding Analysis\n\n\nSensitivity Analysis\n\n\nSensemakr\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 8 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nEunhee & Sangdon\n\n\n\n\n\n\n  \n\n\n\n\n08. Estimation\n\n\n\n\n\n\n\nEstimation\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 7 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nMinsang Namgoong\n\n\n\n\n\n\n  \n\n\n\n\n07. Nonparametric Identification\n\n\n\n\n\n\n\nNonparametric Identification\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 6 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nMinsang Namgoong\n\n\n\n\n\n\n  \n\n\n\n\n06. Randomised Experiments\n\n\n\n\n\n\n\nRandomised Experiments\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 5 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nsohee kim\n\n\n\n\n\n\n  \n\n\n\n\n05. Causal Models\n\n\n\n\n\n\n\nCausal Models\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 4 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nseongsoo kim & hojae jeong\n\n\n\n\n\n\n  \n\n\n\n\n04. Graphical Models\n\n\n\n\n\n\n\nGraphical Models\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 3 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nseongchul hong\n\n\n\n\n\n\n  \n\n\n\n\n03. Potential Outcomes\n\n\n\n\n\n\n\nPotential Outcomes\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 2 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nJinsoo shin\n\n\n\n\n\n\n  \n\n\n\n\n02. Motivation\n\n\n\n\n\n\n\nMotivation\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 1 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\nJinsoo shin\n\n\n\n\n\n\n  \n\n\n\n\n01. Causal Inference 라이브러리 정리\n\n\n\n\n\n\n\npackages\n\n\nreference\n\n\n\n\n인과추론 라이브러리 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\neverybody\n\n\n\n\n\n\n  \n\n\n\n\n00. Casual하게 Causality 이해하기 소개\n\n\n\n\n\n\n\nnews\n\n\n\n\n스터디 소개\n\n\n\n\n\n\nJan 19, 2024\n\n\njinsoo shin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "PseudoLab Causal Inference Team",
    "section": "",
    "text": "about\n안녕하세요. 가짜연구소 Causal Inference팀입니다.\n데이터를 통한 문제해결력을 높이기 위해 Causal Inference를 함께 학습하고 있어요✌️\n한국어 자료가 많지 않은 인과추론을 많은 분들이 쉽게 접하실 수 있도록 기여하고자 합니다!\n\n\n\n인과추론팀 빌더\n\n\n\n이름\n소속\n소개\n\n\n\n\n신진수\n크래프톤 Data Analyst\nBlog / LinkedIn\n\n\n\n\n\nStudy : 인과추론 with Entertainment\n\n\n\n이름\n소속\n소개\n\n\n\n\n김소희\n티빙 Data Analyst\nLinkedIn\n\n\n김지연\n엔씨소프트 Data Analyst\n\n\n\n박시온\n넥슨코리아 Data Analyst\n\n\n\n박병수\n넥슨코리아 Data Analyst\nLinkedIn\n\n\n박이삭\n하이브IM Data Analyst\nLinkedIn\n\n\n유정현\n넥슨코리아 Data Analyst\nLinkedIn\n\n\n임종언\n넥슨코리아 Data Analyst\n\n\n\n조슬지\n넷마블에프앤씨 Data Analyst\nLinkedIn\n\n\n\n\n\nStudy : 인과추론 with Social Science\n\n\n\n이름\n소속\n소개\n\n\n\n\n박상우\n한국은행 Data Analyst\n\n\n\n정호재\n롯데캐피탈 Credit Analyst\nLinkedIn\n\n\n조인서\nKOICA Manager\nLinkedIn\n\n\n\n\n\nResearch : 인과추론 논문쓰기\n\n\n\n이름\n소속\n소개\n\n\n\n\n김성수\n가짜연구소 Data Analyst\n\n\n\n김준영\n가짜연구소 Manager\n\n\n\n\n\n\nTech Support\n\n\n\n이름\n소속\n소개\n\n\n\n\n김상돈\n베가스 Data Analyst\nLinkedIn"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html",
    "title": "10. Instrumental Variables",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀의 남궁민상, 정호재입니다.\nIntroduction to Causal Inference 강의의 아홉번째 챕터이며, 해당 챕터에서 다루는 내용은 아래와 같습니다.\n강의 영상 링크 : https://youtu.be/B0SRWteGoOw\n작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#contents",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#contents",
    "title": "10. Instrumental Variables",
    "section": "Contents",
    "text": "Contents\n\nIntro\nWhat is an Instrument?\nNo Nonparametric Identification of the ATE\nWarm-Up: Binary Linear Setting\nContinuous Linear Setting\nNonparametric Identification of the LATE\nIV in More General Settings"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#intro",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#intro",
    "title": "10. Instrumental Variables",
    "section": "1. Intro",
    "text": "1. Intro\nQ : 관찰되지 않은 교란 요인이 있을 때 어떻게 인과관계를 확인할 수 있나요?\nA : Frontdoor adjustment - Chap.5\n\n중간 매개변수를 사용하여 인과효과를 계산하는 방법\n\nA : Unconfounded children criterion - Chap.5\n\n하나의 conditioning set으로 처치변수 T의 자손 중에 결과변수 Y의 조상인 것들로 통하는 backdoor path를 모두 막는 방법\n\nA : Some other fancy application of do-calculus - Chap.5\n\n그래프가 아닌 statistical quantity를 이용한 일반적인 방법\n\nA : Set identification (bounds) - Chap.7\n\n관찰되지 않은 교란 요인의 interval을 좁혀보는 방법\n\nA : Sensitivity analysis - Chap.7\n\n관찰되지 않은 교란요인이 존재할때 정량적으로 영향력을 판단하는 방법\n\nA : Instrumental Variables(☆)\n\n다른 변수로 관찰되지 않은 교란요인의 영향을 없애는 방법"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#what-is-an-instrument",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#what-is-an-instrument",
    "title": "10. Instrumental Variables",
    "section": "2. What is an Instrument?",
    "text": "2. What is an Instrument?\n도구 변수란, 처치변수 T와에는 영향을 주면서 그 이외의 변수에는 영향을 주거나 받지 않는 변수를 의미합니다.\n\n2.1 Assumption\n1. Relevance\n\n도구변수 Z는 처치변수 T에 인과적 영향(상관성 존재)을 끼칩니다.\n\n\n2. Exclusion Restriction\n\n\n\n\n\n\n\n\n\n\n\n결과변수 Y에 대한 도구변수 Z 인과적 영향은 처치변수 T에 의해 완전히 중재됩니다.\n도구 변수 Z가 결과변수 Y에 영향을 미치기 위해선 반드시 처치변수 T를 통해야 합니다.\n\n3. Instrumental Unconfoundedness\n\n도구변수 Z에서 결과변수 Y간의 backdoor paths는 없습니다.\n도구변수 Z와 관찰되지 않은 교란 요인 U의 관계는 없습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n도구변수 Z와 관찰되지 않은 교란 요인 U의 관계가 없으므로 관찰된 교란 변수(W)를 차단하여 Instrumental variables를 사용할 수 있습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#no-nonparametric-identification-of-the-ate",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#no-nonparametric-identification-of-the-ate",
    "title": "10. Instrumental Variables",
    "section": "3. No Nonparametric Identification of the ATE",
    "text": "3. No Nonparametric Identification of the ATE\nQ : 도구 변수가 인과관계를 식별할 수 있다면, 왜 Chapter 6. Non-parametiric Identification에서 보지 않았을까요?\nA : 도구변수는 Non-parametiric Identification 방법이 아니기 때문입니다.\n\n가정이 필요 없을때 Non-parametiric Identification을 가질 수 있는 데 도구변수에는 3가정이 존재합니다.\n\n&gt; (FYI) Nonparametric Identification을 만족하는 조건\n\n\n[처치변수 T]와 [결과변수 Y의 ancestor이면서 처치변수 T의 자식노드인 어느 노드]와의 path는 차단할 수 있습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#warm-up-binary-linear-setting",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#warm-up-binary-linear-setting",
    "title": "10. Instrumental Variables",
    "section": "4. Warm-Up: Binary Linear Setting",
    "text": "4. Warm-Up: Binary Linear Setting\n\nAssumption\n\n\\(Y:= \\delta T + \\alpha_u U\\)\n\nSetting\n\n처치변수 T와 도구변수 Z는 binary\n\nAssociational difference for the Z-Y relationship :\n\n\\(E[Y | Z = 1] - E[Y | Z = 0]\\)\n\\(= E[\\delta T + \\alpha_u U | Z = 1] -E[\\delta T + \\alpha_u U| Z = 0]\\) ← exclusion restriction(2번째가정) and linear outcome assumptions\n\\(= \\delta(E[T | Z = 1] - E[T | Z = 0]) + \\alpha_u (E[U|Z=1] - E[U|Z=0])\\)\n\\(= \\delta(E[T | Z = 1] - E[T | Z = 0]) + \\alpha_u (E[U] - E[U])\\) ← instrumental unconfoundedness assumption(3번째가정)\n\\(= \\delta(E[T | Z = 1] - E[T | Z = 0])\\)\n\nWald estimand :\n\n\\(\\delta=\\frac{Cov(Y,Z) }{Cov(T,Z) }\\)\nRelevance Assumption으로 \\(E[T | Z = 1] \\not= E[T | Z = 0]\\) 을 만족합니다.\n\n도구변수 Z에서 결과변수 Y로 가는 backdoor path는 존재하지 않으므로 각 path의 영향을 살펴봅니다.\n또한 Causal effect가 있는 directed path를 계수들의 곱으로 표현할 수 있습니다.\n이를 대입하면 \\(\\delta = \\frac{\\alpha_z \\delta}{\\alpha_z}\\) 으로 변경할 수 있습니다.\n\nWald estimator :\n\n\\(\\hat\\delta=\\frac{\\frac{1}{n_1}\\sum_{i:z_i=1}Y_i -\\frac{1}{n_0}\\sum_{i:z_i=0}Y_i }{\\frac{1}{n_1}\\sum_{i:z_i=1}T_i -\\frac{1}{n_0}\\sum_{i:z_i=0}T_i }\\)\nZ→Y의 영향을 구한 후 Z→T의 영향을 나누어서 계산합니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#continuous-linear-setting",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#continuous-linear-setting",
    "title": "10. Instrumental Variables",
    "section": "5. Continuous Linear Setting",
    "text": "5. Continuous Linear Setting\n\nAssumption\n\n\\(Y:= \\delta T + \\alpha_u U\\)\n\nSetting\n\n처치변수 T와 도구변수 Z는 continuous\n\nAssociational difference for the Z-Y relationship :\n\n\\(Cov(Y,Z) = E[YZ]E[Y]E[Z]\\)\n\\(= E[(\\delta T + \\alpha_u U )Z] -E[\\delta T + \\alpha_u U]E[ Z]\\) ← exclusion restriction(2번째가정) and linear outcome assumptions\n\\(= \\delta E[TZ] + \\alpha_u E[UZ] - \\delta E[T]E[Z] - \\alpha_u E[U]E[Z]\\)\n\\(= \\delta (E[TZ] - E[T]E[Z]) + \\alpha_u (E[UZ] - E[U]E[Z])\\)\n\\(= \\delta Cov(T,Z) + \\alpha_u Cov(U,Z)\\)\n\\(= \\delta Cov(T,Z)\\) ← instrumental unconfoundedness assumption(3번째가정)\n\nWald estimand :\n\n\\(\\delta=\\frac{Cov(Y,Z) }{Cov(T,Z) }\\)\nRelevance Assumption으로 \\(Cov(T,Z) \\not=0\\) 을 만족합니다.\n\nWald estimator :\n\n\\(\\hat\\delta=\\frac{\\hat{Cov}(Y,Z) }{\\hat{Cov}(T,Z) }\\)\n\nTwo-stage least squares estimator\n\nLinearly regress \\(T\\) on \\(Z\\) to estimate \\(E[T | Z ]\\) . This gives us the projection of \\(T\\) onto \\(Z\\): \\(\\hat T\\).\nLinearly regress \\(Y\\) on \\(\\hat T\\) to estimate \\(E[\\hat T | Z ]\\) . Obtain our estimate \\(\\hat \\delta\\) as the fitted coefficient in front of \\(\\hat T\\).\n\n\n\n\n\n\n\n\n\n\n\n\\(\\hat T\\)는 \\(U\\)에 대한 함수가 아니므로 \\(U\\)에서 \\(T\\)로가는 path가 사라져서 backdoor path가 제거됩니다.\n※ 예시\nimport numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as sm\n\nnp.random.seed(12345) # 동일한 결과를 위해 시드 설정\nnum = 10000 # 데이터 수\n\nU = np.random.normal(size = num) # Unobserved Factors\nZ = np.random.normal(size = num) # Instrumental Variable\n\n# T는 U와 Z의 자식노드\nT = 3.0*U + 6.0*Z + np.random.normal(size = num) # Treatment\n\n# Y는 T와 U의 지식노드\nY = 15.0*U + 9.0*T + np.random.normal(size = num) # Outcome\n\ndata = pd.DataFrame({'T' : T, 'U' : U, 'Y' : Y})\n\n단순비교\n\n# 단순 비교\nsod_model = sm.ols('Y ~ T', data).fit()\n# 교란 변수를 누락하였기에 인과 효과가 잘못 추정됨\nsod_model.summary().tables[1]\n\n\n\n\n\n\n\n\n\n\n\n\n \ncoef \nstd err\n t\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n-0.1277\n0.134\n-0.953\n0.341\n-0.390\n0.135\n\n\nT\n9.9905\n0.020\n505.906\n0.000\n9.952\n10.029\n\n\n\n교란변수를 통제하지 않았을 때 인과효과는 9.9905로 나옴 0.9905만큼의 error가 발생합니다.\n\\(Y = Intercept + T + e\\)\n\n도구변수 활용\n\n\\[ (T → Y)의 인과효과 = \\frac {(Z → Y) path의 영향} {(Z → T) path의 영향} \\]\n# first stage model(Z -&gt; T)\nZ_to_T = sm.ols('T ~ Z', data).fit()\n# reduced model(Z -&gt; Y)\nZ_to_Y = sm.ols('Y ~ Z', data).fit()\n# first stage model\nZ_to_T.summary().tables[1]\n\n\n\n\n\n\n\n\n\n\n\n\n \ncoef \nstd err\n t\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n-0.0349\n0.032\n-1.103\n0.270\n-0.097\n0.027\n\n\nT\n6.0207\n0.032\n189.711\n0.000\n5.958\n6.083\n\n\n\n# reduced model\nZ_to_Y.summary().tables[1]\n\n\n\n\n\n\n\n\n\n\n\n\n \ncoef \nstd err\n t\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n-0.4725\n0.429\n-1.100\n0.271\n-1.314\n0.369\n\n\nT\n54.3108\n0.431\n126.122\n0.000\n53.467\n55.155\n\n\n\nZ_to_Y.params.Z/Z_to_T.params.Z\n계산결과 9.020754651013464로 실제 인과효과인 9에 근사합니다.\n\n2SLS\n\n인과 효과의 유의성, 신뢰구간을 확인하기 위해 2SLS를 사용합니다.\n# first stage\nt_hat = Z_to_T.predict()\ndata['T_hat'] =  t_hat\n\n# second stage\nThat_to_Y = sm.ols('Y ~ T_hat', data).fit()\n# second stage model\nThat_to_Y.summary().tables[1]\n\n\n\n\n\n\n\n\n\n\n\n\n \ncoef \nstd err\n t\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n-0.1575\n0.429\n-0.367\n0.714\n-0.999\n0.684\n\n\nT\n9.0208\n0.072\n126.122\n0.000\n8.881\n9.161\n\n\n\nThat_to_Y.params.T_hat\n추정 인과효과는 9.020754651013458이며, p-value가 매우 작아 인과효과가 유의하다고 판단할 수 있습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#nonparametric-identification-of-the-late",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#nonparametric-identification-of-the-late",
    "title": "10. Instrumental Variables",
    "section": "6. Nonparametric Identification of the LATE",
    "text": "6. Nonparametric Identification of the LATE\n앞에서 Linear setting에서 ATE를 계산하는 법을 봤습니다. 그런데 이건 너무 강력한 가정입니다.\nnonparametric한 상황(분포에 대한 가정이 없는 상황)에서 ATE를 구할 수는 없을까요? 완전한 ATE는 아니지만 구할 수 있습니다!\n\nIV 관련 Notation\n본격적으로 들어가기 앞서 몇 가지 표기법을 정리합시다\n\n\\(Z\\): 도구변수 (instrumental variable)\n\\(T\\): 처치변수 (treatment variable)\n\\(Y\\): 결과, 종속변수 (dependent variable)\n\n\\(Z \\rightarrow T \\rightarrow Y\\)로 가는 인과가 있다고 할 때,\n\n\\(Y(1) \\triangleq Y(T=1)\\)\n\\(T(1) \\triangleq T(Z=1)\\)\n\\(Y(Z=1)\\)처럼 \\(Z\\)에 intervene했을 때의 potential outcome \\(Y\\)의 값은 별다른 축약형을 가지지 않습니다.\n\n\n\nPrincipal Strata\n\\(Z\\)가 \\(T\\)에 어떻게 영향을 주느냐에 따라 데이터를 4가지 그룹으로 나눌 수 있습니다.\n\nComplier: \\(Z\\)가 시키는대로 하는 사람들.\n\n\\[ T(1)=T(Z=1)=1 \\qquad T(0)=T(Z=0)=0 \\]\n\nDefier: \\(Z\\)가 시키는 거 반대로만 하는 청개구리들.\n\\[ T(1)=T(Z=1)=0 \\qquad T(0)=T(Z=0)=1 \\]\nAlways-taker: \\(Z\\)에 상관 없이 treatment를 받는 사람들.\n\\[ T(1)=T(Z=1)=1 \\qquad T(0)=T(Z=0)=1 \\]\nNever-taker: \\(Z\\)에 상관 없이 treatment를 안 받는 사람들.\n\\[ T(1)=T(Z=1)=0 \\qquad T(0)=T(Z=0)=0 \\]\n\n💡 이 때, 위에 2개 그룹과 아래 2개 그룹은 다른 causal graph를 가집니다.\n\n\n\nLATE 구하기\nIV를 써도, unobserved confounding이 있다면 nonparametric한 상황에서의 ATE를 구할 수는 없습니다.\n하지만 약간의 가정을 추가해서 LATE (Local Average Treatment Effect) 또는 CACE (Complier Average Causal Effect)라고 불리는 걸 구할 수는 있습니다.\n💡 LATE (또는 CACE)는 아래와 같이 정의됩니다.\n\\(\\mathbb{E}[Y(T=1)-Y(T=0)\\:|\\:T(Z=1)=1,\\:T(Z=0)=0]\\)\nLATE를 구하기 위해서는 monotonicity(단조성)이라는 가정을 덧붙여야 합니다.\n\\(\\forall i, \\space T_i(Z=1) \\geq T_i(Z=0)\\)\n다르게 말하자면, 우리 데이터에 defier가 없다는 가정입니다.\nRelevance, exclusion restriction, instrumental unconfoundedness + monotonicity 가정이 만족될 때, LATE는 Wald estimand와 같습니다.\n\\(\\mathbb{E}[Y(1)-Y(0)\\:|\\:T(1)=1,\\:T(0)=0]= \\frac{\\mathbb{E}[Y|Z=1]-\\mathbb{E}[Y|Z=0]}{\\mathbb{E}[T|Z=1]-\\mathbb{E}[T|Z=0]}\\)\n\n\n혹시 유도 과정이 알고 싶나요?\n\n\\(Z\\)가 \\(Y\\)에 끼치는 causal effect는 아래와 같습니다.\n\\(E[Y(Z=1)-Y(Z=0)]\\)\n우리가 앞서 배웠던 4가지 그룹을 생각해볼까요? \\(Z\\)와 \\(T\\)의 값에 따라 아래와 같이 풀어 쓸 수 있습니다.\n\\(\\begin{aligned} \\mathbb{E}[…] &= \\mathbb{E}[…|T(1)=1,T(0)=0]\\:P(T(1)=1,T(0)=0) \\quad (complier) \\\\ &+ \\mathbb{E}[…|T(1)=0,T(0)=1]\\:P(T(1)=0,T(0)=1) \\quad (defier) \\\\ &+ \\mathbb{E}[…|T(1)=1,T(0)=1]\\:P(T(1)=1,T(0)=1) \\quad (always-taker) \\\\ &+ \\mathbb{E}[…|T(1)=0,T(0)=0]\\:P(T(1)=0,T(0)=0) \\quad (never-taker) \\end{aligned}\\)\n여기서 몇 가지 항은 자동으로 소거됩니다.\n\\(\\begin{aligned} \\mathbb{E}[…] &= \\mathbb{E}[…|T(1)=1,T(0)=0]\\:P(T(1)=1,T(0)=0) \\quad (complier) \\\\ &+ \\mathbb{E}[…|T(1)=0,T(0)=1]\\:P(T(1)=0,T(0)=1) \\quad (*defier) \\\\ &+ \\mathbb{E}[…|T(1)=1,T(0)=1]\\:P(T(1)=1,T(0)=1) \\quad (**always-taker) \\\\ &+ \\mathbb{E}[…|T(1)=0,T(0)=0]\\:P(T(1)=0,T(0)=0) \\quad (**never-taker) \\end{aligned}\\)\n*Defier의 경우, monotonicity 가정에 의해 존재하지 않습니다. 따라서 깔끔하게 무시 가능합니다.\n**Always-taker와 **Never-taker의 경우, \\(Z\\)와 \\(T\\) 사이에 (나아가 \\(Z\\)와 \\(Y\\) 사이에) causal effect가 존재하지 않습니다. 따라서 이 항들도 깔끔하게 무시합시다.\n이를 정리하면 다음과 같습니다.\n\\(\\mathbb{E}[Y(Z=1)-Y(Z=0)|T(1)=1,T(0)=0]=\\frac{\\mathbb{E}[Y(Z=1)-Y(Z=0)]}{P(T(1)=1,T(0)=0)}\\)\n이 때, complier는 \\(Z\\)의 값과 \\(T\\)의 값이 같으므로, 좌항의 \\(Y(Z=0)\\)과 \\(Y(Z=1)\\)를 \\(Y(T=0)\\)와 \\(Y(T=1)\\)로 대체할 수 있습니다. 그리고 instrumental unconfoundedness에 의해 우항도 다시 쓸 수 있습니다.\n\\(\\mathbb{E}[Y(T=1)-Y(T=0)|T(1)=1,T(0)=0] =\\frac{\\mathbb{E}[Y|Z=1]-\\mathbb{E}[Y|Z=0]}{P(T(1)=1,T(0)=0)}\\)\n여기에서 \\(P(T(1)=1,T(0)=0)\\)를 자세히 살펴봅시다. 전체 집단에서 \\((T=1|Z=0)\\)인 집단과 \\((T=0|Z=1)\\)인 집단을 제외한 게 \\((T(1)=1, T(0)=0)\\)인 집단이겠죠? 따라서 우항은 아래와 같이 다시 쓸 수 있습니다.\n\\(\\begin{aligned} &=\\frac{\\mathbb{E}[Y|Z=1]-\\mathbb{E}[Y|Z=0]}{1-P(T=1|Z=0)-P(T=0|Z=1)} \\\\ &=\\frac{\\mathbb{E}[Y|Z=1]-\\mathbb{E}[Y|Z=0]}{1-P(T=1|Z=0)-(1-P(T=1|Z=1))} \\\\ &=\\frac{\\mathbb{E}[Y|Z=1]-\\mathbb{E}[Y|Z=0]}{P(T=1|Z=1)-P(T=1|Z=0)} \\end{aligned}\\)\n그리고 마지막으로, \\(T\\)가 binary이므로 \\(T=1\\)에 대한 확률은 기대값으로 바꿀 수 있습니다.\n\\(\\begin{aligned} &=\\frac{\\mathbb{E}[Y|Z=1]-\\mathbb{E}[Y|Z=0]}{P(T=1|Z=1)-P(T=1|Z=0)} \\\\ &= \\frac{\\mathbb{E}[Y|Z=1]-\\mathbb{E}[Y|Z=0]}{\\mathbb{E}[T|Z=1]-\\mathbb{E}[T|Z=0]} \\quad (Wald\\;estimand) \\end{aligned}\\)\n\n💡 관점을 약간 바꿔 볼 수도 있습니다.\nQ. Wald estimand (\\(Z\\rightarrow Y\\) 인과 / \\(Z\\rightarrow T\\) 인과) 는 무엇을 나타내는 지표일까요?\n→ \\(Z\\)가 \\(T\\)에 어떤 식으로 영향을 주느냐에 따라, 집단을 4개 sub-population으로 나눌 수 있습니다. Wald estimand는 이 중 complier 집단의 ATE.\n→ 좀 더 강한 가정 (\\(T\\)와 \\(Y\\)가 linearity한 관계) 이 만족할 때는, 전체 집단의 ATE로 생각할 수도 있습니다.\nLATE에도 다음과 같은 한계가 있습니다\n\nmonotonicity가 항상 충족되는 건 아닙니다.\n상황에 따라, 전체 집단의 ATE가 필요하지 Local ATE가 궁금하지 않은 경우도 많습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#iv-in-more-general-settings",
    "href": "posts/Introduction_to_causal_inference_Instrumental_Variables/Instrumental_Variables.html#iv-in-more-general-settings",
    "title": "10. Instrumental Variables",
    "section": "7. IV in More General Settings",
    "text": "7. IV in More General Settings\n앞서서 \\(Y\\)가 \\(T\\)에 대한 linear equation으로 주어지는 경우를 다뤘었습니다. 이를 좀 더 확장해서 \\(Y\\)가 \\(T\\)에 대해 좀 더 복잡한 함수로 표현되는 경우도 생각해 볼 수 있습니다.\n\\[ Y:=f(T,W)+U \\]\n위와 같이 나타내며, 딥러닝 등을 이용해 \\(f\\)를 모델링할 수 있습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_intro/index.html",
    "href": "posts/Introduction_to_causal_inference_intro/index.html",
    "title": "00. Casual하게 Causality 이해하기 소개",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀입니다.\n지난 3개월 간 가짜연구소에서 “Casual하게 Causality 이해하기” 스터디가 진행되었습니다.\n해당 스터디를 통해 저희가 달성하고자 하는 목표는 크게 3가지입니다.\n\n◦ Causal Inference에 대한 기본적인 개념 학습\n◦ 문제 or ML 모델에 대한 원인 분석 능력 키우기\n◦ 공부한 내용을 정리해, Causal Inference 에 대한 한국어 자료 만들어보기\n\n\n인과추론을 공부하러 오신 분들이 저희가 작성한 블로그를 통해,\n한국어 자료가 많지 않은 인과추론에 더 쉽게 다가가셨으면 좋겠습니다!\n\n\n“Casual하게 Causality 이해하기” 스터디는 Brady Neal의 Introduction to Causal Inference 강의를 바탕으로 진행되었습니다.\n블로그 글 이전에 전체 챕터에 대한 노션 페이지 정리 자료를 보고 싶으신 분들은 가짜연구소 Causal Inference 아카이브를 참고해주시면 감사하겠습니다!"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Potential_Outcomes/Potential_Outcomes.html",
    "href": "posts/Introduction_to_causal_inference_Potential_Outcomes/Potential_Outcomes.html",
    "title": "03. Potential Outcomes",
    "section": "",
    "text": "Contents\n\nPotential Outcomes이란 무엇인가요? (aka. Neyman-Rubin Causal model)\n인과추론의 근본적인 문제\n인과추론의 근본적인 문제를 이해하는데 필요한 가정\n\n강의 영상 링크 : Chapter 2 - Potential Outcomes\n작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\n\n\n(1) Potential Outcomes이란 무엇인가요?\n◦  정의 : 각각의 Treatment Options 하에서, 볼 수 있는 모든 Outcomes 입니다.\n(같은 실험 대상에서 발생할 수 있는 모든 잠재적인 결과를 고려)\n◦  Potential Outcomes와 Observed Outcomes는 무엇이 다른가요?\n\nObserved Outcomes Y : 실험 대상에게 Treatment를 주었을 때, 발생한 결과\nPotential Outcomes Y(t) : 대상에게 Treatment를 주었을 때, 발생할 수 있는 결과\n→ Observed Outcomes Y ≠ Potential Outcomes Y(t)\n\n모든 Potential Outcomes는 잠재적으로는 관측 가능하나, 모두 관측되는 것은 아니에요!\n\nPotential Outcomes에 대한 직관\n\n◦  Intuition : 타임머신을 통해 시간을 되돌릴 수 있어서, 그 때 다른 action을 취했더라면 어떻게 되었을까요?\n◦  Example : 타이레놀 복용과 두통 \n    - Factual : 코로나 의심 증상으로 타이레놀을 먹었더니, 두통이 사라졌다\n                                                             &lt;\\(do(T=1)\\)&gt;                  &lt;\\(Y_i(1) = 1\\)&gt;\n    - Counterfactual : 타이레놀을 안먹었더니, 두통이 사라지지 않았다\n                                                       &lt;\\(do(T=0)\\)&gt;                  &lt; \\(Y_i(1) = 0\\)&gt;\n    → Potential Outcomes : 두통이 사라진 경우 & 두통이 사라지지 않은 경우\n    → Observed Outcomes : 두통이 사라진 경우  \n      \n    - 타임머신이 있어서 타이레놀 먹기 전으로 돌아갈 수 있어서, 타이레놀을 먹지 않은 경우를 관측할 수 있다면?\n      타이레놀은 나의 두통 해소에 Causal Effect를 측정할 수 있을 거에요!\n      하지만, 현실은 타임머신이 없……죠…….. (인과추론의 근본적인 문제에 해당됩니다)\n◦ Causation은 처치 (Treatment) 이후, Potential Outcomes에 대한 차이로 정의될 수 있습니다. \n\n처치에 대한 인과 효과 = (Treatment 받은 경우에 대한 Observed Outcomes) - (Treatment 받지 않은 경우에 대한 Potential Outcomes)\n타이레놀에 대한 인과효과 = (타이레놀을 먹은 후, 두통 여부에 대한 관측 결과) - (타이레놀을 먹지 않고, 두통에 대한 잠재적 결과)\n\n\n\n\n(2) Fundamental Problem of Causal Inference\n\nPotential Outcomes에서 본 것 처럼, 각 실험 대상에서 Potential Outcomes을 동시에 관찰하는 것은 불가능해요…!\n즉, 우리에게 ’만약’이라는 데이터 (Counterfactuals)은 존재하지 않습니다.\n\n1) Potential Outcomes에 대해 동시 관측이 불가능 (우린 타임머신 없어요)\n   - 동일한 실험 대상에 Treatment를 다르게 주고, 결과를 두 번 관측해도 될까요? No\n   → 두 번째 결과는 첫 번째 관측 결과에 영향을 받을 수 있습니다. \n2) Causal Effect 계산을 위해, Counterfactuals (Missing values)을 어떻게 해결하는지에 대한 부분이 중요합니다! \n   - 우리가 파악할 수 있는 부분 : Control Group (Treatment를 받지 않은 그룹)\n   - Causal Effect 추정을 위해 필요한 부분 : Counterfactuals (Treatment Group에서 Treatment가 없을 때 결과)\n   → Control Group이 Counterfactuals과 최대한 가깝게 설계해야 합니다.\n\n\n          (후반부의 Ignorability/Unconfoundedness 가정을 확인해주세요!)\n \n3) Selection Bias  : 실험 대상을 랜덤하게 할당 하지 않는 이상, 시스템적으로 발생하는 문제입니다.\n   - Control Group과 Counterfactuals 간의 차이 = Selection Bias\n   - 예시 : 고객에게 노출된 배너 광고를 고객이 볼지 안볼지 선택하는 건 선택 편향 문제를 야기할 수 있어요.\n\n   → 그룹 간 비교 가능하지 않은 상태라면, 광고로 인해 클릭을 (Causal Effect) 했다고 말할 수 없게됩니다.\n\n참고로, 결과가 관측되기 전까지는 Counterfactuals인지 Factuals인지 구분할 수 없습니다. 그래서 관측 전까지 해당 부분은 Potential Oucomes 입니다!\n\n💡 Causal Inference vs Machine Learning\n- Causal Inference : Potential outcomes까지 고려\n- Machine Learning : Potential Outcomes 고려가 필요하지 않고 Observed outcomes만 고려\n\n\n(3) 근본적인 문제를 이해하는데 필요한 가정 \n\nITE 계산의 어려움 : (2)번의 인과 추론의 근본적인 문제(Missing values)에서 보았던 것 처럼,\n개개인에 대한 효과 (ITE)에 대해서 Treatment 효과를 추정하기가 어려운 문제가 생겨요.\nATE 계산 :\nQ : 반면, ATE는 구할 수 있을까요? \n      A : Yes, 개인이 아닌 집단에 대한 평균 효과는 구할 수 있어요. \n           집단은 일반적으로 Control Group (대조군) vs Treatment Group (실험군)으로 나누어 측정합니다.\n           엄밀하게 말하면 Statistical Estimand를 구할 수 있습니다! (아래 그림에서는 1/3 이네요)\n\n\n\nQ : 그런데, 실제로 ATE가 계산이 가능한 걸까요?\n     A : No, 그 이유는 인과추론의 근본적인 문제인 Counterfactuals (Missing values) 때문이에요.\n          위의 그림에서는 Missing values (Selection Bias)를 무시하고 계산한 Statistical Estimand의 결과입니다.\n          하지만, 저희가 필요한 건 Causal Estimand입니다.\n\n\n                          **\"Association is not Causation\"**\n   → Selection Bias를 해소하기 위해서는 Control/Treatment 그룹간에 비교가 가능해야 합니다!\n\n\n\nPotential Outcomes Framework의 Missing values 문제를 해결하기 위한 가정을 배워봅시다!\n\n◦ Identification Assumption   \n  →  ATE (Average Treatment Effect)가 Associational Difference와 같아지기 위한 가정     \n     a. (Conditional) Exchangeability = Unconfoundness\n     b. Positivity = Overlap\n     c. No Interference\n     d. Consistency \n\n* SUTVA (Stable Unit-Treatment Value Assumption)   \n\n해당 가정은 No Interference와 Consistency를 결합한 부분이에요.\n\n\n\na1. Exchangeability (Ignorability)\n\n정의 : \\(Treatment \\perp (Y(1), Y(0))\\)\n→ Treatment와 발생한 결과(Outcome)은 독립 (Treatment와 관계없이 발생하는 결과는 같습니다!\n\n◦ \\(E[Y(1)|T=0] = E[Y(1)|T=1] = E[Y(1)]\\)\n◦ \\(E[Y(0)|T=0] = E[Y(0)|T=1] = E[Y(0)]\\)\n\n해당 가정을 크게 2가지 관점에서 바라볼 수 있습니다.\n\n◦ Ignorability : 관측되지 않은 Missing values를 고려하지 않아요.\n◦ Exchangeability : Treatment 그룹간은 서로 교환(비교) 가능합니다.\n\n가정의 기대효과\n\n◦ Confounder를(X, 과금수준) 랜덤하게 할당하는 효과를 얻을 수 있습니다 (Random Assignment)\n   = \\(X\\)가 \\(T\\)(프로모션, Treatment)에 할당되는 방식은 Coin Flip과 같아요\n→ 그렇게 되면, Treatment를 제외한 나머지 요인들에 대해, 평균적으로 동질하게 만들어줍니다!\n→ 순수하게 Treatment (프로모션)에 대한 Causal Effect (결제 효과)를 추정 가능하게 해줍니다. \n\n\n문제점 : 다양한 Confounders가 존재하는 현실 상황에서, 두 그룹이 Exchangeable하다고 \n가정하는 것은 다소 비현실적 일 수 있습니다. \n\n\n\na2. Unconfoundedness (Conditional Exchangeability)\n\n등장배경 : 위의 Exchangeability 가정의 문제점에서 말씀드렸던 것 처럼, Observational Study 환경에서는\n현실적이지 않은 가정일 수 있습니다. \n정의 : \\(Treatment|X \\perp (Y(1), Y(0))\\)\n\n 예시 :\n\n◦ 상황 : \\(X\\)(과금 수준)으로 인해, \\(T\\)(프로모션)의 순수한 효과를 알기 어려운 상황입니다.\n◦ 가정 :  Subgroup (고과금, 중과금, 저과금)이 주어졌을 때, Subgroup간 비교가 가능\n◦ 적용 : \\(X\\) (과금 수준)에 대한 Subgroup이 주어졌을 때, 프로모션 그룹은 교환 가능\n   → 이로 인해,  Y (결제)에 대한, Treatment (프로모션)의 효과를 파악할 수 있게 됩니다\n\n계산 방법 : \\(X\\)에 대한 Marginalisation 부분만 추가되고, 나머지는 Exchangeability와 동일합니다!\nConditional Exchangeability 가정을 이용해서 ATE를 구할 수 있습니다.\n\n\n\n문제점 : Unobserved Confounders(\\(W\\))\n\n◦ RCT (Randomized Controlled Trials) 환경이 아니면, 가정이 위배될 수 있습니다.\n◦ 또한 관측되지 않는 교란 변수가 많은 상황에서, Unconfoundedness는 테스트를 할 수 없는 가정이에요.\n    (그래서, 위 가정은 위배되기 쉽습니다ㅜㅜ)\n\n\n\n\nb. Positivity (Common Support)\n\n정의 : \\(0 &lt; P(T=1 |X=x) &lt; 1\\)\n→ 공변량 \\(X\\)이 주어졌을 때, Treatment가 골고루 할당되어야 해요.\n     즉, Treatment를 받은 그룹과 받지 않은 그룹이 특성이 유사해야 합니다!\nPositivity를 보는 다양한 관점\n\n\n조건부 확률 계산 : 해당 Positivity 가정이 없다면, Causal Effect를 추정할 수 없게 됩니다.\n    아래 조건부 확률의 분모 부분이 \\(P(T=1|X=x)\\) 또는 \\(P(T=0|X=x)\\) 0이 되는 문제가 생깁니다…!\n\nOverlap : 어떠한 Covariate \\(X\\)의 분포가 이상적일까요? \n     Treatment가 각각 주어졌을 때, Covariate에 대한 분포가 비슷해야 합니다!\n\n\nPostivity와 Unconfoundedness Tradeoff \n   : Machine Learning에서의 차원의 저주 처럼, Condition하는 Covariate의 차원이 커지면 커질 수록 Overlap이 되는 부분이 점점 줄어들게 됩니다. \n→ 즉, 더 많은 Covariates에 Condition을 줄 수록, Unconfoundedness 가정은 만족하기 쉬워지지만, 반대로 차원이 커지게 되어 Overlap (Positivity)가정은 만족하지 못할 확률이 높아집니다.\n\n\n\n\nc. No Interference\n\n정의 : \\(Y\\_i(t\\_1,...,t\\_{i-1},t\\_i,t\\_{i+1}...,t\\_n) = Y\\_i(t\\_i)\\)\n→ 개개인의 Outcome은 다른 사람의 Treatment에 영향을 받지 않아야합니다.\n예시 :\n\n◦ Treatment : 강아지 입양한 경우 - \\(do(T=1)\\) / 입양하지 않은 경우 - \\(do(T=0)\\)\n◦ Outcome : \\(Y\\_i(1)\\) - 행복함, \\(Y\\_i(0)\\) - 행복하지 않음\n◦ 실험 대상 개인의 Treatment에 대한 Outcome(행복)은 주변 대상으로부터 영향을 받지 않아야 해요.\n\n문제점 :\n\n◦ Node간 Connection이 있는 네트워크 데이터에서는 가정이 위배되기 쉽습니다.\n   (서로가 연결이 되어있기 때문이죠!)\n◦ 다른 사람의 영향을 받지 않아야 하지만, 실제로는 받는 경우가 매우 많습니다. 아래 그림 처럼요…….\n\n\n\nd. Consistency\n\n정의 : \\(T=t \\\\Rightarrow Y=Y(t)\\)\n→ 동일한 Treatment의 경우, 그에 따른 결과도 동일해야 합니다\n\n            “There are no multitple versions of Treatment”\n\n예시 : \n\n◦ Teatment : 강아지 입양한 경우 - \\(do(T=1)\\) / 입양하지 않은 경우 - \\(do(T=0)\\)\n◦ Outcome : \\(Y\\_i(1)\\) - 행복함, \\(Y\\_i(0)\\) - 행복하지 않음\n◦ Consistency 가정에 따르면, 강아지를 입양한 경우 \\(do(T=1)\\), 2개의 Outcome (\\(Y\\_i(1)\\), \\(Y\\_i(0)\\)) 중에서 \n    하나의 결과에 대해서만 관측이 되어야 해요.\n     → 아래와 같이 동일한 실험 대상에게 Treatment를 주었을 때, 다른 결과가 나온다면 가정에 위배가 된 것입니다.\n\n\n문제점 : 당연해보이는 가정이지만, 실제 실험에서는 그렇지 않은 경우도 많습니다!\n\n\n\ne. Trying it all together (Identifiability of the ATE)\n\n위에서 배운 4가지 가정을 모두 종합해서, Causal Effect를 Identify 할 수 있어요. \n\n\nTo be continued) 앞으로 인과추론의 다른 Framework인 Strcutural Causal Models에 대해 배울 예정입니다.\n\n\nReference\n◦ Lecture Notes : 2021 Summer Session on Causal Inference (박지용 교수님) [Link]\n◦ Books : 데이터 분석의 힘 (이토 고이치로 저) [Link]"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_DID/DID.html",
    "href": "posts/Introduction_to_causal_inference_DID/DID.html",
    "title": "11. Difference-in-Difference(DID)",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀의 김성수, 남궁민상입니다. \nIntroduction to Causal Inference 강의의 열 번째 챕터이며, 해당 챕터에서 다루는 내용은 아래와 같습니다.\n\nContents\n\nMotivation and Preliminaries\nDifference-in-Differneces Overview\nAssumptions and Proof\nProbelms with Difference-in-Differences\n\n◦ 강의 영상 링크 : Chapter 10 - Difference in Difference\n    작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\n1. Motivation\nQ. 인과관계를 밝히려면 어떻게 해야할까요?\nA. RCT, frontdoor adjustment, backdoor adjustment, do-calculus 등을 이용해 confounding factor를 통제하고 연관관계를 보세요 (~Chapter 7)\nQ. unobserved confounding factor가 있으면 어떡하죠?\nA. 몇 가지 가정을 통해 구간을 줄일 수도 있고 (Chapter 8) 도구변수를 이용해 unobserved confounder의 영향을 없앨 수 있습니다 (Chapter 9)\nQ. 괜찮은 도구변수를 찾는 게 너무 힘들어요.\nA. 도구변수 외에도, unobserved confounder를 처리하는 기법들이 이것저것 있습니다.\n→ 그 중 하나가 오늘 다룰 이중차분법(Difference-in-Differences)입니다!\n\nDID는 평행 추세를 가정합니다 (parallel trends assumption)\n쉽게 말해, 처치집단과 통제집단이 다를 수는 있지만 (= 변수의 값은 다를 수 있지만) 같은 추세로 움직인다는 가정 (= unobserved confounder의 영향은 두 집단에 동등하다) → 처치집단과 통제집단이 움직이는 추세가 다르다면, 이는 처치 때문이다 → 차분(difference)을 통해 confounder의 영향을 상쇄할 수 있습니다\n\n\n\n1-1 DID 활용 예시\n\n무기 프로모션 A와 방어구 프로모션 B의 수익을 비교해봅시다.\n우리는 인과관계를 추론하는 다양한 방법을 배웠으니, “단순히 올해에는 무기 프로모션 A가 110억의 수익을 냈고, B가 100억의 수익을 냈으니, 무기 프로모션이 10억 정도 더 성과가 좋았다” 로 단순히 분석하고 끝내면 안됩니다.\n그렇다면 왜 이러한 차이가 발생했을까?\n커뮤니티를 분석해보니, 2021.12월부터 무기 위주 업데이트가 되었다는 커뮤니티의 평가가 있었습니다.\n그럼 과연 무기 위주 업데이트가 프로모션의 수익에 영향을 미쳤을까?\nQ. “무기 위주 업데이트”가 프로모션 수익에 긍정적인 영향을 미쳤나?\n여기서 “무기 위주 업데이트”가 프로모션에 미친 Casual effect를 발라내기 위해 고려해야 하는 것은 아래와 같습니다.\n\n같은 시점에서 서로 다른 개체를 관찰한 자료에서 오는 차이\n\n\n각 개체마다 특성이 다를 수 있음. 즉,무기와 방어구는 전혀 다른 개체\n\n\n다른 시점에 따른 변수의 변화\n\n\n작년과 올해라는 시점의 변화\n\n\n\n\n \n무기 프로모션 A\n방어구 프로모션 B\n\n\n\n\n2021.05\n150억(A1)\n200억(B1)\n\n\n2022.05\n110억(A2)\n100억(B2)\n\n\n\n\n다른 시점에 따른 변수의 변화 차분\n\nA1 - A2 : 무기 프로모션의 시간에 따른 변화\nB1 - B2 : 방어구 프로모션의 시간에 따른 변화\n\n다른 개체를 관찰한 자료에서 오는 차이 차분\n\nA1 - B1 : 무기 업데이트 시작 전 무기 프로모션과 방어구 프로모션 간의 차이\nA2 - B2 : 무기 업데이트 시작 후 무기 프로모션과 방어구 프로모션 간의 차이\n\n이중 차분 δDD(Difference-in-Differences)\n(1) 시간적 특성을 제거 (A2-A1) - (B2-B1)(2) 다른 개체에서 오는 차이를 제거 (A2-B2) - (A1-B1)\n=&gt; Term = (2) Term(1) \n\n이렇게 Difference에 한 번 다시 Difference를 하기 때문에 Difference-in-Differences(DID)라 불리며, 이렇게 DID는 두 집단 간의 특징 차이를 제거하고, 시점에 따른 결과 변수의 변화가 얼마나 다르게 일어나는지 확인할 수 있습니다.\n참고 :NC Soft 단비 블로그\n그럼 DID를 이해하기 위해 알아야하는 선행 개념을 알아보겠습니다.\n\n\n\n1-2 Preliminaries\n앞 챕터에서 배운 평균처리 효과(ATE)를 떠올려 보세요.\nATE:\n\\[\n\\begin{aligned}\\\n\\mathbb{E}[Y(1)-Y(0)] &=\\mathbb{E}[Y(1)]-\\mathbb{E}[Y(0)] \\\\\\\n&=\\mathbb{E}[Y(1) \\mid T=1]-\\mathbb{E}[Y(0) \\mid T=0] \\\\\\\n&=\\mathbb{E}[Y \\mid T=1]-\\mathbb{E}[Y \\mid T=0]\n\\end{aligned}\n\\]\n위의 ATE가 성립하려면 만족해야 하는 가정은 Unconfoundedness였습니다.\n\n\\((Y(0), Y(1)) \\perp T\\)\nUnconfoundedness\n\nATT:\nDifference in Difference 에서 활용하는 새로운 Casual estimation은 ATT라고 하며 Treatment가 (T=1)일 때의 ATE입니다.\n아래의 수식과 그림을 보시죠.\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(1)-Y(0) \\mid T=1] &=\\mathbb{E}[Y(1) \\mid T=1]-\\mathbb{E}[Y(0) \\mid T=1] \\\\\\\n&=\\mathbb{E}[Y \\mid T=1](\\text { consistency })-\\mathbb{E}[Y(0) \\mid T=1] \\\\\\\n&=\\mathbb{E}[Y \\mid T=1]-\\mathbb{E}[Y(0) \\mid T=0] \\quad(Y(0) \\perp T) \\\\\\\n&=\\mathbb{E}[Y \\mid T=1]-\\mathbb{E}[Y \\mid T=0](\\text { consistency })\\\n\\end{aligned}\n\\]\n\n\n\n파란색 점: Control Group, 빨간색 점: Treamtment Group\n\n\n위 식을 만족시키기 위해서는 ATE와는 다르게 Unconfoundedness보다 약한 가정이 필요합니다.\n\n\\(Y(0) \\perp T\\)\nWeak Unconfoundedness \n\n\n\n2 OverView\nControl Group은 Treamtment(T=1)에 영향을 받지 않으니, 이 둘의 차이를 구하면 Unconfoundedness 가정 하에서 아래의 식과 같이 됩니다.\n\\(\\mathbb{E}[Y(1)-Y(0)\\mid T=1]\\) (Without Time)\n그럼 이제 Y-axis(Time)을 추가하여 시간에 대한 축을 나타내보고, ATT도 시간 Term을 넣어 일반화 시켜봅시다.\n\n\n\n파란색 점: Control Group, 빨간색 점: Treamtment Group\n\n\n여기서 Treatment를 받는 것은 오직 Treatment Administered(어떠한 처치를 실행) 이후의 오른쪽 상단에 있는 수식입니다. 즉, Treatment Group이며, 이때 Control Group은 어떠한 Treatment도 받지 않습니다.\n타임 t=0은 처치를 시행하기 전, t=1은 처치를 시행한 후로 두고 ATT에 Time Term(t)를 넣어 다음과 같이 일반화할 수 있습니다.\n\\[\n\\begin{aligned}\n\\text{ ATT estimand with time: } \\mathbb{E}\\left[Y_{1}(1)-Y_{1}(0) \\mid T=1\\right]\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[Y_{1}(1) \\mid T=1\\right]-{E}\\left[Y_{1}(0) \\mid T=1\\right](Counter Factual)\n\\end{aligned}\n\\]\n하지만 여기서 \\({E} \\left[Y_{1}(0) \\mid T=1\\right]\\) 는 Counterfactual 이기 때문에, 관측할 수 없습니다. 따라서 이때 Control Group의 결과를 활용하여 Counterfactual를 계산할 수 있게 만들어 줍니다.\n\n위 그림에서 보이는 실선과 같이 애초부터 Treatment를 받지 않은 Control Group을 Treatment Group에서 Counterfactual\n\\({E}\\left[Y_{1}(0) \\mid T=1\\right]\\) 을 대신합니다.\n따라서 Difference-in-Differences의 식은 다음과 같습니다.\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[Y_{1}(1)-Y_{1}(0) \\mid T=1\\right]=\n\\left(\\mathbb{E}\\left[Y_{1} \\mid T=1\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=1\\right]\\right)-\\left(\\mathbb{E}\\left[Y_{1} \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=0\\right]\\right)\n\\end{aligned}\n\\]\n여기서 첫 번째 Term \\(\\left(\\mathbb{E}\\left[Y_{1} \\mid T=1\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=1\\right]\\right)\\) 은 Treatment Group에서 만들어진 삼각형에서 높이와 같고 두번째 Term \\(\\left(\\mathbb{E}\\left[Y_{1} \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=0\\right]\\right)\\) Control Group에서 만들어진 삼각형의 높이와 같습니다.\n\n그리고 첫번째 Term과 두번째 Term을 차분(Difference)하는 것은 아래 그림과 같이 Purple line을 구하는 것과 같으며, 이는 우리가 구하고자 하는 Treatment에 의한 Causal estimand입니다.\n\nDID는 Time-Invariant(대상 또는 시간 차이에서 오는 이질성) Confounders에 대해 Robustness 한데, 그 이유는 다른 시점에 따른 변수의 변화 차분, 다른 개체를 관찰한 자료에서 오는 차이를 차분하기 때문입니다.\n\n\n3. Assumptions\n\n→(1) 위 그림에서 \\(\\mathbb{E}\\left[Y_{1}(0) \\mid T=1\\right]\\) 는 Counterfactual 이기 때문에, 관측할 수 없음\n(우리가 관측할 수 있는 것은 \\({E}\\left[Y_{1}(1) \\mid T=1\\right]\\))\n→(2) 처치를 받지 않는 Control Group의 결과를 활용하여 Counterfactual를 계산할 수 있게 만듦\n\n→(3) 위 그림에서 Control Group의 기울기를 통해 그어진 점선을 통해 Treatment Group에서 Counterfactual \\({E}\\left[Y_{1}(0) \\mid T=1\\right]\\)을 대신함\n→(4) Control Group의 기울기가 Treatment Group의 Counterfactual, 즉 \\({E}\\left[Y_{1}(0) \\mid T=1\\right]\\)을 대신하기 위한 Assumptions 이 필요\n\nConsistency Assumption\n\nExtended to Time Causal estimand → Statistical estimand\n\n*Counterfacutal Quantities \\({E}\\left[Y_{\\tau}(1) \\mid T=0\\right]\\) 와 \\({E}\\left[Y_{\\tau}(0) \\mid T=1\\right]\\)는 관측 불가하기 때문에 Consistency Assumption을 통해 Statistical estimand 로 추정할 수 없습니다.\n\nParalled Trends Assumption\n\nCounterfacual \\({E}\\left[Y_{1}(1) \\mid T=0\\right]\\)이 Control Group과 비슷하게 똑같이 움직인다는 가정\n\n\n\nParalled Trends Assumption\n\n\n\n우리가 알고 싶은것은 위 그림에서 저 Gray point가 Treatment Group의 Counterfactual \\(\\mathbb{E}\\left[Y_{1}(1) \\mid T=0\\right]\\) 인가를 알고 싶습니다.\n즉, 저 첫 번째 Blue line이 두 번째 Blue line과 같은지를 확인해야 하는 것이며, 이것은 두 선의 기울기가 같은가를 추정하는 것과 같은 문제⇒ 따라서 Parallel Trends Assumption이라고 합니다.\n위 가정에서 \\({E}\\left[Y_{0}(0) \\mid T=1\\right]\\)는 Consistency를 통해 \\({E}\\left[Y_0 \\mid T=1\\right]\\) 를 만들 수 없음. 따라서 하나의 가정이 더 필요합니다.\n\nNo Pretreatment effect Assumption\n\n어떠한 처치의 시점이 되기 전에는 Treatment Group에 어떠한 Treatment도 없다는 것을 가정\n\n\n\n3. Proof\n위에서 배운 가정을 활용하여, 증명해봅시다.\n우리가 보여주고자 하는 DID 수식은 아래와 같습니다.\n\\[  \n\\begin{aligned}  \n&\\mathbb{E}\\left[Y_1(1)-Y_1(0) \\mid T=1\\right]=\\left(\\mathbb{E}\\left[Y_1 \\mid T=1\\right]-\\mathbb{E}\\left[Y_0 \\mid T=1\\right]\\right)- \\\\  \n&\\left(\\mathbb{E}\\left[Y_1 \\mid T=0\\right]-\\mathbb{E}\\left[Y_0 \\mid T=0\\right]\\right)  \n\\end{aligned}  \n\\]\n(1) Consistency 충족하지 않는 Counterfacual Term을 좌변에 두고, Paralled Trend assumption을 통해 수식 전개\n\\[  \n\\begin{aligned}(Assumptions)\\mathbb{E}\\left[Y_{1}(0) \\mid T=1\\right] &=\\mathbb{E}\\left[Y_{0}(0) \\mid T=1\\right]+\\mathbb{E}\\left[Y_{1}(0) \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0}(0) \\mid T=0\\right] \\\\&=\\mathbb{E}\\left[Y_{0}(0) \\mid T=1\\right]+\\mathbb{E}\\left[Y_{1} \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=0\\right] \\\\&=\\mathbb{E}\\left[Y_{0}(1) \\mid T=1\\right]+\\mathbb{E}\\left[Y_{1} \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=0\\right] \\\\&=\\mathbb{E}\\left[Y_{0} \\mid T=1\\right]+\\mathbb{E}\\left[Y_{1} \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=0\\right]\\end{aligned}  \n\\]\n(2) 위에서 만들어진 수식을 아래의 식에 대입\n\\[  \n\\begin{aligned}\\mathbb{E}\\left[Y_{1}(1)-Y_{1}(0) \\mid T=1\\right] &=\\mathbb{E}\\left[Y_{1}(1) \\mid T=1\\right]-\\mathbb{E}\\left[Y_{1}(0) \\mid T=1\\right]\\\\&=\\mathbb{E}\\left[Y_{1} \\mid T=1\\right]-\\mathbb{E}\\left[Y_{1}(0) \\mid T=1\\right]\\end{aligned}      \n\\]\n(3) 결론\n\\[  \n\\begin{aligned}\\mathbb{E}\\left[Y_{1}(1)-Y_{1}(0) \\mid T=1\\right] &=\\mathbb{E}\\left[Y_{1} \\mid T=1\\right]-\\left(\\mathbb{E}\\left[Y_{0} \\mid T=1\\right]+\\mathbb{E}\\left[Y_{1} \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=0\\right]\\right) \\\\&=\\left(\\mathbb{E}\\left[Y_{1} \\mid T=1\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=1\\right]\\right)-\\left(\\mathbb{E}\\left[Y_{1} \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=0\\right]\\right)\\end{aligned}  \n\\]\n즉, 우리가 증명하고자 한 아래 식을 가정을 통해 성립함을 알 수 있습니다.\n\\[  \n\\mathbb{E}\\left[Y_{1}(1)-Y_{1}(0) \\mid T=1\\right]=  \n\\left(\\mathbb{E}\\left[Y_{1} \\mid T=1\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=1\\right]\\right)-\\left(\\mathbb{E}\\left[Y_{1} \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0} \\mid T=0\\right]\\right)  \n\\]\n\n\n4. Problems with Difference-in-Differnces\n\nViolations of Paralle Trends\n\nDID는 기본적으로 Parallel trands assumption을 따르지만 실제에선 이 가정을 따르지 않는 경우가 많습니다. \n\\(Violation: \\quad \\mathbb{E}\\left[Y_{1}(0)-Y_{0}(0) \\mid T=1\\right] \\neq \\mathbb{E}\\left[Y_{1}(0)-Y_{0}(0) \\mid T=0\\right]\\)\n\nDID procedures rely on different parallel trends assumptions (PTAs), and recover different causal parameters (Michelle Marcus and Pedro H. C. Sant’Anna)\n\n\nWe document a “robustness” versus “efficiency” trade-off in terms of the strength of the underlying Parelle Trends assumtions (Michelle Marcus and Pedro H. C. Sant’Anna)\n\n그럴때는, W라는 변수로 Conditioning하여 Backdoor path를 막아 Parallel Trends 가정이 성립되도록 할 수 있습니다.\nControl for relevant confounders\n\\(\\mathbb{E}\\left[Y_{1}(0)-Y_{0}(0) \\mid T=1, W\\right]=\\mathbb{E}\\left[Y_{1}(0)-Y_{0}(0) \\mid T=0, W\\right]\\)\n하지만 위 식에서 회귀분석에서 말하는 interaction term이 Treatment 와 Time 사이에 있다면, W라는 변수로 Conditioning 한다고 해서 Parallel Trends를 성립할 수 있도록 할 수 없다는 것을 주위하셔야 합니다.\n\\(Y:=\\ldots+T \\tau \\quad \\Longrightarrow \\quad \\text { Parallel trends violation }\\)\n\nParalle Trends is Scale-Specific\n\nthe parallel trends assumption이 만족한다고 해서, Y에 transoformation 또는 Scale을 취한 값이 parallel trends assumption를 만족한다고 할 수 없기 때문에 이를 주의하셔야 합니다.\n\\(\\mathbb{E}\\left[Y_{1}(0) \\mid T=1\\right]-\\mathbb{E}\\left[Y_{0}(0) \\mid T=1\\right]=\\mathbb{E}\\left[Y_{1}(0) \\mid T=0\\right]-\\mathbb{E}\\left[Y_{0}(0) \\mid T=0\\right]\\)\n이상으로 Chapter 10. Difference-in-Difference를 마치도록 하겠습니다.\n감사합니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Motivation/Motivation.html",
    "href": "posts/Introduction_to_causal_inference_Motivation/Motivation.html",
    "title": "02. Motivation",
    "section": "",
    "text": "Contents\n\nCausal Inference 란 무엇인가?\n심슨의 역설 (Simpson’s Paradox)\n상관관계는 인과관계를 의미하지 않는다\nCausation in Observational studies\n\n◦ 강의 영상 링크 : Chapter 1 - A Brief Introduction to Causal Inference (Course Preview)\n작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\n\n\n(1) Causal Inference 란 무엇인가?\n\nCausal Inference is concerned with a very specific kind of prediction problem :\nPredicting the results of an action, manipulation, or Intervention\n“Making Things Happen” (2003, Woodwrad)\n\n\n정의 : 현상(문제)에 대한 원인을 찾고 해당 원인에 대한 효과를 추론하는 것\n목표 : 발생한 현상에 대한 ‘Why’ 라는 질문에 대답하는 것 (Causal Structure를 기반으로)\nExample : Effect of \\(X\\) (독립변수) on \\(Y\\) (종속변수)\n\n\n - 이번 할인 이벤트(\\(X\\))로 고과금 PU(\\(Y\\))가 증가한 것 같은데, 어느 정도 효과가 있었을까요?\n - 어떠한 캠페인(\\(X\\))을 노출시키면, CTR(\\(Y\\))를 늘릴 수 있을까요?\n\n\n인과관계의 3가지 단계 (The Ladder of Causation)\n\n\n\nAssociation : \\(P(Y|observe(X))\\) &lt; Supervised Learning &gt;\n    ◦ 관찰된 데이터를 바탕으로 변수간의 연관성을 파악하는 단계 (What If I see ?)\nIntervention : \\(P(Y|do(X))\\) &lt; \\(do\\) : 실험 개입(통제)의 의미 &gt;\n    ◦ 만약 \\(X\\)(개입, 행동)으로 인해, \\(Y\\)(결과)가 어떻게 변화하는지 파악하는 단계\nCounterfactuals (Counter to fact) : 가정법\n    ◦ 가상의 현실 (실제로 관측되지 않는 상황)을 상상하는 단계\n    ◦ 실제로 일어나지 않았지만, 해당 상황이 발생했다면 (\\(X'\\)) 결과(\\(Y\\))가 달라졌을까?\n    ◦ 인과추론의 근본적인 문제 (Fundamental Problem of Causal Inference, 2장)\n\n\n\n\n\n(2) 심슨의 역설 (Simpson’s paradox)\n\n정의 : 데이터를 Subgroup으로 나눠서 보았을 때와 전체 데이터를 합해서 봤을 때,\n           결과가 서로 다른 경우 (통계적 연관성이 유지되지 않는 경우)\n예시 : COVID-27에 대한 치료법\n\n\n◦  목적 : COVID-27에 확진된 환자의 사망율을 낮추는 Treatment (A, B)를 선택\n◦  상황 : 치료법 B는 A보다 더 귀함 (치료법 A를 받는 비중 : 73%, B를 받는 비중 : 27%)\n◦  데이터 해석 : \n    - 데이터 전체로 본 경우 : 치료법 A를 받은 환자 사망율은 치료법 B보다 낮음\n    - Subgroup으로 나눠서 본 경우 : 각 환자 Condition별 사망율은 치료법 A가 B보다 높음\n\n\n◦ 동일한 데이터인데, 결과가 다른 이유는 무엇일까요?\n→ Weighted Sum : 치료법 A, B에 대한 사망율의 각 Condition(Subgroup)에 대한 가중치가 다르기 때문입니다.\n&lt;Non-uniformity of allocation of people to groups&gt;\n\n\n◦ 환자의 사망율을 낮추려면 어떤 치료법을 선택해야 할까요? 환자의 상태를 모른다면, 치료법을 제공할 수 없는 걸까요?\n→ 데이터의 Casual Structure에 따라, 치료법 선택해야 합니다!\n\n\n\n\n(3) 상관관계는 인과관계를 의미하지 않는다\n\nCorrelation : 엄밀하게는 변수간 선형적인 통계적 관계를 의미 (Linear Statistical Dependence)\nSpurious Correlations : 서로 연관성이 없는 변수가 높은 상관관계를 보이는 경우\n\n       → 데이터를 통한 의사결정 과정에서, 잘못된 판단을 하게 만들 수 있습니다\n\n통계학를 배우면 항상 나오는 이야기 입니다. 사례를 통해 이해해보도록 해요!\n사례 1 : 연간 니콜라스 케이지의 영화 출현 횟수와 연간 익사 사망사고 건수 \n\n\n◦  연간 니콜라스 케이지의 영화 출현 횟수와 연간 익사 사망건수는 높은 상관관계를 보입니다.\n◦  그러면, 케이지가 많은 수영하는 사람들이 수영장에 뛰어들도록 부추긴걸까요? No No!\n\n\n\n사례 2 : 신발을 신고 자는 것과 두통으로 일어났을 때 두통을 호소하는 것  \n\n\n◦  상황 : 신발을 신고 자는 것과 두통으로 일어났을 때 두통을 호소하는 것은 큰 상관관계가 존재합니다.\n◦  목표 : 우리는 해당 실험에서, 신발을 신고 자는 것이 일어났을 때 두통을 유발하는 지 인과관계를 찾고 싶어요!\n◦  방해요인 : 두 변수의 공통으로 영향을 주는 변수 &lt; 전날 술을 마신 것 &gt;\n    - Confounder : \\(X\\)(원인)와 \\(Y\\)(결과)에 동시에 영향을 주는 변수\n    - Collider : \\(X\\)(원인)와 \\(Y\\)(결과)에 동시에 영향을 받는 변수\n    → 인과추론을 어렵게 만드는 요인 중 하나입니다.\n◦  What to do? \n  → 일어났을 때 두통이 있는 것(\\(Y\\))의 원인이 신발을 신고 잠에든 경우(\\(X\\))라고 결론을 내리려면, 전날 음주 여부 (Confounder)에 대한 부분을 통제해야 합니다.\n\n\n\nTotal Association = Confounding Association + Causal Association \n→ 이 식을 통해 본 것 처럼, 상관관계는 인과관계를 의미하지 않습니다!\nCorrelation이 Causation과 같다는 것은 Cognitive Bias에 해당합니다. (인지편향, 경험에 의한 비논리적 추론)\n\n\n◦  Availability heuristic : 의사결정 시, 사람의 머릿속에 당장 떠오르는 것에 의존하는 경향\n◦  Motivated Reasoning : 결론에 대한 목표를 정해놓고, 그 주제에 대해서만 생각하는 경향\n◦  해당 인지적 편향으로 인해, 신발을 신고 자서 일어 났을 때 두통이 발생(?)\n◦  Bias : Causation과 Association을 다르게 만드는 요소\n    → 이러한 과정에서 Correlation을 Causation으로 착각하는 오류가 발생하게 됩니다.\n\n\n→ 앞으로 인과추론에 방해되는 요소를 어떻게 통제할 것인지에 (Bias Adjustment) 대해 학습할 예정이에요!\n\n\n(4) Causation in Observational studies\n→ 관측 환경 (Observational Studies, 통제되지 않은 환경)에서, 인과추론을 어떻게 할까요?\n\n◦  인과추론을 바라보는 관점 : Potential Outcomes (Chapter 2), Causal Models (Chapter4)\n◦  실험 설계 : Experiment Design (Chapter 5, 6)\n◦  인과효과 추정 : IPTW / Meta-Learner (Chapter 7), DID (Chapter 10), IV (Chapter 9) \n◦  그 외에도 여러가지 추정 방법이 존재합니다.\n\n\nTreatment : 인과 효과를 추정하기 위한 원인 변수에 해당 \nTreatment Effect : Treatment에 따른 효과\n\n        ◦ ITE (Individual Treatment Effect) : Treatment에 대한 개개인의 효과를 측정\n        ◦ ATE (Average Treatment Effect) : Treatment에 대한 전체 평균 효과를 측정\n           → 개개인에 대해 ITE를 파악할 수 없는 경우가 존재합니다. 그래서 ATE를 사용하곤 합니다.            \n\n\nObservational Study (관측 연구) vs Experimental Study (실험 연구)\n\n        ◦ Experimental Study : 연구자가 설명변수의 할당 수준에 대해 개입, 조절이 가능\n        ◦ Observational Study : 연구자가 X (설명변수)에 대해 조작, 개입없이 단순히 관찰\n          &lt; ~대부분 Analyst가 분석하는 환경은 Observational Study 이지 않을까요??..~&gt;\n\na. Potential(Counterfactual) Outcomes 관점\n\n정의 : Treatment Option에서 볼 수 있는 모든 잠재적인 결과를 반영한 Causal Effect를 바라보는 관점 \n          &lt; 실제로 관측되지 않은 Counterfactual한 결과도 포함 &gt;\n예시 : \n\n\n사례 1) 광고 노출과 클릭율 \n◦  Treatment : 유저에게 게임 광고 노출 (Treatment Option - 캠페인 A, 캠페인 B)\n◦  Outcome : \\(Y_i(1)\\) - 클릭, \\(Y_i(0)\\) - 클릭하지 않음\n사례 2) 약과 두통약 \n◦   Treatment : 약을 먹는 경우 - \\(do(T=1)\\) / 약을 먹지 않는 경우 - \\(do(T=0)\\)\n◦   Outcome : \\(Y_i(1)\\) - 두통 해소, \\(Y_i(0)\\) - 두통 지속\n\n\nCausal Quantity(Estimand, 인과 추정값)와 Statistical Quantity(Estimand, 통계적 추정값) 비교\n\n\n◦  상황 : Causal Quantity는 Counterfactuals로 인해, 직접적으로 계산할 수 없습니다.\n◦  대안 : 해당 부분 대신, Treatment가 주어진 상황에서의 Outcome인 Statistical Quantity로 계산할 수 있어요.\n◦  문제 : Confounding Association으로 Causal Quantity ≠ Statistical Quantity\n    → 그러면, Confounding Association을 어떻게 없애줄 수 있을까요?\n\n◦  해결방법 : Randomized Controlled Trial (RCT)가 해당 부분을 해결하는데 답을 줄 수 있습니다!\n◦  RCT : Control Group (대조군)과 Treatment Group (실험군)을 랜덤하게 할당해,\n             X가 Y에 영향을 미쳤는지 확인하기 위한 실험 설계입니다. (실무에서는 A/B 테스트라고 해요)\n\n◦  RCT 기대효과 : \n     1) 대조군과 실험군의 그룹간 동질성을 가정할 수 있음 (Comparable)\n     2) 잠재적인 Confounder를 평균적으로 동일하게 만들어주는 효과 (Confounder 효과 제거)\n          → 이로 인해, Causal Effect 측정이 가능해 집니다!\n◦  Randomization 어려움 : 매우 이상적이나, 아래 3가지 이유로 항상 Treatment를 랜덤화하는 건 어렵습니다.\n     1) 윤리적 이유 : 담배를 피지 않는 사람에게, 실험을 위해 담배를 피우게 한다면???\n     2) 실행 가능하지 않음 : Country-level의 실험인 경우, 전세계의 대통령이 되어야해요…\n     3) 불가능 : 암의 효과를 측정하기 위해, 태어날 때 사람의 DNA를 바꾸는 건 불가능합니다…\n     4) 번외로, A/B 테스트를 하는데 자원(시간과 비용)이 많이 들어가요ㅜㅜ\n\n\n\n앞으로 나올 내용 : 관측 환경이 실험 환경과(RCT)비슷하게 끔 만들어 주는 가정에 대해 배웁니다.\n\n       → Identifiability Conditions (Causal Quantity와 Statistical Quantity가 같아지기 위한 조건)\n\n◦   Unconfoundedness : 실험군과 대조군은 교환 (비교) 가능!\n◦   Positivity : Causal Effect를 계산하기 위한 수학적인 가정!\n◦   No Interference : 나의 Outcome은 다른 사람의 Outcome에 영향을 받지 않아야 함!\n◦   Consistency : Treatment에 대해서는 일관된 결과를 보여줘야 함!\n\n\n\nb. Causal Models 관점\n\n정의 : Causal Graph (DAG)를 바탕으로, Causal Effect를 바라보는 관점 \n질문 : \n\n\n\nQ : Causal Model을 바탕으로 Causal Effect를 측정하기 위해 어떠한 방법이 필요할까요?\n     A : Confounding Association이 생기지 않도록 Confounder를 조절/통제하는 방법이 필요해요.\n          아래 그림은 W가 주어졌을 때, Confounding Association이 사라진 부분을 나타내고 있습니다. \n          이 때, W (그림에서는 C)를 Sufficient adjustment set이라고 정의해요\n    → Chapter 3, 4에서 Confounder를 조절하기 위한 방법을 배웁니다! (Back/Frontdoor Adjustment, Do-calculus)\n\nQ : 인과관계를 파악하는 구조를 발견해야 할 것 같은데, 어떻게 발견할 수 있나요?\n     A : 해당 내용은 Causal Discovery (Chapter 11/12)에서 공부할 예정입니다. \n\n\nTo be continued) 앞으로 인과추론의 Framework와 인과 효과를 추정하기 위한 방법에 대해 배울 예정입니다.\n\n\n\nReference\n\n◦ Lecture Notes : 2021 Summer Session on Causal Inference (박지용 교수님) [Link]\n◦ Blog : Individualized treatment effect inference (van der Schaar 교수님, Figure1) [Link]"
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_RCT/RCT.html",
    "href": "posts/Introduction_to_causal_inference_RCT/RCT.html",
    "title": "06. Randomised Experiments",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀의 김소희입니다. \nIntroduction to Causal Inference 강의의 다섯 번째 챕터이며, 해당 챕터에서 다루는 내용은 아래와 같습니다.\n\nContents\n\nRandomized Experiments\nFrontdoor adjustment\n\n◦ 강의 영상 링크 : Chapter 5 - Randomised Experiments\n    작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\n\n\n(1) Randomized Experiments\n\nRandomized experiments are magic\n\n\nObservational study : 관측되지 않은 confounders의 존재가능성 때문에, unconfoundedness를 보장받거나 backdoor criterion가 존재하는지 알 수 없습니다.\nRandomized experiments : unobserved confounding의 가능성을 차단함으로써 unconfoundedness를 보장받고 backdoor criterion이 만족되는지 알 수 있게 됩니다.\n\n       ⇒ Randomization은 Association is causation을 성립하게 만들어줍니다!\n\nRandomized Control Trial (RCT)\n\n\n1. 2장에 나온 예시 \n    ◦ 변수 소개\n        - \\(T\\) (Treatment) : 신발을 신고 잔다\n        - \\(Y\\) (Outcome) : 다음 날 두통 여부\n        - \\(X\\) (Confounder) : 전날 밤 술에 취했는지 여부 \n    ◦ Observational study : 신발에 신고 자는 그룹(\\(T=1\\)) vs 벗고 자는 그룹(\\(T=0\\))의 그룹을 있는 그대로 나눕니다.\n        - 어떤 문제가 생길까요? Treatment / Control group간 비교 가능하지 않습니다!\n        ⇒ 즉, 신발 신고 잔 그룹(\\(T=1\\)) 중, 전날 술에 취한 사람의 비율(confounding)이 신발 벗고 잔 그룹에 비해\n            훨씬 높은 것을 볼 수 있어요.\n\n    ◦ Randomized experiment : 신발을 신고 잘지 벗고 잘지 여부를(treatment를) 동전 던지기로 결정합니다.\n        ⇒ 동전 앞뒷면이 나올 확률이 같으므로, 신발 신은 그룹과 벗은 그룹 내 전날 술에 취한 사람의 비율이 \n            거의 같아지게 됩니다.\n\n\n\nRandomized Experiments에 대한 3가지 관점 \n\n\n1. Comparability and Covariate balance\n  ◦ 처치 여부에 대한 랜덤화 : 처치 집단과 통제 집단의 다른 모든 조건을 같게 만들고(confounders 분포를 포함), \n        딱 하나 처치 여부만 다르게 합니다.\n        → 따라서 처치 집단과 통제 집단의 결과에 차이가 생길 경우 이를 처치 여부 때문이라고 할 수 있게 됩니다.\n    ◦ 처치 여부를 랜덤화 하는 것은 unobserved covariates까지도 covariate balance를 갖게 하는 효과를 가집니다.\n        그렇기 때문에 \\(T\\)가 \\(X\\)에 의해 결정되지 않아요. (\\(T{\\perp \\!\\!\\! \\perp} X\\))\n        \\[P(X|T=1)\\stackrel{d}{=}P(X) \\quad and \\quad P(X|T=0)\\stackrel{d}{=}P(X)\\]\n    ◦ Covariate balance : 처치 집단과 통제 집단에서 covariates \\(X\\)의 분포가 같음\n        \\[P(X | T=1) \\stackrel{d}{=} P(X|T=0)\\]\n         → “Covariate balance 이면, association is causation입니다”\n    ◦Covariate balance에 대한 부분을 \\(P(y|do(t)) = P(y|t)\\)을 통해 증명할 수 있는데요. 과정은 아래와 같습니다.\n\n    ◦ Randomization ⇒ Covariate balance ⇒ “Association is causation”\n2. Exchangeability\n  ◦ Exchangeability 의미 : Treatment 여부에 따라 아래와 같은 성질이 달라지지 않습니다.\n        - 그룹의 구성\n        - 평균적 결과\n    ◦ Exchangeability의 형식적 정의와 “Association is causation”의 도출과정은 아래와 같아요 &lt; textbook p.51 &gt;\n      \\[E[Y(0)|T=0] = E[Y(0)|T=1]\\] \\[E[Y(1)|T=1] = E[Y(1)|T=0]\\]\n    ◦ Treatment/Control 그룹이 교환 가능 : 앞면이 나온 사람을 처치 집단에 넣기로 하든 뒷면이 나온 사람을\n        처치 집단에 넣기로 하든 각 그룹의 Y에 대한 기댓값은 같습니다.\n\n3. No backdoor paths\n    ◦ T를 randomize하면 T는 더이상 인과적 parents를 가지지 않게 됩니다. \n        - \\(X\\) → \\(T\\)로 가는 edge가 사라져서 backdoor path가 끊김\n        - Unobserved variables도 마찬가지로 path가 끊김\n\n\n\n\n(2) Frontdoor Adjustment\n\nBackdoor adjustment를 다시 리마인드 해봅시다!\n\n        →  왼쪽처럼 빨간색 점선(backdoor path)를 통한 non-causal association이 존재할 때,\n              \\(W\\_2\\)와 \\(C\\)에 대해 각각 conditioning 함으로써 그 path를 차단할 수 있습니다.\n\n\nFrontdoor Adjustment 도입 배경 : Unobserved Confounders \\(W\\)\n\n\n    ◦ Q : \\(W\\)는 unobserved confounder이므로 conditioning을 할 수 없는 경우가 생깁니다. 이 경우 backdoor path를                  막을 수 없게 되는데요, 여전히 \\(T → Y\\)에 대한 casual effect를 identify 할 수 있을까요?\n \n    ◦ A : “Frontdoor path”를 통해 가능합니다.\n\n\n    ◦  직관 :\n       - 아래 그림에서 Backdoor path는 \\(T → W → Y\\)의 Confounding association 입니다.\n       - 우리가 관심이 있는 Causal association이 \\(M\\)를 통하고 있습니다.\n        → \\(M\\)에 집중하면, Causal association을 분리할 수 있습니다. \n\n\n\nFrontdoor Adjustment 3가지 Step \n\n\n0. Frontdoor Adjustment 과정\n    ◦  \\(T → M\\)에 대한 인과 효과 Identify\n    ◦  \\(M → Y\\)에 대한 인과 효과 Identify\n    ◦  앞의 2개의 스텝을 합쳐서, \\(T→ Y\\)에 대한 인과 효과를 Identify\n\n1. Frontdoor Adjustment : Step 1  &lt; \\(T → M\\)에 대한 인과 효과 Identify &gt; \n    ◦  \\(T → M\\)으로 가는 path에는 \\(Y\\)가 \\(T→W→Y→M path\\)에서 collider로 backdoor path를 막고 있어요.\n    ◦  따라서 \\(T → M\\)으로 가는 association은 causal association만 존재하게 됩니다.\n         ⇒ Empty set을 adjustment set으로 사용해, 아래와 같이 bacdkoor adjustment로 identify 가능합니다.\n             \\[P(m|do(t)) = P(m|t)\\]\n2. Frontdoor Adjustment : Step 2  &lt; \\(M → Y\\)에 대한 인과 효과 Identify &gt; \n    ◦  \\(M→ Y\\)에 \\(M→T→W→Y\\)의 backdoorpath가 존재하지만, 여기서는 \\(T\\)에 대해 conditioning해서\n         backdoor path를 막을 수 있어요.\n    ◦  Frontdoor adjustment는 backdoor adjustment를 응용한 버전이라고도 볼 수 있어요.\n        \\[P(y|do(m)) = \\sum_tP(y|m,t)P(t)\\]\n        ⇒ \\(T\\)를 sufficient adjustment set으로 사용해서 backdoor adjustment 적용할 수 있습니다.\n3. Frontdoor Adjustment : Step 3  &lt; 앞의 2개의 스텝을 합쳐서, \\(T→ Y\\)에 대한 인과 효과를 Identify &gt; \n    ◦  \\(T → Y\\) 의 인과 효과 규명을 위해 step1, 2를 chaining 하게 되면 아래와 식과 같습니다.\n         \\[P(y|do(t)) = \\sum_mP(m|do(t))P(y|do(m))\\]\n\n\n\nFrontdoor Adjustment Criterion\n\n\n◦ 만약 (\\(T\\), \\(M\\), \\(Y\\))가 frontdoor criterion를 만족시키고, positivity를 가정한 경우, step1과 step2의 공식을\n     step3와 합친식은 아래와 같습니다.\n         \n       \\[ P(y | do(t)) = \\sum_mP(m|t)\\sum_{t'}P(y|m, t')P(t') \\]\n◦ 변수 세트 \\(M\\)은 \\(T\\)와 \\(Y\\)에 관해, 다음 조건들이 참이면 frontdoor criterion을 만족시킨다고 할 수 있어요.\n     - \\(M\\)이 \\(T → Y\\)의 효과를 완전하게 매개\n          (complete mediation, 예시 : 모든 \\(T\\)에서 \\(Y\\)로 가는 causal path가 \\(M\\)을 지나는 경우)\n     - \\(T\\)에서 \\(M\\)으로 가는 unblocked backdoor path가 없음\n     - \\(M\\)에서 \\(Y\\)로 가는 모든 backdoor path가 \\(T\\)에 의해서 blocked\n\n\nTo be continued)  다음은 Nonparametric Identification 에 대해 배울 예정입니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Nonparametric_Identification/Nonparametric_Identification.html",
    "href": "posts/Introduction_to_causal_inference_Nonparametric_Identification/Nonparametric_Identification.html",
    "title": "07. Nonparametric Identification",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀의 남궁민상입니다.\nIntroduction to Causal Inference 강의의 여섯 번째 챕터이며, 해당 챕터에서 다루는 내용은 아래와 같습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Nonparametric_Identification/Nonparametric_Identification.html#do-calculus",
    "href": "posts/Introduction_to_causal_inference_Nonparametric_Identification/Nonparametric_Identification.html#do-calculus",
    "title": "07. Nonparametric Identification",
    "section": "\\(do\\)-calculus",
    "text": "\\(do\\)-calculus\n잠깐 지금까지의 내용을 되짚어 볼까요? 우리가 원하는 것은 treatment \\(T\\)와 outcome \\(Y\\)의 인과관계, 즉 \\(P(y\\:|\\:do(t))\\)를 밝혀내는 것입니다. 이것을 identification이라 하죠.\n\n아주아주 간단한 경우, 다른 노드 없이 \\(T \\rightarrow Y\\)라면 statistical quantity가 곧 causal quantity입니다. \\(P(y\\:|\\:do(t))\\:=\\:P(y\\:|\\:t)\\)입니다.\n그런데 여러 노드들 사이의 관계가 복잡하게 엮이면, \\(P(y\\:|\\:do(t))\\)를 계산하기 위해 더 복잡한 과정이 필요합니다.\n\ngraph factorization을 통해 노드들 사이의 관계를 쭉 늘어놓고\n우리가 관심없는 것들(\\(T\\)를 제외한 노드들)은 marginalize하고\n그리고 \\(do(t)\\) 항을 없애는 방향으로(observation으로 바꿔나가는 방향으로) 식을 정리한다.\n이 과정이 지난 시간에 배웠던 adjusting for confounders입니다.\n\n\n앞서 다룬 backdoor criterion과 frontdoor criterion은 이런 과정이 간단한 케이스입니다. DAG만 쓱 보고도 identify할 수 있는 특수 케이스죠. 그런데 특수 케이스 말고, 일반적인 접근법은 없을까요?\n당연히 있습니다! 이 과정에 쓰일 수 있는 3가지의 inference rule이 있는데, 이 일련의 규칙들이 바로 \\(do\\)-calculus입니다.\n\n\n\n누군가가 던진 질문에 주디아 펄 교수님이 직접 답변해주셨네요!\n\n\n 쉽게 말하자면, \\(do\\)-calculus는 일종의 논리적 법칙입니다. 우리가 유클리드 기하학의 5가지 공준을 이용해 피타고라스의 정리를 유도할 수 있는 것처럼, \\(do\\)-calculus의 3가지 규칙을 이용하면 인과적 관계를 규명할 수 있습니다. frontdoor & backdoor adjustment는 이 법칙들을 적용해서 유도한 공식 중 하나인 거고요.\n 밑에 자세히 설명하겠지만 \\(do\\)-calculus의 3가지 룰은 DAG에서 ‘이런 노드들은 무시해도 돼!’ 또는 ‘이런 intervention은 observation으로 취급해도 돼!’ (또는 그 역) 라고 말해줍니다. 쉽게 말해 복잡하게 얽혀있는 상관관계 항들을 쳐내면서 인과관계를 규명할 수 있게 도와주는 거죠.\n\n\\(do\\)-calculus의 의미를 쉽게 설명하자면…\nRule 1: ~~한 조건이 만족된다면, ~~에 대한 observation을 무시할 수 있다.\nRule 2: ~~한 조건이 만족된다면, ~~에 대한 intervention을 observation으로 간주할 수 있다.\nRule 3: ~~한 조건이 만족된다면, ~~에 대한 intervention을 무시할 수 있다.\n또는 3개의 규칙 모두…\nDAG를 ~~하게 조작했을 때, \\(Y\\)와 \\(Z\\)가 d-separated 관계라면 \\(Z\\)에 대한 항을 무시 or 치환할 수 있다.\n\n\n\\(do\\)-calculus를 위한 몇 가지 표기법\n\\(do\\)-calculus를 살펴보기 앞서, 이 챕터에서 자주 쓰이는 노드 이름은 다음과 같습니다.\n\n\\(T\\) 또는 \\(X\\): 조작변인. 우리가 그 영향력을 알아보고자 하는 노드들.\n\\(Y\\): 종속변인. 쉽게 말하면 결과. 우리가 궁극적으로 원하는 것은 \\(P(y\\:|\\:do(t))\\)를 알아내는 것.\n\n또, \\(do\\)-calculus에서는 causal graph를 이리저리 조작할 필요가 있습니다. 그래서 아래와 같은 표기법을 도입합니다.\n\nCausal graph \\(G\\)에 대해서, \n\n\\(G\\_{\\overline{X}}\\): 집합 \\(X\\)에 포함된 노드들의 incoming edge (\\(parent(X)\\rightarrow X\\)인 엣지)를 제거한 그래프\n\\(G\\_{\\underline{X}}\\): 집합 \\(X\\)에 포함된 노드들의 outgoing edge (\\(X \\rightarrow child(X)\\)인 엣지)를 제거한 그래프\n\n처음 보는 표기법이지만, 직관적으로 이해하기는 어렵지 않을 겁니다. 노드 사이의 관계가 폭포처럼 위에서 아래로 흐른다고 생각해봅시다.\n\n\\(G\\_{\\overline{X}}\\): 위를 막는다 → 부모로부터 오는 엣지 차단\n\\(G\\_{\\underline{X}}\\): 아래를 막는다 → 자식한테 넘겨주는 엣지 차단\n\n그럼 본격적으로 \\(do\\)-calculus의 3가지 규칙을 살펴볼까요?\n\n\nRule 1: Observation의 삽입 / 제거\n\\([P(y\\:|\\:do(t),z,w)=P(y\\:|\\:do(t),w)\\quad if \\quad Y {\\perp\\!\\!\\!\\perp}_{G_{\\overline{T}}} Z\\:|\\:T,W]\\)\n수학적인 의미를 풀어보자면, 우리가 \\(P(y\\:|\\:do(t))\\)를 계산하는 과정에서 \\(Z\\)에 대한 observation 항이 등장할 수도 있습니다. 그런데 이 때, \\(G\\_{\\overline{T}}\\)에서 \\((Y {\\perp\\!\\!\\!\\perp} Z\\:|\\:T,W)\\)가 성립하면 \\(Z\\)에 대한 observation 항은 무시할 수 있습니다.\n조금 직관적으로 풀어보자면, \\(Z\\)가 \\(Y\\)에 영향을 줄 수 있는 path가 없다면, \\(Z\\)에 대한 observation은 무시할 수 있다는 이야기입니다.\n\n예시 하나 살펴볼까요? 위와 같은 그래프를 생각해보자. (여기서는 \\(T\\) 대신 \\(X\\)라는 문자를 사용합니다)\n\\(X\\rightarrow Y\\)에 대한 인과관계를 밝히고 싶은데, \\(Z\\)를 신경써야 할까요?\n\\(do\\)-calculus의 1 규칙에 따르면, \\(G\\_{\\overline{X}}\\)에서 \\(W\\),\\(X\\)를 conditioning 했을 때, \\(Z\\)와 \\(Y\\)가 d-separation 되어있는 걸 볼 수 있습니다. 따라서 \\(Z\\)는 무시해도 됩니다!\n직관적으로 봤을 때도, \\(Z\\)가 바뀌었다고 \\(Y\\)에 영향을 주는 경로가 없죠? 지금 같은 경우는 그래프가 간단해 바로 보이지만, 그래프가 복잡해지면 유용하게 사용되겠죠?\n\n\nRule 2: Action ↔︎ Intervention의 교환\n그런데 Rule 1을 아무리 활용해도 식에 do-operator가 있는 걸 없앨 수는 없죠? 그걸 해주는 게 Rule 2입니다!\n\\([P(y\\:|\\:do(t),do(z),w)=P(y\\:|\\:do(t),z,w)\\quad if \\quad Y {\\perp\\!\\!\\!\\perp}_{G_{\\overline{T},\\underline{Z}}} Z\\:|\\:T,W]\\)\n수학적으로는, \\(G\\_{\\overline{T},\\underline{Z}}\\)에서 \\((Y {\\perp\\!\\!\\!\\perp} Z\\:|\\:T,W)\\)가 성립하면 \\(Z\\)에 대한 intervention은 observation과 같습니다. 즉, \\(Z\\)에 \\(do\\)-operator를 마음대로 삽입하거나 제거할 수 있습니다.\n직관적으로는, \\(Z\\)가 \\(Y\\)에 영향을 줄 수 있는 path가 directed path 밖에 없다면 \\(Z\\)에 대한 intervention은 observation과 같게 생각할 수 있다는 뜻입니다.\n\n마찬가지로 위와 같은 예시를 생각해봅시다. 여기서 \\(do(z)\\)를 관측값 \\(z\\)로 생각할 수 있을까요?\n\\(G\\_{\\overline{X},\\underline{Z}}\\)를 보면 \\(W,X\\)를 conditioning 했을 때, \\(Z\\)와 \\(Y\\)는 서로 영향을 주지 않습니다 (d-separation). 따라서 \\(do(z)\\)를 그냥 \\(z\\)로 생각해도 무방합니다.\n\n\nRule 3: Action의 삽입 / 제거\n규칙 3은 꽤나 복잡하게 생겼습니다.\n\\([P(y\\:|\\:do(t),do(z),w)=P(y\\:|\\:do(t),w)\\quad if \\quad Y {\\perp\\!\\!\\!\\perp}_{G_{\\overline{T},\\overline{Z(W)}}} Z\\:|\\:T,W ]\\)\n먼저 \\(Z(W)\\)가 뭘까요? \\(Z(W)\\)는 ’\\(Z\\)에 속한 노드 중에, \\(W\\)의 부모가 아닌 노드들의 집합’입니다.\n\n위 케이스에서, \\(Z\\)는 \\(W\\)의 부모가 아닙니다. 따라서 \\(Z(W)\\)는 그냥 \\(Z\\)와 같습니다. (여기서는 \\(Z\\)가 하나의 노드이지만, \\(Z\\)가 여러 노드의 집합을 의미하도록 확장될 수 있다는 것, 명심하세요!)\n따라서 \\(G\\_{\\overline{X},\\overline{Z(W)}}\\)는 위와 같이 변경됩니다. \\(Z\\rightarrow X\\)는 \\(\\overline{X}\\)에 의해, \\(W\\rightarrow Z\\)는 \\(\\overline{Z(W)}\\)에 의해 제거되었죠.\n\n반면 이 경우, 하나 있는 \\(Z\\)가 \\(W\\)의 부모이므로 \\(Z(W)\\)는 공집합입니다. 그래서 \\(\\overline{Z(W)}\\)를 한다고 해도 \\(X\\rightarrow Z\\)는 바뀌지 않습니다.\n그러면 두 케이스에서 \\(do(z)\\)는 무시할 수 있을까요? 두 케이스 모두, \\(X\\)와 \\(W\\)를 conditioning하면 \\(Z\\)와 \\(Y\\)는 d-separated이므로 \\(do(z)\\)는 무시 가능합니다!\n\n\nApplication\n앞서서 frontdoor & backdoor adjustment는 \\(do\\)-calculus를 통해 유도될 수 있다고 했습니다. 그 과정을 직접 살펴보면서 \\(do\\)-calculus가 실제로 어떻게 적용될 수 있는지 살펴봅시다.\n\nBackdoor Adjustment\n\n\n\n\nFrontdoor Adjustment\n\n\n\n\n\\(do\\)-calculus의 특징\n\\(do\\)-calculus는 아래와 같은 특징을 가집니다.\n\nComplete: \\(do\\)-calculus의 3가지 규칙을 이용하면 모든 identifiable causal estimand를 identify할 수 있습니다. 다시 말해, 이 세 가지 규칙을 이용해도 identify하지 못하는 케이스는 그냥 identify할 수 없는 케이스입니다.\nNonparametric: \\(do\\)-calculus는 데이터 분포에 대해 특별한 가정을 하지 않습니다. 특정 분포를 가정했을 때는 parametric identification이라고 불리며 nonparametric에 비해 더 많은 causal estimand를 알아낼 수 있다고 합니다. 하지만 이 코스에서는 다루지 않는다네요."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Nonparametric_Identification/Nonparametric_Identification.html#determining-identifiability-from-the-graph",
    "href": "posts/Introduction_to_causal_inference_Nonparametric_Identification/Nonparametric_Identification.html#determining-identifiability-from-the-graph",
    "title": "07. Nonparametric Identification",
    "section": "Determining Identifiability from the Graph",
    "text": "Determining Identifiability from the Graph\n\\(do\\)-calculus가 유용하고 좋긴 한데, frontdoor이나 backdoor criterion처럼 그래프만 언뜻 보고도 identifiability를 알아낼 수는 없죠. causal graph를 언뜻 보고도 찾아낼 수 있는, 특수한 causal estimand는 더 없을까요?\n있습니다! Unconfounded Children Identifiability라고 불리는 케이스입니다. 아래와 같은 경우죠.\n\n하나의 conditioning set으로 \\(T\\)의 자손 중에 \\(Y\\)의 조상인 것들로 통하는 backdoor path를 모두 막을 수 있다면, \\(P(y\\:|\\:do(t))\\)는 identifiable하다.\n\nfrontdoor adjustment와 비슷해 보입니다. 자세한 예시를 볼까요?\n\n위의 그림에서 frontdoor는 만족하지 않지만 confounded children은 만족한다. Confounded children criterion이 좀 더 일반적인 기준인 셈이죠.\n이 외에도 hedge condition이라는 게 있긴 한데, 이 강의에서는 다루지 않습니다."
  },
  {
    "objectID": "posts/Introduction_to_causal_inference_Nonparametric_Identification/Nonparametric_Identification.html#참고자료",
    "href": "posts/Introduction_to_causal_inference_Nonparametric_Identification/Nonparametric_Identification.html#참고자료",
    "title": "07. Nonparametric Identification",
    "section": "참고자료",
    "text": "참고자료\n\ndo-calculus adventures!\nDeriving the front-door criterion with the do-calculus\nchandan singh Causality"
  }
]