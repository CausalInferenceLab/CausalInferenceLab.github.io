---
title: "09\\. Unobserved Confounding Analysis"
author: "Eunhee & Sangdon"
description: |
  Introduction to Causal Inference ê°•ì˜ chapter 8 ì†Œê°œ   
date: now
categories: [Unobserved Confounding Analysis, Sensitivity Analysis, Sensemakr]
---

ì•ˆë…•í•˜ì„¸ìš”, ê°€ì§œì—°êµ¬ì†Œ Causal Inference íŒ€ì˜ ìµœì€í¬, ê¹€ìƒëˆì…ë‹ˆë‹¤.Â 

Introduction to Causal Inference ê°•ì˜ì˜ ì—¬ëŸë²ˆì§¸ ì±•í„°ì´ë©°, í•´ë‹¹ ì±•í„°ì—ì„œ ë‹¤ë£¨ëŠ” ë‚´ìš©ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

ê°•ì˜ ì˜ìƒ ë§í¬ : <https://youtu.be/IXNMYqUsBBQ>

Â  Â  ì‘ì„±ëœ ë‚´ìš© ì¤‘ ê°œì„ ì ì´ë‚˜ ì˜ëª»ëœ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”!

------------------------------------------------------------------------

## Contents

-   Â Overview
    -   Potential Outcomes, ATE ë¦¬ë§ˆì¸ë“œ
-   Bounds
    -   Observational-Counterfactual Decomposition
    -   No-Assumptions Bound
    -   Monotone Treatment Response (MTR)
    -   Monotone Treatment Selection (MTS)
    -   Optimal Treatment Selection (OTS)
-   Sensitivity Analysis
    -   Linear Single Confounder
    -   Towards More General Settings

## Overview

1.  Potential outcomes

-   ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ ìš°ë¦¬ê°€ ê°€ì§„ Control groupì„ í™œìš©í•˜ì—¬ ê´€ì¸¡ë˜ì§€ ì•Šì€ Counterfactual(Unobserved confounders)ê³¼ ìµœëŒ€í•œ ê°™ì•„ì§€ê²Œ í•´ì•¼í•¨
-   ì¸ê³¼ì¶”ë¡ ì˜ Consistency ì›ì¹™ (ë™ì¼ Tì˜ ê²½ìš° ê·¸ì— ëŒ€í•œ ê²°ê³¼ë„ ë™ì¼í•´ì•¼í•¨)Potential Outcomes
    -   í•˜ì–€ ìƒì¥ì˜ ê²½ìš° Consistí•˜ì§€ ì•Šê³  Counterfactualí•¨ (ì´ëŸ° ê²½ìš°ê°€ ë°”ë¡œ unobserved confounding factors)

![](img1.png)

2\. ATEì— ëŒ€í•´ ë‹¤ì‹œ í•œë²ˆ ì§šì–´ë³´ì.

$\mathbb{E}[Y(1)-Y(0)]=\mathbb{E}_W[\mathbb{E}[Y\,|\, T=1,W]-\mathbb{E}[Y\,|\, T=0,W]]$

-   What is ATE(Average Treatment Effect)?
    -   ì¼ë°˜ì ìœ¼ë¡œ A/B testingì—ì„œ ì‚¬ìš©ë˜ëŠ” ë¶„ì„ ë°©ë²•. ê°œì¸ì˜ ì¸ê³¼íš¨ê³¼ë¥¼ í‰ê· ì„ ë‚´ì–´ ì§‘ë‹¨ ë ˆë²¨ì—ì„œ ì„¤ëª…. ë³´í†µì˜ ê²½ìš° êµë€ë³€ìˆ˜(Confounders) $W$ê°€ ê´€ì¸¡ë  ê²½ìš° ì²˜ì¹˜ $T$(treatment)ì™€ ê²°ê³¼ $Y$ì— ëŒ€í•œ ì¸ê³¼ë¥¼ ì•„ë˜ì™€ ê°™ì€ ATE ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…í•  ìˆ˜ ìˆìŒ
    -   ìœ„ ATEì‹ì´ ì„±ë¦½ ê°€ëŠ¥í•œ ê²½ìš°: Confounderê°€ ëª¨ë“  ê·¸ë£¹ì— ë™ì¼í•˜ê²Œ ì‘ìš©í• ë•Œ ë‘ ê·¸ë£¹ì— Confounding factorsê°€ ë™ì§ˆí•˜ê²Œ ì‘ìš©í•˜ê¸° ìœ„í•´ì„ ? RCTë¥¼ í†µí•´ ê°€ëŠ¥!

::: column-margin
![](img2.png)
:::

-   í•˜ì§€ë§Œ ATEì˜ ê²½ìš° Outlierì— ì·¨ì•½í•œ ë‹¨ì  ë˜í•œ ìˆìŒ
    -   e.g. íƒ€ê²Ÿêµ°ê³¼ ëŒ€ì¡°êµ°ì˜ ë§¤ì¶œ ë¹„êµ ì§„í–‰ ì‹œ, ë§Œì•½ ëŒ€ì¡°êµ°ì— íƒ€ê²Ÿêµ°ì˜ êµ¬ë§¤ì•¡ì„ í•©ì¹œ ìˆ˜ì¤€ì˜ í•µê³¼ê¸ˆëŸ¬ê°€ í•œ ëª…ì´ë¼ë„ ì¡´ì¬í•œë‹¤ë©´?

::: column-margin
![](img3.png)
:::

-   Identify a point \[Identification\]
    -   ëª¨ë“  ë³€ìˆ˜ê°€ ê´€ì¸¡ê°€ëŠ¥í•˜ë‹¤ê³  ê°•í•œ ê°€ì •ì„ í•œë‹¤ë©´, ìš°ë¦¬ëŠ” í¬ì¸íŠ¸ê°€ ë˜ëŠ” ì§€ì ì„ ëª…í™•íˆ ì•Œ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

3\. ë§Œì•½ ê´€ì¸¡ ë¶ˆê°€(Unobserved Confounders)í•œ $U$ë¥¼ ë°œê²¬í•˜ì˜€ì„ë• ì–´ë–¡í•´ì•¼ í• ê¹Œ?

-   ì‚¬ì‹¤ ê´€ì¸¡ ë¶ˆê°€í•œ $U$ëŠ” ê±°ì˜ ëª¨ë“  ì—°êµ¬ì—ì„œ ê³ ë ¤í•´ì•¼í•  ì‚¬í•­

$\begin{aligned}\mathbb{E}[Y(1)-Y(0)] &=\mathbb{E}_W,_U[\mathbb{E}[Y\,|\, T=1,W,U]-\mathbb{E}[Y\,|\, T=0,W,U]] \\ &\approx \mathbb{E}_W[\mathbb{E}[Y\,|\, T=1,W]-\mathbb{E}[Y\,|\, T=0,W]]\end{aligned}$

-   Identify an interval (Partial identification)
    -   ATEë¥¼ í™œìš©í•˜ì—¬ ìµœëŒ€í•œ ê·¼ì‚¬ì¹˜ë¥¼ ì°¾ì•„ë³´ì
    -   í•œê°€ì§€ ê°€ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì´ ì•„ë‹Œ ê°€ì •ì˜ ë²”ìœ„ë¥¼ ë„“í˜€ \[ê·¼ì‚¬ì¹˜\], ì¦‰ ê·¸ ê°„ê²©(Interval)ì„ ì¶”ì •í•´ë³´ì

::: column-margin
![](img4.png)
:::

> ğŸ’¡Â 'NoÂ UnobservedÂ Confounding'Â isÂ Unrealistic.\
> Â  Â í˜„ì‹¤ ì„¸ê³„ì—ì„œ ëª¨ë“  ë³€ìˆ˜ë¥¼ ê´€ì¸¡í•œë‹¤ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë‹¤.

| 1   | **No-Assumptions Bound**         | ê°€ì •ì´ ì—†ë‹¤.                                                     | Interval ë§¤ìš° ê¹€   |
|------------------|------------------|------------------|------------------|
| 2   | **Monotone Treatment Response**  | ì²˜ì¹˜($T$)ëŠ” ì–¸ì œë‚˜ ê²°ê³¼($Y$)ì— ì˜í–¥ì„ ì¤€ë‹¤.                      | Â                   |
| 3   | **Monotone Treatment Selection** | ì²˜ì¹˜($T$)ë¥¼ ë°›ì€ êµ°ì´ ì–¸ì œë‚˜ ì¢‹ì€ Potential Outcomesì„ ë„ì¶œí•œë‹¤. | Â                   |
| 4   | **Optimal Treatment Selection**  | ê°œê°œì¸ì€ ì–¸ì œë‚˜ ìµœì ì˜ ì²˜ì¹˜($T$)ë¥¼ ë°›ëŠ”ë‹¤.                       | \- Interval ì§§ì•„ì§ |

ğŸ‘‰ ê°€ì •ì˜ ì •ë„ê°€ ì˜¬ë¼ê°ˆìˆ˜ë¡ í˜„ì‹¤ ì„¸ê³„ì—ì„œ ë°œìƒë˜ëŠ” í˜„ìƒì— ëŒ€í•œ ì„¤ëª…ë ¥ì´ ë–¨ì–´ì§„ë‹¤ëŠ” í•œê³„ì ì´ ì¡´ì¬í•œë‹¤. ê°•í•œ ê°€ì • ì•„ë˜ì—ì„œ ë‚˜ì˜¨ ê²°ë¡ ì¼ìˆ˜ë¡ ê·¸ ê²°ê³¼ì˜ ì‹ ë¢°ì„±ì„ ë–¨ì–´ì§„ë‹¤ëŠ” ëœ». ("The credibility of inference decreases with the strength the assumptions maintained." Manski)

ğŸ‘‰ Intervalì´ ì§§ì•„ì§ˆìˆ˜ë¡ ê²°ê³¼ì— ëŒ€í•œ ì‹ ë¢°ë„ë„ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ (ê°œê°œì¸ì´ ì–¸ì œë‚˜ ìµœì ì˜ ì²˜ì¹˜ë¥¼ ë°›ì„ í™•ë¥ ì€?)

## Bounds

> Â ğŸ’¡Â ì§€ê¸ˆë¶€í„°Â ê´€ì¸¡ì´Â ì–´ë ¤ìš´Â ë³€ìˆ˜ë“¤ì˜Â ë²”ìœ„ë¥¼Â ì¢íˆëŠ”Â ë°©ë²•ë¡ ë“¤ì—Â ëŒ€í•´Â ì•Œì•„ë´ë³´ì.

### Observational-Counterfactual Decomposition

ì´ì¯¤ì—ì„œ ë‹¤ì‹œë³´ëŠ” ATE. $\mathbb{E}[Y(1)-Y(0)]=\mathbb{E}_W[\mathbb{E}[Y\,|\, T=1,W]-\mathbb{E}[Y\,|\, T=0,W]]$

-   Observational : ê´€ì¸¡ë˜ëŠ” ë¶€ë¶„
-   Counterfactual : ê°€ì •ì„ í†µí•´ ë²”ìœ„ë¥¼ ì¢íˆëŠ” ë¶€ë¶„

![](img5.png)

> ğŸ’¡Observational-Counterfactual Decomposition\
> $\begin{aligned}\mathbb{E}[Y(1)-Y(0)] = \pi\mathbb{E}[Y|T=1] + (1-\pi)\mathbb{E}[Y(1)|T=0] \\ -\,\pi\mathbb{E}[Y(0)|T=1] - (1-\pi)\mathbb{E}[Y|T=0] \\ whereÂ \;\;Â \piÂ \triangleqÂ P(T=1)\end{aligned}$

### \[1\] No-Assumptions Bound

-   ê°€ì •: ë²”ìœ„(Bound)ì— ëŒ€í•œ ê°€ì •ì´ ì—†ì„ ë•Œ Interval Length êµ¬í•´ë³´ê¸°

**Bounded Potential Outcomes**

$Y(0)$ê³¼ $Y(1)$ì´ $0$ê³¼ $1$ ì‚¬ì´ì— ìˆë‹¤ê³  ê°€ì •í–ˆì„ ë•Œ $\mathbb{E}Y(1)-Y(0)$ì˜ ê²½ìš° ìŒì˜ 0ê³¼ 1, ì–‘ì˜ 0ê³¼ 1 ì‚¬ì´ì— ìˆë‹¤.

$-1 \le \mathbb{E}[Y(1)-Y(0)] \le 1$

ì´ë¥¼ ì¼ë°˜í™”í•œë‹¤ë©´, $\forall t, a \le Y(t) \le b$

$$ a-b \le \mathbb{E}[Y(1)-Y(0)] \le b-a $$

-   Trival length limit : $2(b-a)$

**No-Assumptions Bound**

-   observational-counterfactual decomposition ì™€ ê° ë°©ë²•ë¡ ì˜ ê°€ì •ì„ í™œìš©í•˜ì—¬ lower boundì™€ upper boundë¥¼ ì¶”ì •í•˜ëŠ” ê³¼ì •
    -   upper bound
        -   $\mathbb{E}[Y(1)-Y(0)] \le \pi\mathbb{E}[Y|T=1]+(1-\pi)b -\pi a-(1-\pi)\mathbb{E}[Y|T=0]$
    -   lower bound
        -   $\mathbb{E}[Y(1)-Y(0)] \ge \pi\mathbb{E}[Y|T=1]+(1-\pi)a -\pi b-(1-\pi)\mathbb{E}[Y|T=0]$$$ Interval\; Length = b-a $$
-   ìµœì´ˆì˜ ì‹œì‘ì—ì„œ ë²”ìœ„ë¥¼ ë°˜ìœ¼ë¡œ ì¤„ì´ê²Œ ë˜ëŠ” ê²ƒ. $2(b-a) \longrightarrow b-a$
-   ì–¸ì œë‚˜ 0ì„ í¬í•¨í•œë‹¤.

> ğŸ’¡ (ì•ìœ¼ë¡œ ê³„ì† ë‚˜ì˜¬) ì˜ˆì‹œ\
> (1) Potential outcomes ê°€ $0(a)$ ì™€ $1(b)$ ì‚¬ì´ì— ìˆìŒ\
> (2) $\pi = 0.3$ $\mathbb{E}[Y|T=1]=0.9$ $\mathbb{E}[Y|T=0]=0.2$\
> $$ -0.17 \le \mathbb{E}[Y(1)-Y(0)] \le 0.83 $$

### \[2\] Monotone Treatment Response (MTR)

> ê°€ì •: ì²˜ì¹˜(T)ëŠ” ì–¸ì œë‚˜ ê²°ê³¼(Y)ì— ì˜í–¥ì„ ì¤€ë‹¤ëŠ” ê°€ì • (Nonnegative, Nonpositive)

| Nonnegative MTR                        | Nonpositive MTR                         |
|------------------------------------|------------------------------------|
| $\forall i\; Y_i(1) \ge Y_i(0)$        | $\forall i\; Y_i(1) \le Y_i(0)$         |
| $0Â \leÂ \mathbb{E}[Y(1)-Y(0)]Â \leÂ 0.83$ | $-0.17 \le \mathbb{E}[Y(1)-Y(0)] \le 0$ |

1.  Nonnegative MTR (lower bound ë¬´ì‹œ)
    -   ì²˜ì¹˜ëŠ” ì–¸ì œë‚˜ ê²°ê³¼ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ì¤€ë‹¤.

$\forall i\; Y_i(1) \ge Y_i(0)$

-   ITE (Individual Treatment Effect) $a - b \ge 0$
-   ATE (Average Treatment Effect) $\mathbb{E}[Y(1)-Y(0)] \ge 0$

1.  Nonpositive MTR (upper bound ë¬´ì‹œ)
    -   ì²˜ì¹˜ëŠ” ì–¸ì œë‚˜ ê²°ê³¼ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ì¤€ë‹¤.Â 

$\forall i\; Y_i(1) \le Y_i(0)$

-   ITE (Individual Treatment Effect) $a - b \le 0$
-   ATE (Average Treatment Effect) $\mathbb{E}[Y(1)-Y(0)] \le 0$

### \[3\]Monotone Treatment Selection (MTS)

> ê°€ì •: ì²˜ì¹˜($T$)ë¥¼ ë°›ì€ íƒ€ê²Ÿêµ°(Target)ì´ ëŒ€ì¡°êµ°(Control)ë³´ë‹¤ ì–¸ì œë‚˜ ì¢‹ì€ Potential Outcomes ë„ì¶œí•œë‹¤. (MTS Upper Bound)

-   $\mathbb{E}[Y(1)|T=1] \ge \mathbb{E}[Y(1)|T=0]$
-   $\mathbb{E}[Y(0)|T=1] \ge \mathbb{E}[Y(0)|T=0]$

$$ \mathbb{E}[Y(1)-Y(0)] \le \mathbb{E}[Y|T=1] - \mathbb{E}[Y|T=0] $$

> ğŸ’¡ ê·¸ëŸ¬ë©´ ì´ì œ MTS Upper Boundì— nonnegative MTRì„ í•©ì³ë³´ì.\
> ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ë” ì¢ì€ Interval lengthë¥¼ ê²Ÿí•  ìˆ˜ ìˆë‹¤!

| No Assumptions          | $-0.17 \le \mathbb{E}[Y(1)-Y(0)] \le 0.83$ |
|-------------------------|--------------------------------------------|
| MTS Upper Bound         | $-0.17 \le \mathbb{E}[Y(1)-Y(0)] \le 0.7$  |
| nonnegative MTR         | $0 \le \mathbb{E}[Y(1)-Y(0)] \le 0.83$     |
| do combine. (MTS + MTR) | $0 \le \mathbb{E}[Y(1)-Y(0)] \le 0.7$      |

### \[4\]Optimal Treatment Selection (OTS)

> ê°€ì •: ê°œê°œì¸ì€ ì–¸ì œë‚˜ ê·¸ë“¤ì—ê²Œ ìµœì ì˜ ì²˜ì¹˜(Optimal Treatment)ë¥¼ ë°›ëŠ”ë‹¤.

> ğŸ’¡ OTS Assumption\
> (1) Treatment Group (íƒ€ê²Ÿêµ°) $T_i = 1 \Longrightarrow Y_i(1) \ge Y_i(0)$\
> (2) Nontreatment Group (ëŒ€ì¡°êµ°) $T_i = 0 \Longrightarrow Y_i(0) > Y_i(1)$Â 

**\[4-1\] ë°©ë²•ë¡ 1**

observational-counterfactual decomposition

-   OTS Upper Bound 1 : $\mathbb{E}[Y(1)|T=0] \le \mathbb{E}[Y|T=0]$
-   OTS Lower Bound 2 : $-\mathbb{E}[Y(0)|T=1] \ge -\mathbb{E}[Y|T=1]$

$$ Interval\; Length = \pi\mathbb{E}[Y|T=1]+(1-\pi)\mathbb{E}[Y|T=0]-a $$

| No Assumptions | $-0.17 \le \mathbb{E}[Y(1)-Y(0)] \le 0.83$ |
|----------------|--------------------------------------------|
| OTS Bound 1    | $-0.14 \le \mathbb{E}[Y(1)-Y(0)] \le 0.27$ |

ì—¬ì „íˆ 0ì„ í¬í•¨í•˜ê³  ìˆëŠ”ë°.....

**\[4-2\] ë°©ë²•ë¡ 2** : Bound the identifies the sign!

observational-counterfactual decomposition

-   OTS Upper Bound 2 : $\mathbb{E}[Y(1)|T=0] \le \mathbb{E}[Y|T=1]$
-   OTS Lower Bound 2 : ì•Œì•„ì„œ í•´ë³´ë˜ìš”...

| No Assumptions | $-0.17 \le \mathbb{E}[Y(1)-Y(0)] \le 0.83$ |
|----------------|--------------------------------------------|
| OTS Bound 1    | $-0.14 \le \mathbb{E}[Y(1)-Y(0)] \le 0.27$ |
| OTS Bound 2    | $0.07 \le \mathbb{E}[Y(1)-Y(0)] \le 0.76$  |
| do combine     | $0.07 \le \mathbb{E}[Y(1)-Y(0)] \le 0.27$  |

## Unobserved Confoundingì´ ê³¼ì—° ê´€ì¸¡ ì—°êµ¬ì—ë§Œ ì ìš©ë˜ëŠ” ì´ìŠˆì¼ê¹Œ?

> ğŸ’¡ ì‹¤í—˜ ì—°êµ¬(Experimental Study)ì—ì„œ ë°œìƒí•˜ëŠ” Unobserved Confounding factors

-   ê´€ì¸¡ë˜ì§€ ì•ŠëŠ” êµë€ ë³€ìˆ˜ê°€ RCT ê¸°ë°˜ì˜ ì‹¤í—˜ì—ì„œëŠ” ì „í˜€ ì´ìŠˆê°€ ë˜ì§€ ì•Šì„ê¹Œ?
    -   RCT (Randomised Controlled Trial) ëœë¤í™” ì‹¤í—˜ (RCT ìˆ˜í–‰ ëª©ì : ê·¸ë£¹ì˜ ë™ì§ˆì„±)
    -   ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì´ìƒì ì¸ RCT ê¸°ë°˜ A/B testëŠ”...
    -   íƒ€ê²Ÿêµ°ê³¼ ëŒ€ì¡°êµ°ì„ ëœë¤í•˜ê²Œ ë‚˜ëˆ„ì–´ ë™ì§ˆ ê·¸ë£¹(homogeneous group)ìœ¼ë¡œ ë¶„í• í•˜ê³ , íƒ€ê²Ÿêµ°ì—ë§Œ ì²˜ì¹˜(Treatment)ë¥¼ ì§„í–‰í•˜ì—¬ ë‚˜ì˜¨ ê°’ì—ì„œ ëŒ€ì¡°êµ°ì˜ ê°’ì„ ì°¨ê°í•´ì¤€ ê²°ê³¼ëŠ” ì²˜ì¹˜ë¡œ ì¸í•œ ê²°ê³¼ë‹¤! $T \longrightarrow Y$ (ì²˜ì¹˜ì™€ ê²°ê³¼ ì‚¬ì´ì—ëŠ” ì¸ê³¼ê´€ê³„ê°€ ì¡´ì¬í•œë‹¤.)

::: column-margin
![](img6.png)
:::

-   (íŠ¹íˆ ë§ˆì¼€íŒ…ì—ì„œ)ì¸ê³¼ì¶”ë¡ ì„ ì˜ ëª¨ë¥´ëŠ” ì˜ì‚¬ê²°ì •ìì˜ í”í•œ ë°˜ë¡ . ì›ë˜ \[ìƒí’ˆ/ì´ë²¤íŠ¸/ê¸°ëŠ¥ê°œì„ /ì—…ë°ì´íŠ¸\]ê°€ ì´ì „ë³´ë‹¤ ê³ ê°ì—ê²Œ ë§¤ë ¥ì ì´ì–´ì„œ ê·¸ëŸ°ê±° ì•„ëƒ?
-   í”í•œ ë¶„ì„ê°€ì˜ ì„¤ëª…: íƒ€ê²Ÿêµ°ê³¼ ëŒ€ì¡°êµ° ëª¨ë‘ì—ê²Œ ë™ì§ˆí•˜ê²Œ ì ìš©ë˜ëŠ” ì™¸ë¶€ë³€ìˆ˜ì„.
    -   ğŸ¤” ê³¼ì—° ì§„ì§œ ê·¸ëŸ´ê¹Œ? ì˜ì™¸ë¡œ ë‚ ì¹´ë¡œìš´ ì§€ì ì´ì—ˆì„ ìˆ˜ë„

::: column-margin
![](img7.png)
:::

-   ë…¼ë¬¸ì†Œê°œ. (Microsoft) Common Metric Interpretation Pitfall in A/B test [ì›ë¬¸ì€ ì—¬ê¸°](https://www.notion.so/Casual-Causality-efb2d821ae334b8d9674ca331edebc72)

> ğŸ’¡ A/B testë¥¼ ì§„í–‰í•  ë•Œ ë°˜ë“œì‹œ ì•„ë˜ 4ê°€ì§€ë¥¼ í™•ì¸í•´ì•¼ í•¨\
> (1) Data Quality : í™œìš©ëœ ë°ì´í„°ê°€ ì‹ ë¢°í• ë§Œí•œê°€? e.g. íƒ€ê²Ÿêµ°ê³¼ ëŒ€ì¡°êµ°ì˜ ë™ì¼í•œ ëª¨ì§‘ë‹¨ì—ì„œ ëœë¤ ìƒ˜í”Œë§ë˜ì—ˆëŠ”ì§€.\
> (2) OverallEvaluation Criteria : ì²˜ì¹˜ê°€ ì„±ê³µì ì´ì—ˆëŠ”ì§€, ì„±ê³µí–ˆë‹¤ë©´ ì–´ëŠ ì •ë„ì˜ íš¨ê³¼ì˜€ëŠ”ì§€, ê·¸ íš¨ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œì§€\
> (3) Guardrail : ì‹¤í—˜ì— ì˜í–¥ì„ ì£¼ëŠ” êµë€ì€ ì–´ëŠ ì •ë„ì˜€ëŠ”ê°€ (ì „ì‚¬ì ìœ¼ë¡œ ì˜í–¥ì„ ë°›ìœ¼ë©´ ì•ˆë˜ëŠ” ì§€í‘œ)\
> (4) Local Feature and Diagnostic : ìœ ì €ì˜ ì•¡ì…˜ì„ ì„¸ë°€í•œ ìˆ˜ì¤€ì—ì„œ ë¶„ì„í•˜ì—¬ ì²˜ì¹˜ì˜ ì„±ê³µ ì—¬ë¶€ì™€ êµë€ ë³€ìˆ˜ì˜ ì˜í–¥ ì •ë„ë¥¼ íŒŒì•…Â 

-   

    -   ì‚¬ë¡€1. Counfounding factor - Metric Sample Ratio Mismatch(e.g.)
        -   ë§í¬ ì´ë™ ë°©ë²•ì— ë”°ë¥¸ ìœ ì € ê²½í—˜ ìµœì í™”
        -   ë§í¬ë¥¼ ìƒˆë¡œìš´ íƒ­ì—ì„œ ë„ìš°ëŠ” ê²ƒì´ í™ˆí˜ì´ì§€ ë¡œë“œ íƒ€ì„ì„ ì¦ê°€ì‹œì¼°ë‹¤ (?)

| Â       | ê°€ì„¤                                                                       | ê²°ê³¼ (í˜ì´ì§€ ë¡œë“œ ìˆ˜) |
|------------------------|------------------------|------------------------|
| íƒ€ê²Ÿêµ° | MSN í™ˆí˜ì´ì§€ì—ì„œ í´ë¦­ëœ ì–´ëŠ ë§í¬ë“ , ìƒˆë¡œìš´ íƒ­ìœ¼ë¡œ í˜ì´ì§€ê°€ ëœ¬ë‹¤.          | \~8.4M                |
| ëŒ€ì¡°êµ° | MSN í™ˆí˜ì´ì§€ì—ì„œ í´ë¦­ëœ ì–´ëŠ ë§í¬ë“ , ì˜¤í”ˆë˜ì–´ ìˆëŠ” íƒ­ì—ì„œ ë§í¬ë¡œ ì´ë™ëœë‹¤. | \~9.2M                |

ê²°ë¡ : ì‹¤í—˜êµ°(íƒ€ê²Ÿêµ°)ì—ì„œ í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì´ ì•½ 8.32% ì¦ê°€í–ˆë‹¤. -\> ê¸°ëŒ€ ì´ìƒì˜ í° ì¦ê°€

ğŸŒŸÂ **Confounding factor**

(1) **í™ˆí˜ì´ì§€ íƒ­ì´ ë¯¸ë¦¬ ì¼œì ¸ ìˆì–´ reloadí•˜ì§€ ì•Šì•„ë„ ë˜ëŠ” ìƒí™©**

(2) **ëŒ€ì¡°êµ°ì˜ ê²½ìš° ë¸Œë¼ìš°ì €ì— ë‚¨ì€ í™ˆí˜ì´ì§€ ìºì‹œ**

ğŸ’¡ ì´ëŸ° ìš”ì¸ë“¤ì„ ì–´ë–»ê²Œ ë°œê²¬ í•´ì•¼í• ê¹Œ?

(1) ë¹„ìœ¨ ì§€í‘œë¥¼ ë¶„í•´í•˜ì—¬ ì–´ëŠ ë¶€ë¶„ì—ì„œ ì°¨ì´ê°€ ë°œìƒí•˜ëŠ”ì§€ íŒŒì•…

(2) ë¹„ìœ¨ mismatchì— ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ” ì‹¤í—˜êµ°, ëŒ€ì¡°êµ° ê°„ì˜ ë™ë“±í•˜ê²Œ ë¹„êµí•  ìˆ˜ ìˆëŠ” subsetì„ ì°¾ì•„ì„œ ì‹ ë¢° ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ë¶„ì„

-   ì‚¬ë¡€2. Counfounding factor - Novelty and Primacy Effects
    -   (e.g.) CRMì¸¡ë©´ì—ì„œì˜ ê° ì„¸ê·¸ë¨¼íŠ¸ ë³„ ì²˜ì¹˜ì— ë”°ë¥¸ íš¨ê³¼ ì¸¡ì •
    -   ê·¸ë£¹ Aì˜ ì²˜ì¹˜ íš¨ê³¼ê°€ ê·¸ë£¹ Bì˜ ì²˜ì¹˜ íš¨ê³¼ë³´ë‹¤ ì¢‹ì•˜ë‹¤(?)

| Â          | ê·¸ë£¹ A                               | ê·¸ë£¹ B                               |
|------------------------|------------------------|------------------------|
| ì²˜ì¹˜ íš¨ê³¼ | (ì²˜ì¹˜êµ°ì´ ëŒ€ì¡°êµ°ì— ë¹„í•´) + 126% ìƒìŠ¹ | (ì²˜ì¹˜êµ°ì´ ëŒ€ì¡°êµ°ì— ë¹„í•´) + 108% ìƒìŠ¹ |

ì—¬ê¸°ì„œ ë‚¼ ìˆ˜ ìˆëŠ” ê²°ë¡ : ê·¸ë£¹ Aê°€ CRM ì¸¡ë©´ì—ì„œ ê·¸ë£¹ Bë³´ë‹¤ ë” ì¢‹ì€ ì„¸ê·¸ë¨¼íŠ¸ë‹¤. ê·¸ë£¹ Aë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ì „ëµì„ ìˆ˜ë¦½í•´ë³´ì(?)

![](img8.png)

![](img9.png)

ğŸŒŸÂ **Confounding factor** - ê·¸ë£¹ Aì—ì„œì˜ Novelty effect

-   Novelty effect : ê¸ì •ì ì¸ íš¨ê³¼ê°€ ë‹¨ê¸°ê°„ í˜¹ì€ ì´ˆë°˜ì—ë§Œ ë°œìƒí•˜ê³ , ê¸°ê°„ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ ê·¸ íš¨ê³¼ê°€ ë‚˜íƒ€ë‚˜ì§€ ì•Šì„ ë•Œ (ì´ˆë‘íš¨ê³¼)
-   Primacy effect : ì´ˆë°˜ì—ëŠ” ìœ ì €ì˜ ë°˜ì‘ì´ ê·¹ì ì´ì§€ ì•Šì§€ë§Œ, ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ user learningì´ ë°œìƒí•˜ì—¬ ì²˜ì¹˜ ìµœì í™”ê°€ ì˜ ì´ë£¨ì–´ì§ˆë•Œ

> ğŸ’¡ ì´ëŸ° ìš”ì¸ë“¤ì„ ì–´ë–»ê²Œ ë°œê²¬ í•´ì•¼í• ê¹Œ?\
> (1) ì²˜ì¹˜ íš¨ê³¼ë¥¼ ë‹¤ì–‘í•œ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ìª¼ê°œì–´ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³¸ë‹¤.\
> (2) ì²˜ì¹˜ì˜ íš¨ê³¼ë¥¼ ì¼ë³„ë¡œ ìª¼ê°œì–´ í™•ì¸í•´ë³¸ë‹¤.\
> (3) ì‹¤í—˜ì˜ ê¸°ê°„ì„ ëŠ˜ë ¤ ì¥ê¸°ì ìœ¼ë¡œ í™•ì¸í•´ë³¸ë‹¤.

-   **ê²°ë¡ **
    -   ìš°ë¦¬ê°€ ì§„í–‰í•œ í…ŒìŠ¤íŠ¸ ì„¤ê³„ê°€ ì˜ë˜ì–´ìˆë‹¤ëŠ” êµ³ì€ ë¯¿ìŒì—ì„œ ë²—ì–´ë‚˜ ê²°ê³¼ë¥¼ ì£¼ì–´ì§„ ë¦¬ì†ŒìŠ¤ ì•ˆì—ì„œ ìµœëŒ€í•œ ë¹„íŒì ìœ¼ë¡œ í•´ì„í•´ì•¼í•œë‹¤.
    -   A/B testë¥¼ ì§„í–‰í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” êµë€ ë³€ìˆ˜ì˜ ë²”ìœ„ë¥¼ ì •í•œë‹¤ í•˜ë”ë¼ë„ ì„¸ë¶€ì ì¸ ë³€ìˆ˜ë“¤ì„ ëª¨ë‘ íŒŒì•…í•˜ê¸°ë€ í˜ë“¤ë‹¤. í•˜ì§€ë§Œ ìœ„ ë…¼ë¬¸ì—ì„œ ì†Œê°œí•œëŒ€ë¡œ ì—¬ëŸ¬ Metricì— ëŒ€í•´ ì •ì˜ë¥¼ ì§„í–‰í•˜ê³  ê²½í—˜ì ìœ¼ë¡œ ìŒ“ì¸ ë°œìƒ ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤ì— ëŒ€í•œ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ì˜ êµ¬ì¶•í•œë‹¤ë©´ ë” ë°œì „ëœ ì¶”ë¡ ì„ í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.
    -   A/B test ë¶„ì„ì„ ì§„í–‰í•˜ëŠ” ë¶„ì„ê°€ì˜ ë„ë©”ì¸ì— ëŒ€í•œ ì´í•´ë„, ì‚¬ì „ ì§€ì‹ì´ ì¤‘ìš”í•  ìˆ˜ ìˆë‹¤. ë„ë©”ì¸ ì§€ì‹ ì •ë„ì— ë”°ë¼ ì¶”ì¸¡í•  ìˆ˜ ìˆëŠ” êµë€ ë³€ìˆ˜ì˜ ë²”ìœ„ë„ ë„“ì–´ì§ˆ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

## Sensitivity analysis

ì¼ë°˜ì ìœ¼ë¡œÂ ê´€ì°°Â ë°ì´í„°ë¡œÂ ì¸ê³¼ì¶”ë¡ Â ë¶„ì„ì„Â í• Â ë•Œì—ëŠ”Â ê´€ì¸¡ë˜ì§€Â ì•Šì€Â êµë€Â ìš”ì¸ì´Â ì—†ë‹¤ëŠ”Â ê°€ì •Â í•˜ì—ì„œÂ ë¶„ì„ì„Â ì§„í–‰í•©ë‹ˆë‹¤.Â ì¼ë°˜ì ìœ¼ë¡œÂ ì´ëŸ¬í•œÂ ê°€ì •ì€Â ë§Œì¡±ë Â ìˆ˜Â ì—†ìŠµë‹ˆë‹¤.Â ë”°ë¼ì„œÂ ê°€ì •ì´Â ìœ„ë°˜ë˜ì—ˆì„Â ë•Œ,Â ì¸ê³¼Â ê´€ê³„ì—Â ë¯¸ì¹˜ëŠ”Â ì˜í–¥ì„Â ì •ëŸ‰ì ìœ¼ë¡œÂ í™•ì¸í•˜ëŠ”Â ì ˆì°¨,Â ì¦‰Â ê°•ê±´ì„±ì„Â í™•ì¸í•˜ëŠ”Â ì ˆì°¨ê°€Â í•„ìš”í•©ë‹ˆë‹¤. ì´ê²ƒì„Â ì¸¡ì •í•˜ê¸°Â ìœ„í•´Â ë‹¤ìŒê³¼Â ê°™ì€Â ì§ˆë¬¸ì„Â í•´ë³¼Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.

ê´€ì°° ë°ì´í„°ë¡œ ì¶”ì •í•œ ì¸ê³¼íš¨ê³¼ë¥¼ $0$ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ì„œ ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸ì´ $T$ì™€ $Y$ì— ì–¼ë§ˆë‚˜ ë§ì€ ì˜í–¥ì„ ë¼ì³ì•¼ í•˜ëŠ”ê°€? ë¯¼ê°ë„ë¶„ì„ì€ ì´ëŸ¬í•œ ì§ˆë¬¸ì— ë‹µì„ í•˜ê¸° ìœ„í•œ ì •ëŸ‰ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.Â 

### Sensitivity Basiscs in Linear Setting

ë¨¼ì €Â ê°€ì¥Â ê°„ë‹¨í•œÂ ì„¸íŒ…ìœ¼ë¡œÂ linearÂ settingì„Â ê³ ë ¤í•´ë³´ê² ìŠµë‹ˆë‹¤.Â ì˜¤ë¥¸ìª½Â ê·¸ë¦¼ì„Â ë³´ë©´Â $W$ëŠ”Â ê´€ì°°ëœÂ êµë€ìš”ì¸ì´ê³ ,Â $U$ëŠ”Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸ì„Â ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.Â $U$ì˜Â íš¨ê³¼ë¥¼Â ë¬´ì‹œí–ˆì„Â ë•Œ,Â ë‚˜íƒ€ë‚˜ëŠ”Â í¸í–¥ì€Â ì–´ëŠÂ ì •ë„ì¼ê¹Œìš”?

::: column-margin
![](img10.png)
:::

linearÂ settingì—ì„œÂ $T$ì™€Â $Y$ëŠ”Â ë‹¤ìŒê³¼Â ê°™ì´Â í‘œí˜„í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.

$$\begin{aligned} &T := \alpha_w W + \alpha_u U \\ &Y := \beta_w W + \beta_u U + \delta T \\ \end{aligned}$$

ë¨¼ì €Â $T,Â \,Â U$ê°€Â ì£¼ì–´ì¡Œì„Â ë•Œë¥¼Â ê°€ì •í•˜ë©´,Â ATEëŠ”Â $\delta$ë¡œÂ ê³„ì‚°ë©ë‹ˆë‹¤.

$$E[Y(1) - Y(0)] = E_{W, U}[E[Y|T=1,W,U] - E[Y|T=0, W, U]] = \delta$$

í•˜ì§€ë§ŒÂ $U$ëŠ”Â ê´€ì°°í• Â ìˆ˜Â ì—†ëŠ”Â êµë€ìš”ì¸ì´ë¯€ë¡œ,Â ì‹¤ì œë¡œëŠ”Â $W$ë§ŒÂ ì¡°ì •í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â ë”°ë¼ì„œÂ $U$ì˜Â ì˜í–¥ìœ¼ë¡œÂ confoundingÂ biasê°€Â $\frac{\beta_u}{\alpha_u}$Â ë§Œí¼Â ë°œìƒí•©ë‹ˆë‹¤.

> $$ E_W[E[Y|T=1, W]-E[Y|T=0, W]] - E_{W,U}[E[Y|T=1, W, U] - E[Y|T=0, W, U]] = \frac{\beta_u}{\alpha_u} $$

$proof$

$$ \begin{aligned} E_W[E[Y|T=t, W]] &= E_W[E[\beta_w W + \beta_u U + \delta T|T=t, W]] \\ &= E_W[\beta_w W + \beta_u E[U|T=t, W] + \delta t] \\ \newline &=E_w \left[\beta_w W + \beta_u \frac{t-\alpha_w W}{\alpha_u} + \delta t\right] \\ &=E_w \left[\beta_w W + \frac{\beta_u}{\alpha_u}t - \frac{\beta_u \alpha_w}{\alpha_u}W + \delta t\right] \\ &=\beta_w E[W] + \frac{\beta_u}{\alpha_u}t - \frac{\beta_u \alpha_w}{\alpha_u}E[W] + \delta t \\ &=\left(\delta + \frac{\beta_u}{\alpha_u}\right)t + \left(\beta_w - \frac{\beta_u \alpha_w}{\alpha_u}\right)E[W] \end{aligned} $$

$$ \begin{aligned} &E_W[E[Y|T=1, W]-E[Y|T=0, W]] \\ &= \left(\delta + \frac{\beta_u}{\alpha_u}\right)(1) + \left(\beta_w - \frac{\beta_u \alpha_w}{\alpha_u}\right)E[W] - \left[\left(\delta + \frac{\beta_u}{\alpha_u}\right)(0) + \left(\beta_w - \frac{\beta_u \alpha_w}{\alpha_u}\right)E[W]\right] \\ &= \delta + \frac{\beta_u}{\alpha_u} \end{aligned}$$

$$ \begin{aligned} Bias &= E_W[E[Y|T=1, W]-E[Y|T=0, W]] \\ &- E_{W,U}[E[Y|T=1, W, U] - E[Y|T=0, W, U]] \\ &= \delta + \frac{\beta_u}{\alpha_u} - \delta \\ &= \frac{\beta_u}{\alpha_u} \end{aligned} $$

### Sensitivity Contour Plots

trueÂ ATEì¸Â $\delta$ëŠ”Â ì•„ë˜ì™€Â ê°™ì´Â ë‹¤ì‹œÂ ì •ë¦¬í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.

$$ E_W[E[Y|T=1, W]-E[Y|T=0, W]] = \delta + \frac{\beta_u}{\alpha_u} $$

$$\begin{aligned} \delta = E_W[E[Y|T=1, W]-E[Y|T=0, W]] - \frac{\beta_u}{\alpha_u} \end{aligned}$$

ì‹ì„Â í•œë²ˆÂ ë”Â í•´ì„í•´ë³´ë©´Â ë‹¤ìŒê³¼Â ê°™ìŠµë‹ˆë‹¤.

-   $U$ì— ì˜í•´ ìƒê¸°ëŠ” biasì¸ $\frac{\beta_u}{\alpha_u}$ì´ í¬ë‹¤ë©´ $E_W[E[Y|T=1, W]-E[Y|T=0, W]]$ëŠ” ìƒì‡„ë˜ê³ , $\delta$ëŠ” $0$ì— ê°€ê¹Œì›Œì§
-   $U$ì— ì˜í•´ ìƒê¸°ëŠ” biasì¸ $\frac{\beta_u}{\alpha_u}$ì´ ì‘ë‹¤ë©´ $E_W[E[Y|T=1, W]-E[Y|T=0, W]]$ëŠ” í¬ê²Œ ë³€í™”í•˜ì§€ ì•Šê³ , $\delta$ëŠ” $E_W[E[Y|T=1, W]-E[Y|T=0, W]]$ê³¼ í° ì°¨ì´ê°€ ì—†ìŒ

ì´ì—Â ëŒ€í•´ì„œÂ ê·¸ë˜í”„ë¡œÂ ë‚˜íƒ€ë‚´ë³´ë©´Â ë‹¤ìŒê³¼Â ê°™ìŠµë‹ˆë‹¤.

![](img11.png)

ê·¸ë¦¼ì€Â ($\frac{1}{\alpha_u}$,Â $\beta_u$)ì—Â ë”°ë¥¸Â $\delta$ì˜Â ë³€í™”Â ê·¸ë˜í”„ì…ë‹ˆë‹¤.Â ë¨¼ì €Â greenÂ curveÂ ê°’ì„Â í•´ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.Â $E_W[E[Y|T=1,Â W]-E[Y|T=0,Â W]]=25$ë¡œÂ ê³ ì •í–ˆì„Â ë•Œ,Â $\frac{1}{\alpha_u}Â =Â 1$ì´ê³ ,Â $\beta_uÂ =Â 25$ë¼ë©´Â $\deltaÂ =Â 0$ì´Â ë©ë‹ˆë‹¤. ë”°ë¼ì„œÂ greenÂ curveì¼Â ê²½ìš°Â ($\frac{1}{\alpha_u}$,Â $\beta_u$)ì˜Â ë³€í™”ì—Â ë”°ë¥¸Â $\deltaÂ =Â 0$Â ì¼Â ë•Œì—Â í•´ë‹¹í•˜ëŠ”Â ê³¡ì„ ì…ë‹ˆë‹¤.Â $\deltaÂ =Â 0$ì´ë¼ëŠ”Â ì˜ë¯¸ëŠ”Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€Â ìš”ì¸Â $U$ì—Â ì˜í•´Â $E_W[E[Y|T=1,Â W]-E[Y|T=0,Â W]]$ì„Â ì „ë¶€Â ì„¤ëª…í•œë‹¤ëŠ”Â ì˜ë¯¸ì™€Â ê°™ìœ¼ë©°,Â $U$ëŠ”Â ê°•ë ¥í•œÂ êµë€ìš”ì¸ì´ë¼ê³ Â ë³¼Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤. ê²°ë¡ ì ìœ¼ë¡œÂ greenÂ curveì—Â ê°€ê¹Œì›Œì§€ê±°ë‚˜Â í˜¹ì€Â greenÂ curveë¥¼Â ë„˜ì–´ì„¤Â ê²½ìš°Â êµë€ìš”ì¸ì—Â ì˜í•´Â ì˜í–¥ì„Â ë§ì´Â ë°›ìœ¼ë¯€ë¡œ,Â ê°•ê±´ì„±ì´Â ë–¨ì–´ì§„ë‹¤ê³ Â ë³¼Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤. ì •ë¦¬í•˜ë©´,Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸ì´Â treatmentì™€Â outcomeì—Â ëŒ€í•´Â ë¯¸ì¹˜ëŠ”Â ì˜í–¥ì˜Â ë°©í–¥ì€Â ì•ŒÂ ìˆ˜Â ì—†ìŠµë‹ˆë‹¤.Â ì´ì—Â ë”°ë¼Â ë¯¼ê°ë„Â ë¶„ì„ì—ì„œëŠ”Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸ì˜Â \*\*í¬ê¸°\*\*ë¥¼Â ê³ ë ¤í•©ë‹ˆë‹¤.Â ìœ„ì˜Â ê·¸ë¦¼Â ì˜ˆì‹œì²˜ëŸ¼Â ë¯¼ê°ë„Â ë¶„ì„ì„Â í†µí•´Â ì¶”ì •ëœÂ íš¨ê³¼ë¥¼Â ì—†ì•¨Â ì •ë„ë¡œÂ ì¶”ì •ëŸ‰ì„Â ë³€ê²½í•˜ë ¤ë©´Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸ì˜Â í¬ê¸°ê°€Â ì–´ëŠÂ ì •ë„ì—¬ì•¼Â í•˜ëŠ”ì§€ë¥¼Â í™•ì¸í• Â ìˆ˜Â ìˆê³ ,Â ë„ë©”ì¸Â ì§€ì‹ì„Â í™œìš©í•˜ì—¬Â ì¶”ì •ëœÂ íš¨ê³¼ì˜Â ê°•ê±´ì„±ì„Â **ì£¼ê´€ì **ìœ¼ë¡œÂ ê²°ì •í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.

### More General Settings

ê°•ì˜ì—ì„œëŠ” ë” ì¼ë°˜ì ì¸ ë¯¼ê°ë„ ë¶„ì„ ë°©ë²•ì— ëŒ€í•´ ì†Œê°œí•©ë‹ˆë‹¤.Â 

1.  **Assess-ing Sensitivity to an Unobserved Binary Covariate in an Observational Study with Binary Outcome(1983)**

2.  **Making sense of sensitivity: extending omitted variable bias(2020)**

ì´ ì¤‘ ë‘ ë²ˆì§¸ ë…¼ë¬¸ì— ëŒ€í•´ì„œ ì§§ê²Œ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.Â 

ì´ ë…¼ë¬¸ì—ì„œëŠ” partial $R^2$ë¥¼ í™œìš©í•´ì„œ linear regressionì—ì„œ ë¯¼ê°ë„ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ë¦¬í¬íŒ…í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤.Â 

\*\*ì£¼ìš”Â ê¸°ì—¬ì‚¬í•­\*\*

1.Â Â RobustnessÂ valueÂ ê°œë°œ

2.Â Â partialÂ $R^2$ë¥¼Â í™œìš©í•œÂ ë¯¼ê°ë„ë¶„ì„Â íˆ´Â ê°œë°œ

3.Â Â extremeÂ scenarioì—Â ëŒ€í•œÂ ë¶„ì„Â ê·¸ë˜í”„Â ê°œë°œ

í•´ë‹¹Â ë…¼ë¬¸Â ì €ìê°€Â ê°œë°œí•œÂ íˆ´ì€Â R,Â Python,Â StataÂ ë“±ì—ì„œÂ ì´ìš©í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.

::: column-margin
-   python :Â 
    -   [PySensemakr](https://github.com/nlapier2/PySensemakr)
    -   [pywhy](https://www.pywhy.org/dowhy/v0.9.1/_modules/dowhy/causal_refuters/linear_sensitivity_analyzer.html#LinearSensitivityAnalyzer.robustness_value_func)
-   R : sensemakrÂ 
:::

ë…¼ë¬¸ì—ì„œ ë‚˜ì˜¤ëŠ” exampleì´ ì§ê´€ì ì´ì§€ ì•Šì•„ì„œ ë‹¤ë¥¸ ë¸”ë¡œê·¸ ì˜ˆì‹œë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.Â 

-   ì°¸ê³  : <https://matteocourthoud.github.io/post/ovb/>
-   êµìœ¡ê¸°ê°„ê³¼ ì„ê¸ˆ ì‚¬ì´ì˜ ê´€ê³„ì— ê´€ì‹¬ì´ ìˆìŒ
-   êµìœ¡ê¸°ê°„ê³¼ ì„ê¸ˆ ì‚¬ì´ì—ëŠ” ë§ì€ unobserved confounderê°€ ì¡´ì¬í•¨
-   ì˜ˆì‹œë¥¼ ìœ„í•´ unobserved confounderë¡œ abilityê°€ ìˆë‹¤ê³  ê°€ì •
-   abilityëŠ” omitted variableì´ì§€ë§Œ educationê³¼ wageì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ì•Œê³  ìˆë‹¤ê³  ê°€ì •í•¨

::: column-margin
![](img12.png)
:::

```         
library(sensemakr)
library(tidyverse)
```

```         
#setwd("./posts/2023-02-07-sensitivity-analysis")
df <- read.csv("ex_data.csv")[, -1] %>% 
    mutate(gender = as.factor(gender))
df %>% head(2)

  age gender education wage
1  62   male         6 3800
2  44   male         8 4500
```

```         
fit <- lm(wage ~ ., df)
summary(fit)

Call:
lm(formula = sleep_total ~ ., data = dat)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.7435 -2.6495  0.0466  1.3376  7.0845 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 12.618464   0.862433  14.631 4.59e-11 ***
brainwt     -9.246523  14.305157  -0.646    0.527    
bodywt      -0.009216   0.013960  -0.660    0.518    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 3.476 on 17 degrees of freedom
Multiple R-squared:  0.4766,    Adjusted R-squared:  0.4151 
F-statistic: 7.741 on 2 and 17 DF,  p-value: 0.004072
```

íšŒê·€ë¶„ì„ ê²°ê³¼, ì¶”ì •ëœ ATEëŠ” ì•½Â 96ìœ¼ë¡œ, êµìœ¡ ê¸°ê°„ì´ í•œ ë‹¨ìœ„ ì¦ê°€í•  ë•Œ, ì„ê¸ˆì€ ì•½ 96 ì¦ê°€í•©ë‹ˆë‹¤(education =Â 95.94). í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸(ability)ì´ ì¡´ì¬í•˜ë¯€ë¡œ, í•´ë‹¹ ì¶”ì •ëŸ‰ì€ í¸í–¥ ì¶”ì •ëŸ‰ì…ë‹ˆë‹¤(í•´ë‹¹ ë°ì´í„°ëŠ” ê°€ìƒì˜ ë°ì´í„°ì´ë¯€ë¡œ, ì‹¤ì œë¡œëŠ” ìˆ˜ ë§ì€ êµë€ìš”ì¸ì´ ì¡´ì¬í•©ë‹ˆë‹¤).

ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸ì˜ í¬ê¸°ì— ë”°ë¼ ì¶”ì •ëœ ATEì˜ ê°•ê±´ì„±ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ ë¯¼ê°ë„ ë¶„ì„ì„ ìˆ˜í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤. sensemakr íŒ¨í‚¤ì§€ì˜Â sensemakr()Â í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ê°„ë‹¨íˆ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```         
sens <- sensemakr(model = fit, treatment = "education")
summary(sens)

Sensitivity Analysis to Unobserved Confounding

Model Formula: wage ~ age + gender + education

Null hypothesis: q = 1 and reduce = TRUE 
-- This means we are considering biases that reduce the absolute value of the current estimate.
-- The null hypothesis deemed problematic is H0:tau = 0 

Unadjusted Estimates of 'education': 
  Coef. estimate: 95.9437 
  Standard Error: 38.7521 
  t-value (H0:tau = 0): 2.4758 

Sensitivity Statistics:
  Partial R2 of treatment with outcome: 0.1176 
  Robustness Value, q = 1: 0.3044 
  Robustness Value, q = 1, alpha = 0.05: 0.0627 

Verbal interpretation of sensitivity statistics:

-- Partial R2 of the treatment with the outcome: an extreme confounder (orthogonal to the covariates) that explains 100% of the residual variance of the outcome, would need to explain at least 11.76% of the residual variance of the treatment to fully account for the observed estimated effect.

-- Robustness Value, q = 1: unobserved confounders (orthogonal to the covariates) that explain more than 30.44% of the residual variance of both the treatment and the outcome are strong enough to bring the point estimate to 0 (a bias of 100% of the original estimate). Conversely, unobserved confounders that do not explain more than 30.44% of the residual variance of both the treatment and the outcome are not strong enough to bring the point estimate to 0.

-- Robustness Value, q = 1, alpha = 0.05: unobserved confounders (orthogonal to the covariates) that explain more than 6.27% of the residual variance of both the treatment and the outcome are strong enough to bring the estimate to a range where it is no longer 'statistically different' from 0 (a bias of 100% of the original estimate), at the significance level of alpha = 0.05. Conversely, unobserved confounders that do not explain more than 6.27% of the residual variance of both the treatment and the outcome are not strong enough to bring the estimate to a range where it is no longer 'statistically different' from 0, at the significance level of alpha = 0.05.
```

Unadjusted Estimates of ' education ':ëŠ” ê¸°ì¡´ íšŒê·€ë¶„ì„ ê²°ê³¼ì™€ ê°™ìŠµë‹ˆë‹¤. Sensitivity Statistics:ì„ ë³´ë©´ partial $R^2$ì™€ Robustness Value(RV) ë“±ì´ í‘œê¸°ë©ë‹ˆë‹¤. ë˜í•œ í•´ë‹¹ ì§€í‘œì— ëŒ€í•œ í•´ì„ë„ í•¨ê»˜ ì œì‹œë©ë‹ˆë‹¤.

-   $RV_1$Â : ì¸¡ì •ë˜ì§€ ì•Šì€ êµë¸ìš”ì¸ì´ êµìœ¡ê³¼ ì„ê¸ˆì˜ ì”ì°¨ ë³€ë™ì˜ 30.44%ë¥¼ ì„¤ëª…í•œë‹¤ë©´ ì¶”ì •ëŸ‰ì„ 0ìœ¼ë¡œ ë§Œë“¤ê¸° ì¶©ë¶„í•¨ or ì¶©ë¶„í•˜ì§€ ì•ŠìŒ

30.44%ê°€ ì¶©ë¶„í•œì§€ or ì¶©ë¶„í•˜ì§€ ì•Šì€ì§€ëŠ” ë¶„ì„ê°€ì˜ íŒë‹¨ì— ì˜ì¡´í•©ë‹ˆë‹¤. ë˜ëŠ”Â benchmark_covariatesÂ ì˜µì…˜ì„ í†µí•´ ê´€ì°°ëœ $X$Â ë³€ìˆ˜ì™€ ë¹„êµí•¨ìœ¼ë¡œì¨ ì¶”ê°€ì ì¸ í•´ì„ì„ í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Â Robustness valueÂ 

$RV_q$ëŠ”Â ì¶”ì •ëœÂ treatmentÂ effectì˜Â ì•½Â $(100Â \timesÂ q)$%ë¥¼Â ì„¤ëª…í•˜ê¸°Â ìœ„í•´ì„œÂ unobservedÂ confounderì˜Â íš¨ê³¼ê°€Â ì–¼ë§ˆë‚˜Â ê°•ë ¥í•´ì•¼Â í•˜ëŠ”ì§€ë¥¼Â ì„¤ëª…í•˜ëŠ”Â ì§€í‘œì…ë‹ˆë‹¤.

::: column-margin
![](img13.png)
:::

$ZÂ \simÂ Y$ì˜Â ì˜í–¥ê³¼Â $ZÂ \simÂ D$ì˜Â ì˜í–¥ì´Â ë™ì¼í•˜ë‹¤ê³ Â ê°€ì •í• Â ê²½ìš°Â $RV_q$ë¥¼Â ìœ ë„í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.

$R^2_{Y\simÂ Z|X,Â D}Â =Â R^2_{D\simÂ Z|X}=RV_q$ì¼Â ë•Œ,

$$ \begin{aligned} RV_qÂ =Â \frac{1}{2}(\sqrt{f^4_qÂ +Â 4f^2_qÂ -Â f^2_q}),Â \quadÂ fÂ =Â q\cdot|\frac{t}{df}|\,\,Â (cohen's\,f) \end{aligned} $$

-   $RV_q \approx 1$ì¼ ê²½ìš° $Z$ê°€ $Y$ì™€ $D$ì˜ ëª¨ë“  ì”ì°¨ ë³€ë™ì„ ì„¤ëª…í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•¨Â  Â 
    -   strong confounder
-   $RV_q \approx 0$ì¼ ê²½ìš° $Z$ê°€ $Y$ì™€ $D$ì˜ ëª¨ë“  ì”ì°¨ ë³€ë™ì„ ì„¤ëª…í•˜ì§€ ëª»í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•¨Â  Â  Â 
    -   weak confonder

#### Sensitivity Contour plotÂ 

Robustness ValueëŠ” $R^2_{Y\sim Z|X, D} = R^2_{D\sim Z|X}$ì¼ ë•Œë¥¼ ê°€ì •í•˜ë¯€ë¡œ, $R^2_{Y\sim Z|X, D} \neq R^2_{D\sim Z|X}$ì¼ ê²½ìš° ê·¸ë˜í”„ë¥¼ í†µí•´ ëŒ€ëµì ì¸ ì¶”ì´ë¥¼ íŒŒì•…í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.Â 

```         
plot(sens, xlab = "Partial R^2 of ability with education", 
     ylab = "Partial $R^2$ of ability with wage")
```

![](img14.png)

ê·¸ë˜í”„ë¥¼Â ë³´ë©´Â UnadjustedëŠ”Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸(ability)ê°€Â ì˜í–¥ì„Â ì£¼ì§€Â ì•Šì„Â ë•Œë¥¼Â ì˜ë¯¸í•©ë‹ˆë‹¤.Â ì¦‰,Â íšŒê·€ë¶„ì„Â ê²°ê³¼ì™€Â ë™ì¼í•©ë‹ˆë‹¤.Â ìš°ì¸¡Â ìƒë‹¨ìœ¼ë¡œÂ ê°ˆìˆ˜ë¡Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸ì˜Â íš¨ê³¼ê°€Â ì¦ê°€í•˜ê³ ,Â ë¹¨ê°„ìƒ‰Â dotÂ lineì—Â ë„ë‹¬í–ˆì„Â ë•Œ,Â $\hat{\beta}_{education}Â =Â 0$ì´Â ë©ë‹ˆë‹¤.Â 

ê·¸ë˜í”„ë¥¼Â ë³´ë©´Â ë¹¨ê°„ìƒ‰Â dotÂ lineÂ ìœ„ì—Â ìˆëŠ”Â ê°’ìœ¼ë¡œÂ $R^2_{YÂ \simÂ Z|D,X}Â =Â 0.3$,Â \$Â R\^2\_{DÂ \\simÂ Z\|X}Â =Â 0.3\$Â ì •ë„ë¡œÂ ìƒê°í•´ë³¼Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â ë…¼ë¬¸ì—ì„œÂ ìœ ë„í•œÂ ê³µì‹ì„Â ì´ìš©í•´ì„œÂ biasÂ ì¶”ì •ì¹˜ë¥¼Â êµ¬í•´ë³´ê³ Â í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.Â 

ë…¼ë¬¸ì—ì„œÂ partialÂ $R^2$ë¥¼Â ì´ìš©í•´ì„œÂ ìœ ë„í•œÂ biasÂ ì¶”ì •ì¹˜ëŠ”Â ë‹¤ìŒê³¼Â ê°™ìŠµë‹ˆë‹¤.Â 

$$ |\hat{bias}|Â =Â \sqrt{\frac{R^2_{YÂ \simÂ Z|D,X}Â \cdotÂ R^2_{DÂ \simÂ Z|X}}{1Â -Â R^2_{DÂ \simÂ Z|X}}}Â \cdotÂ \frac{sd(Y^{\perpÂ X,Â D})}{sd(D^{\perpÂ X})} $$

```         
R_YZ = 0.3
R_DZ = 0.3 

DperpX <- lm(education ~ age + gender, df)$residuals
YperpXD <- lm(wage ~ ., df)$residuals

bias <- sqrt((R_YZ*R_DZ/(1 - R_DZ)))*(sd(YperpXD)/sd(DperpX))

95.94 - bias

[1] 1.697537
```

$\hat{\beta}_{education}Â =Â 95.94$ì´ê³ ,Â $|\hat{bias}|Â =Â 94.24$ì´ë¯€ë¡œ,Â ëŒ€ëµÂ $0$ì—Â ê°€ê¹Œìš´Â ê²ƒì„Â í™•ì¸í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â 

#### SensitivityÂ contourÂ plotÂ usingÂ benchmarkÂ covariatesÂ 

sensitivity contour plotì„ ë´¤ì„ ë•Œ, ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸ì˜ treatmentì™€ outcomeì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ë”°ë¥¸ bias íš¨ê³¼ë¥¼ í™•ì¸í•´ë³¼ ìˆ˜ ìˆì§€ë§Œ, ì‹¤ì œë¡œ ì´ biasê°€ í°ì§€ í˜¹ì€ ì‘ì€ì§€ëŠ” ì£¼ê´€ì ì¸ íŒë‹¨ì— ì˜ì¡´í•©ë‹ˆë‹¤. ì¦‰, ì´ì „ ì˜ˆì‹œì—ì„œ $R^2_{Y \sim Z|D,X} = 0.3$, $R^2_{D \sim Z|X} = 0.3$ ì¼ ë•Œ, ì¶”ì •ëœ íšŒê·€ê³„ìˆ˜ëŠ” $0$ì´ ë˜ë§Œ, $R^2_{Y \sim Z|D,X} = 0.3$, $R^2_{D \sim Z|X} = 0.3$ ê°’ì´ í°ì§€ í˜¹ì€ ì‘ì€ì§€ì˜ ê¸°ì¤€ì€ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.Â 

ì´ëŸ¬í•œ ê¸°ì¤€ ì„¤ì •ì˜ ì–´ë ¤ì›€ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ì„œ ê´€ì°°ëœ ì„¤ëª…ë³€ìˆ˜ë¥¼ ë²¤ì¹˜ë§ˆí¬í•˜ì—¬ ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸ì´ ë¯¸ì¹˜ëŠ” ì˜í–¥ì˜ í¬ê¸°ë¥¼ ëŒ€ëµì ìœ¼ë¡œ ì¶”ì¸¡í•©ë‹ˆë‹¤.Â 

$$ \begin{aligned} k_DÂ :=Â \frac{R^2_{DÂ \simÂ Z|X_{-j}}}{R^2_{DÂ \simÂ X_j|X_{-j}}},Â \quad k_YÂ :=Â \frac{R^2_{YÂ \simÂ Z|X_{-j},Â D}}{R^2_{YÂ \simÂ X_j|X_{-j},Â D}} \end{aligned} $$

$k_D \ge 1$ì¼ ë•Œ, $R^2_{D \sim Z|X_{-j}} \ge R^2_{D \sim X_j|X_{-j}}$ì´ë¯€ë¡œ ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸ì´ ì‚¬ì „ì— ì§€ì •í•œ ì„¤ëª…ë³€ìˆ˜ ëŒ€ë¹„ Treatmentì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í¬ë‹¤ëŠ” ì˜ë¯¸ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. $k_Y \ge 1$ì¼ ë•Œë„ ë§ˆì°¬ê°€ì§€ë¡œ ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸ì´ ì‚¬ì „ì— ì§€ì •í•œ ì„¤ëª…ë³€ìˆ˜ ëŒ€ë¹„ ë°˜ì‘ë³€ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í¬ë‹¤ëŠ” ì˜ë¯¸ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```         
sens2 <- sensemakr(model = fit, treatment = "education", 
                  benchmark_covariates = "age", 
                  kd = c(0.5, 1, 2), 
                  ky = c(0.5, 1, 2))

plot(sens2)
```

![](img15.png)

sensemakr()Â í•¨ìˆ˜ì—ëŠ”Â \`benchmark_covariates\`Â ì˜µì…˜ì´Â ì¡´ì¬í•˜ë©°,Â $k_D$,Â $k_Y$ì˜Â í¬ê¸°ë¥¼Â ì‚¬ì „ì—Â ì§€ì •í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â ê·¸ë˜í”„ë¥¼Â í•´ì„í•´ë³´ë©´Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸(ability)ê°€Â ageì˜Â ë‘Â ë°°Â ì •ë„ì˜Â ì„¤ëª…ë ¥ì„Â ê°–ë”ë¼ë„,Â $\hat{\beta}_{education}Â =Â 67.61$ë¡œÂ ê°’ì˜Â ë³€í™”ëŠ”Â ìˆì§€ë§ŒÂ ë¶€í˜¸ëŠ”Â ì—¬ì „íˆÂ positiveì¸Â ê²ƒì„Â ë³¼Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â 

ì˜µì…˜ì„Â ì¶”ê°€í• Â ê²½ìš°Â í•´ë‹¹Â plotì—ì„œÂ í†µê³„ì Â ìœ ì˜ì„±Â ë˜í•œÂ ì²´í¬í•´ë³¼Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â 

```         
plot(sens2, sensitivity.of = "t-value")
```

![](img16.png)

í†µê³„ì  ìœ ì˜ì„±ì„ ë³´ë©´ ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸(ability)ê°€ $1 \times age$ë³´ë‹¤ ì•½ê°„ í° ì •ë„ì˜ ì„¤ëª…ë ¥ì„ ê°–ëŠ”ë‹¤ë©´, $\hat{\beta}_{education}$ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•Šê²Œ ë°”ë€” ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.Â 

```         
plot(sens2)
add_bound_to_contour(r2dz.x = 0.3, 
                     r2yz.dx = 0.3, 
                     bound_label = "Something related to\nboth outcome and treatment")
```

![](img17.png)

ì¶”ê°€ì ìœ¼ë¡œÂ ì„ì˜ë¡œÂ partialÂ $R^2$ë¥¼Â ì„¤ì •í•´ì„œÂ ì ì„Â ì°ì–´ë³¼Â ìˆ˜ë„Â ìˆìŠµë‹ˆë‹¤.Â 

#### SensitivityÂ plotsÂ ofÂ extremeÂ scenarios

extremeÂ scenarioëŠ”Â outcomeì˜Â ê±°ì˜Â ëª¨ë“ Â ì”ì°¨Â ë³€ë™ì„Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸ì´Â ì„¤ëª…í•œë‹¤ëŠ”Â ì˜ë¯¸ë¡œ,Â $R_{YÂ \simÂ Z|D,X}Â =Â 1$ì„Â ì˜ë¯¸í•©ë‹ˆë‹¤(ì˜µì…˜ìœ¼ë¡œÂ $0.75,Â 0.5$ì¼Â ë•Œë„Â í•¨ê»˜Â ì œì‹œë¨).Â ê·¸ë˜í”„ë¥¼Â í™œìš©í•˜ì—¬Â extremeÂ scenarioì¼Â ë•Œ,Â $R^2_{DÂ \simÂ Z|X}$ì˜Â ë³€í™”ì—Â ë”°ë¼Â ì¶”ì •ëœÂ íšŒê·€ê³„ìˆ˜ê°€Â ì–´ë–»ê²ŒÂ ë°”ë€ŒëŠ”ì§€ë¥¼Â ì‹œê°í™”í•´ë³¼Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â 

```         
sens3 <- sensemakr(model = fit, treatment = "education", 
                  benchmark_covariates = "age", 
                  kd = c(1, 2, 3, 4), 
                  ky = c(1, 2, 3, 4))
plot(sens3, type = "extreme", lim = 0.5)
result <- plot(sens3, type = "extreme", lim = 0.5)
```

![](img18.png)

```         
result$scenario_r2yz.dx_1[117:119,]

    r2dz.x r2yz.dx adjusted_estimate
117  0.116       1         0.7348541
118  0.117       1         0.2712232
119  0.118       1        -0.1912156
```

-   Â x axis : $R^2_{D \sim Z|X}$Â 
-   y axis : $\hat{\tau} = \hat{\tau}_{res} - \hat{bias}$Â 
-   line : $R^2_{Y \sim Z|D,X}$

ê·¸ë˜í”„ë¥¼Â ë³´ë©´Â ë¹¨ê°„ìƒ‰Â dotÂ lineì€Â ì¶”ì •ëœÂ íšŒê·€ê³„ìˆ˜ê°€Â 0ì´Â ë˜ëŠ”Â ê²½ìš°ì—Â í•´ë‹¹í•©ë‹ˆë‹¤.Â solidÂ lineì€Â $R^2_{YÂ \simÂ Z|D,X}Â =Â 1$ì¼Â ë•Œì—Â í•´ë‹¹í•©ë‹ˆë‹¤.Â $R^2_{YÂ \simÂ Z|D,X}Â =Â 1$ì¼Â ë•Œ,Â ì¶”ì •ëœÂ íšŒê·€ê³„ìˆ˜ê°€Â 0ì´Â ë˜ê¸°Â ìœ„í•´ì„œëŠ”Â $R^2_{DÂ \simÂ Z|X}Â \approxÂ 0.117$Â ì •ë„Â ë˜ì–´ì•¼Â í•˜ëŠ”Â ê²ƒì„Â í™•ì¸í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â Â 

ë˜í•œ, ì™¼ìª½ í•˜ë‹¨ì— ë¹¨ê°„ìƒ‰ vertical lineì€ benchmarkë¡œ ì„¤ì •í•œ ë³€ìˆ˜ì— ë¹„í•´ confounderê°€ ëª‡ ë°° ë” ê°•ë ¥í•œì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ \`kd = c(0.5, 1, 2)\` ì˜µì…˜ì—ì„œ ì„¤ì •í•œ ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.Â 

ê´€ì°°ëœ ì„¤ëª…ë³€ìˆ˜ ageê°€ educationì— ë¯¸ì¹˜ëŠ” íš¨ê³¼ì— ë¹„í•´ì„œ ê´€ì°°ë˜ì§€ ì•Šì€ êµë€ìš”ì¸ì´ educationì— ë¯¸ì¹˜ëŠ” íš¨ê³¼ê°€ ë„¤ ë°° ì •ë„ í´ ë•Œ, $\hat{\beta}_{education} \approx 0$ì´ ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Â 

ìƒì‹ì ìœ¼ë¡œÂ êµìœ¡ê¸°ê°„ê³¼Â ë‚˜ì´ëŠ”Â ì¶©ë¶„í•œÂ ì–‘ì˜Â ìƒê´€ê´€ê³„ê°€Â ì¡´ì¬í•œë‹¤ê³ Â ìƒê°í• Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤.Â ë”°ë¼ì„œÂ ê´€ì°°ëœÂ ì„¤ëª…ë³€ìˆ˜Â ageê°€Â educationì—Â ë¯¸ì¹˜ëŠ”Â íš¨ê³¼ì—Â ë¹„í•´ì„œÂ ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸ì´Â educationì—Â ë¯¸ì¹˜ëŠ”Â íš¨ê³¼ê°€Â ë„¤Â ë°°ì •ë„Â í´Â ë•Œ,Â $\hat{\beta}_{education}Â \approxÂ 0$ì´Â ëœë‹¤ëŠ”Â ì˜ë¯¸ëŠ”Â ATEÂ ì¶”ì •ëŸ‰ì´Â ì¶©ë¶„íˆÂ ì‹ ë¢°í• Â ìˆ˜Â ìˆê³ ,Â ê´€ì°°ë˜ì§€Â ì•Šì€Â êµë€ìš”ì¸ì—Â ê°•ê±´í•˜ë‹¤ëŠ”Â ê²ƒì„Â ì˜ë¯¸í•œë‹¤ê³ Â ë³¼Â ìˆ˜Â ìˆìŠµë‹ˆë‹¤(**ì£¼ê´€ì ì¸ í•´ì„**).Â Â 

#### pywhy tutorialÂ 

```         
import dowhy
from dowhy import CausalModel
import pandas as pd
import numpy as np
import dowhy.datasets
import os
from dowhy import CausalModel
```

```         
dat = pd.read_csv("posts/2023-02-07-sensitivity-analysis/ex_data.csv", index_col = 0)
dat.head()
```

```         
gdot = """graph[directed 1 node[id "age" label "age"]
                    node[id "gender" label "gender"]
                    node[id "education" label "education"]
                    node[id "wage" label "wage"]
                    
                    edge[source "education" target "wage"]
                    edge[source "gender" target "wage"]
                    edge[source "age" target "wage"]]"""
```

```         
model = CausalModel(
            data = dat,
            treatment="education",
            outcome="wage", 
            graph = gdot
        )
```

```         
identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)
print(identified_estimand)
```

```         
estimate = model.estimate_effect(identified_estimand,
                                 method_name="backdoor.linear_regression")
```

```         
refute = model.refute_estimate(identified_estimand, 
                               estimate,
                               method_name = "add_unobserved_common_cause",
                               simulated_method_name = "linear-partial-R2",
                               benchmark_common_causes = "age",
                               effect_fraction_on_treatment = [ 1,2,3]
                              )
```
